url,title,content,metadata,category,keyword,category_explanation,keyword_explanation
https://speakerdeck.com/gaelvaroquaux/open-source-software-how-to-live-long-and-go-far,Open source software: how to live long and go far - Speaker Deck,"Open source software: how to live long and go far Open source software: how to live long and go far An opinionated guide to building open-source software toolswith a focus on Python and science A talk that I gave when I was stepping down as a lead for the nilearn software, passing the baton to new maintainers. My goal is to summarize what I have learned across the years as a maintainer of open source/ More Decks by Gael Varoquaux Other Decks in Programming Open source software: how to live long and go far Open source software: how to live long and go far A project vision is crucial Outline a clear vision & Building with a community Community-driven "" Open source G Varoquaux Building with a community Community-driven "" Open source A community Building with a community Community-driven "" Open source A community Building with a community Community-driven "" Open source A community Limiting complexity G Varoquaux 5 Limiting complexity: being inclusive means keeping it simple Every required Limiting complexity: understanding is harder than building Debugging is twice Limiting complexity: a super-linear cost Features are costly [An Experiment Technical debt: today’s asset may be tomorrow’s liability Choose widely Technical debt: today’s asset may be tomorrow’s liability Choose widely Limiting drag Compiled code increases severely burden Installation is where Limiting drag Navigating the trade-oﬀs Compiled code increases severely burden Design: innovation and product design G Varoquaux 11 Design: innovation and product design G Varoquaux 11 Design: innovation and product design Use technical sophistication to ﬁnd Design: ergonomics Separating control of temperature and ﬂow rate Rethinking Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Design: Some API design principles for Python tools Consistency, consistency, Iterations: Short cycles, limited ambitions G Varoquaux 24 Iterations: Short cycles, limited ambitions Keep coming back to your Iterations: Limited resources Limited resources are good Need success in Quality: a priority G Varoquaux 26 Quality: a priority Quality will give you users Bugs give Quality: a priority Quality will give you users Bugs give Quality: everywhere Great documentation Simplify, but don’t dumb down Focus Quality: everywhere Great documentation Simplify, but don’t dumb down Focus Quality: Process Code review Everything is discussed ñ foster knowledge Users ﬁrst: Enabling Usability is key Users are not stupid, Users ﬁrst: reducing their cognitive load Design: Jonathan Ive, an @GaelVaroquaux Open source software: how to live long and go @GaelVaroquaux Open source software: how to live long and go","{""viewport"": ""width=device-width, initial-scale=1, viewport-fit=cover"", ""csrf-param"": ""authenticity_token"", ""csrf-token"": ""MUkxuJf0S5PnZjhOl5cFMfiK_18aEAPbfLsW3ZVijjQKfm7MOi-GqAx76VKBKHkyhV_R88b7tTA7aRMCi5nfWA"", ""og:url"": ""https://speakerdeck.com/gaelvaroquaux/open-source-software-how-to-live-long-and-go-far"", ""og:site_name"": ""Speaker Deck"", ""og:title"": ""Open source software: how to live long and go far"", ""description"": ""An opinionated guide to building open-source software tools\r\nwith a focus on Python and science\r\n\r\nA talk that I gave when I was stepping down as a lead&hellip;"", ""og:type"": ""website"", ""og:author"": ""Gael Varoquaux"", ""og:image"": ""https://files.speakerdeck.com/presentations/6aec13879123442b8de1d2b1b1c33b5e/slide_0.jpg?33758342"", ""robots"": ""max-image-preview:large"", ""twitter:card"": ""summary_large_image"", ""twitter:site"": ""@speakerdeck"", ""twitter:creator"": ""@speakerdeck"", ""twitter:title"": ""Open source software: how to live long and go far"", ""twitter:description"": ""An opinionated guide to building open-source software tools\r\nwith a focus on Python and science\r\n\r\nA talk that I gave when I was stepping down as a lead&hellip;"", ""twitter:image:src"": ""https://files.speakerdeck.com/presentations/6aec13879123442b8de1d2b1b1c33b5e/slide_0.jpg?33758342"", ""stats-owner_id"": ""2514508"", ""stats-talk_id"": ""1321367"", ""stats-view_type"": ""talk""}",,,,
https://medium.com/@seanjtaylor/a-personal-retrospective-on-prophet-f223c2378985,A Personal Retrospective on Prophet | by Sean J. Taylor | Medium,"A Personal Retrospective on ProphetSean J. TaylorFollow7 min read·Jun 4, 2023--1ListenShareFebruary 2017 was a pretty exciting time for me.Ben Lethamand I were on the cusp ofopen sourcing Prophet, now a popular forecasting library but at the time just a library for internal use at Facebook. We had developed the method for a specific forecasting use-case, and then gotten a few additional wins helping internal teams improve the accuracy of their growth forecasts.The Prophet open source launch was so successful I was taken by surprise, but with hindsight we had a lot of things going for us:We were coming from a big and prestigious company.We had a beautiful and convincing website.Our tool was available in R and Python, and easy to install and use.We used theStanlibrary, which had a devoted following.We invested in strong documentation and examples.Perhaps most importantly, there were few alternatives available at the time.We were invited to give manytalks about Prophetand a lot of people now associate me quite closely with the project. Being a co-creator of a popular open source project has had a number of unseen consequences, and I think it’s instructive to share this more personal part of the journey and some lessons I’ve learned.Unearned credibilityProphet isan approach to forecastingborn out of pragmatism — at the time we had found few off-the-shelf methods that were easy to use and accounted for the complexities we faced. It just wasn’t a rigorous research project like a forecasting researcher might complete. We validated the method on a few use cases at Facebook and then deemed it worth sharing. Some people now include me in a group of expert time-series forecasters, when a more accurate portrayal would be that I spent about a year working on a specific forecasting problem, had a great collaborator in Ben, and was pretty good at writing usable software. I think anyone who’s an actual forecasting expert could justifiably feel we got a little more credit that we deserved for the project. I regret not engaging with the forecasting community earlier in the project and trying to understand how the method fit within existing approaches. A more thorough research project might have helped us create a more broadly useful technique, rather than something tailored to the use cases we were tackling.Contribution guiltAfter open sourcing Prophet I couldn’t keep up with the community in helping to maintain the project. Part of it was prioritization — I am usually working on a variety of things and I viewed the project as “finished” in the sense that I had already made the improvements I wanted for the teams at Facebook. Ben took on a lot of maintenance work, andother folksstepped in and helped do the dirty work to make sure people could continue to painlessly install and use the software. I’ll never be able to fully transfer the credit I get over to them, but I wish I could. I’m always going to feel like I abandoned our users by not participating more fully in the ongoing improvements and maintenance.The tool creator’s dilemmaI did not face some difficult choice about whether to share Prophet, it felt obviously useful and relatively low cost to open it up. But I now feel some misgivings about it on a recurring basis — it’s hard for me to conclude it was unambiguously positive to share it publicly. Many folks would have been worse off if Prophet were not open sourced (I’ve heard many success stories!), and the competition that it helped foster in the forecasting software space has been very beneficial for practitioners. But there are many plausible negative effects as well, as people mis-apply Prophet to problems and overly trust the resulting forecasts. The central problem is that the method isn’t as great or general as some people believe it to be. I sum this up here:I do actually feel a bit of shame about the project at this point — of course I wish it worked better! Many people go out andfind obvious problemsin Prophet forecasts, or they build better methods and demonstrate that it is a worse method. A large number of the citations on theForecasting at scalepaper are showing it underperforming other approaches. I see no flaws with these studies, Prophet is not a reasonable model in many settings. I’m glad people are motivated to create better approaches and to do the evaluations needed to show they are superior. I wish I could definitively communicate that I never intended for Prophet to be the best and that I believe there are better options in many cases.One reason I haven’t continued to work on forecasting is because there arebetter researchersto work on it andbetterapproachesavailableto build on. But I struggle with how to “unspread” an already widely proliferated tool — I guess this post may help a bit, but ultimately it’s challenging to communicate the nuanced view that people should consider a variety of methods besides Prophet and carefully choose among them based on their requirements.Sharp edgesA running joke on Twitter is thatProphet was the causeof Zillow’s 2021 stock price collapse (some folksdidn’t really get the joke). This bit is very funny to me because it takes the “overly trusting your tools” pathology to the logical extreme:what if you bet billions of dollars on the accuracy of models you didn’t understand and didn’t evaluate properly?Yeah that would be bad!Every tool can be used in ways that result in mistakes, but with models the mistakes can maybe feel more surprising. To paraphrase some wisdom I’ve heard attributed toAndrej Karpathy:You can usually anticipate and enumerate most of the ways your model will fail to work in advance. Yet the problems you’ll encounter in practice are usually exactly one of those things you knew to watch out for, but failed to.For forecasting that common failure is to have not conducted a thorough evaluation, which has a variety of challenges (scaling computation, specifying a scalar objective you care about, extrapolation problems, etc).In my experience, fitting models and making predictions is fun and you can easily find some “good news.” But evaluating models you’ve fit is very muchnot fun, and more often leads to bad news (your new model is not better).So the mistake I will own up to is throwing one more tool into the ring (giving people a good news machine) without giving people the information or encouragement they need to evaluate it properly (giving them a bad news machine). If I could launch Prophet again, the homepage would be an explorable dashboard of model performance on a variety of tasks and including a number of common baselines, just likeErik Bernhardssonprovidesfor Annoy. People who build comparison tools like this are unsung heroes, dramatically improving the signal-to-noise ratio for practitioners choosing what to do.A spectrum of toolsTools lie on a spectrum between being so simple they can’t reasonably be blamed for mistakes (if you smash your thumb with a hammer, that’s on you) to so complex they can cause mistakes in a variety of ways (an LLM practicing law). So how much paternalism should we be applying to managing the risk of complex tools? Was part of the Prophet problem that it make forecasting too accessible?Tool builders usually want to offer a better product than existing ones, so it should be more powerful/complex. They also want it to be intuitive and usable, so it attracts a variety of users and use cases. So it sort of manufactures a situation where people potentially less equipped to detect mistakes are given the ability to make a broader range of them than they could have before.My current perspective is that the underlying problem isn’t from tools being too inherently mistake-proneorfrom attracting less discerning users. I think we introduce mistakes because it is too challenging, annoying, or cumbersome to validate our tools and compare them to alternatives. So the right question isn’t about whether specific tools should exist or not, but rather how we build trust in them and know what we should use in a given situation. The tool paternalism is misguided and most of that energy should be focused on creating the culture and incentives for checking our work.Wrapping upNow that I’m working on an analytics product atMotif, and I’m wondering what I can apply from my Prophet experience to making it more successful. I’d summarize as:Consulting with existing experts: I had underrated how much there was to be learned from existing forecasting approaches and I think Prophet would have been a more durable contribution if I had asked for more help and advice in the early phases.Be in it for the long-haul: Commit the requisite time to responding to feedback and engaging with the community. Successful tools will have long lives and you need to be able to support all your users, make them feel heard, and ensure they have the resources they need.Invite and encourage comparisons: There are usually existing ways people are approaching the tasks your tool addresses, and it will help them to understand how your approach differs and how it may lead to different results in specific situations. It behooves you to be upfront about where your tool may be worse than alternatives.Ease of installation and quality documentation work: It’s clear to me that lowering friction for people using and understanding your tools is successful at getting people to try your work. A Personal Retrospective on ProphetSean J. TaylorFollow7 min read·Jun 4, 2023--1ListenShareFebruary 2017 was a pretty exciting time for me.Ben Lethamand I were on the cusp ofopen sourcing Prophet, now a popular forecasting library but at the time just a library for internal use at Facebook. We had developed the method for a specific forecasting use-case, and then gotten a few additional wins helping internal teams improve the accuracy of their growth forecasts.The Prophet open source launch was so successful I was taken by surprise, but with hindsight we had a lot of things going for us:We were","{""viewport"": ""width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"", ""theme-color"": ""#000000"", ""twitter:app:name:iphone"": ""Medium"", ""twitter:app:id:iphone"": ""828256236"", ""al:ios:app_name"": ""Medium"", ""al:ios:app_store_id"": ""828256236"", ""al:android:package"": ""com.medium.reader"", ""fb:app_id"": ""542599432471018"", ""og:site_name"": ""Medium"", ""apple-itunes-app"": ""app-id=828256236, app-argument=/@seanjtaylor/a-personal-retrospective-on-prophet-f223c2378985, affiliate-data=ct=smart_app_banner"", ""og:type"": ""article"", ""article:published_time"": ""2023-06-13T19:26:03.032Z"", ""title"": ""A Personal Retrospective on Prophet | by Sean J. Taylor | Medium"", ""og:title"": ""A Personal Retrospective on Prophet"", ""al:android:url"": ""medium://p/f223c2378985"", ""al:ios:url"": ""medium://p/f223c2378985"", ""al:android:app_name"": ""Medium"", ""description"": ""February 2017 was a pretty exciting time for me. Ben Letham and I were on the cusp of open sourcing Prophet, now a popular forecasting library but at the time just a library for internal use at\u2026"", ""og:description"": ""February 2017 was a pretty exciting time for me. Ben Letham and I were on the cusp of open sourcing Prophet, now a popular forecasting\u2026"", ""og:url"": ""https://medium.com/@seanjtaylor/a-personal-retrospective-on-prophet-f223c2378985"", ""al:web:url"": ""https://medium.com/@seanjtaylor/a-personal-retrospective-on-prophet-f223c2378985"", ""article:author"": ""https://medium.com/@seanjtaylor"", ""author"": ""Sean J. Taylor"", ""robots"": ""index,noarchive,follow,max-image-preview:large"", ""referrer"": ""unsafe-url"", ""twitter:title"": ""A Personal Retrospective on Prophet"", ""twitter:site"": ""@Medium"", ""twitter:app:url:iphone"": ""medium://p/f223c2378985"", ""twitter:description"": ""February 2017 was a pretty exciting time for me. Ben Letham and I were on the cusp of open sourcing Prophet, now a popular forecasting\u2026"", ""twitter:card"": ""summary"", ""twitter:creator"": ""@seanjtaylor"", ""twitter:label1"": ""Reading time"", ""twitter:data1"": ""7 min read""}",,,,
https://github.com/jackboyla/GLiREL,GitHub - jackboyla/GLiREL: Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text),"jackboyla/GLiRELPublicNotificationsYou must be signed in to change notification settingsFork14Star212Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text)arxiv.org/abs/2501.03172212stars14forksBranchesTagsActivityStarNotificationsYou must be signed in to change notification settingsjackboyla/GLiRELmainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commitHistory177 Commitsconfigsconfigsdatadataexamplesexamplesglirelglirel.gitignore.gitignoreMakefileMakefileREADME.mdREADME.mdRELEASE.mdRELEASE.mddemo.jpgdemo.jpgeval.pyeval.pyeval_with_gpt.pyeval_with_gpt.pyimage.pngimage.pngpyproject.tomlpyproject.tomlquickstart.pyquickstart.pyquickstart_demo.ipynbquickstart_demo.ipynbquickstart_demo_spacy.ipynbquickstart_demo_spacy.ipynbrequirements-dev.txtrequirements-dev.txtrequirements.txtrequirements.txttrain.pytrain.pyvisualise.ipynbvisualise.ipynbView all filesRepository files navigationGLiREL : Generalist and Lightweight model for Zero-Shot Relation ExtractionGLiREL is a Relation Extraction model capable of classifying unseen relations given the entities within a text. This builds upon the excelent work done by Urchade Zaratiana, Nadi Tomeh, Pierre Holat, Thierry Charnois on theGLiNERlibrary which enables efficient zero-shot Named Entity Recognition.📄 GLiREL Paper•📄 GLiNER Paper•🤗 Demo•🤗 Available modelsInstallationpip install glirelUsageOnce you've downloaded the GLiREL library, you can import theGLiRELclass. You can then load this model usingGLiREL.from_pretrainedand predict entities withpredict_relations.fromglirelimportGLiRELimportspacymodel=GLiREL.from_pretrained(""jackboyla/glirel-large-v0"")nlp=spacy.load('en_core_web_sm')text='Derren Nesbitt had a history of being cast in ""Doctor Who"", having played villainous warlord Tegana in the 1964 First Doctor serial ""Marco Polo"".'doc=nlp(text)tokens=[token.textfortokenindoc]labels=['country of origin','licensed to broadcast to','father','followed by','characters']ner=[[26,27,'PERSON','Marco Polo'], [22,23,'Q2989412','First Doctor']]# 'type' is not used -- it can be any string!relations=model.predict_relations(tokens,labels,threshold=0.0,ner=ner,top_k=1)print('Number of relations:',len(relations))sorted_data_desc=sorted(relations,key=lambdax:x['score'],reverse=True)print(""\nDescending Order by Score:"")foriteminsorted_data_desc:print(f""{item['head_text']}-->{item['label']}-->{item['tail_text']}| score:{item['score']}"")Expected OutputNumber of relations: 2 Descending Order by Score: {'head_pos': [26, 28], 'tail_pos': [22, 24], 'head_text': ['Marco', 'Polo'], 'tail_text': ['First', 'Doctor'], 'label': 'characters', 'score': 0.9923334121704102} {'head_pos': [22, 24], 'tail_pos': [26, 28], 'head_text': ['First', 'Doctor'], 'tail_text': ['Marco', 'Polo'], 'label': 'characters', 'score': 0.9915636777877808}Constrain labelsIn practice, we usually want to define the types of entities that can exist as a head and/or tail of a relationship. This is already implemented in GLiREL:labels={""glirel_labels"": {'co-founder': {""allowed_head"": [""PERSON""],""allowed_tail"": [""ORG""]},'no relation': {},# head and tail can be any entity type'country of origin': {""allowed_head"": [""PERSON"",""ORG""],""allowed_tail"": [""LOC"",""GPE""]},'parent': {""allowed_head"": [""PERSON""],""allowed_tail"": [""PERSON""]},'located in or next to body of water': {""allowed_head"": [""LOC"",""GPE"",""FAC""],""allowed_tail"": [""LOC"",""GPE""]},'spouse': {""allowed_head"": [""PERSON""],""allowed_tail"": [""PERSON""]},'child': {""allowed_head"": [""PERSON""],""allowed_tail"": [""PERSON""]},'founder': {""allowed_head"": [""PERSON""],""allowed_tail"": [""ORG""]},'founded on date': {""allowed_head"": [""ORG""],""allowed_tail"": [""DATE""]},'headquartered in': {""allowed_head"": [""ORG""],""allowed_tail"": [""LOC"",""GPE"",""FAC""]},'acquired by': {""allowed_head"": [""ORG""],""allowed_tail"": [""ORG"",""PERSON""]},'subsidiary of': {""allowed_head"": [""ORG""],""allowed_tail"": [""ORG"",""PERSON""]}, } }Usage with spaCyYou can also load GliREL into a regular spaCy NLP pipeline. Here's an example using an English pipeline.importspacyimportglirel# Load a blank spaCy model or an existing onenlp=spacy.load('en_core_web_sm')# Add the GLiREL component to the pipelinenlp.add_pipe(""glirel"",after=""ner"")# Now you can use the pipeline with the GLiREL componenttext=""Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976. The company is headquartered in Cupertino, California.""labels={""glirel_labels"": {'co-founder': {""allowed_head"": [""PERSON""],""allowed_tail"": [""ORG""]},'country of origin': {""allowed_head"": [""PERSON"",""ORG""],""allowed_tail"": [""LOC"",""GPE""]},'licensed to broadcast to': {""allowed_head"": [""ORG""]},'no relation': {},'parent': {""allowed_head"": [""PERSON""],""allowed_tail"": [""PERSON""]},'followed by': {""allowed_head"": [""PERSON"",""ORG""],""allowed_tail"": [""PERSON"",""ORG""]},'located in or next to body of water': {""allowed_head"": [""LOC"",""GPE"",""FAC""],""allowed_tail"": [""LOC"",""GPE""]},'spouse': {""allowed_head"": [""PERSON""],""allowed_tail"": [""PERSON""]},'child': {""allowed_head"": [""PERSON""],""allowed_tail"": [""PERSON""]},'founder': {""allowed_head"": [""PERSON""],""allowed_tail"": [""ORG""]},'headquartered in': {""allowed_head"": [""ORG""],""allowed_tail"": [""LOC"",""GPE"",""FAC""]},'acquired by': {""allowed_head"": [""ORG""],""allowed_tail"": [""ORG"",""PERSON""]},'subsidiary of': {""allowed_head"": [""ORG""],""allowed_tail"": [""ORG"",""PERSON""]}, } }# Add the labels to the pipeline at inference timedocs=list(nlp.pipe([(text,labels)],as_tuples=True) )relations=docs[0][0]._.relationsprint('Number of relations:',len(relations))sorted_data_desc=sorted(relations,key=lambdax:x['score'],reverse=True)print(""\nDescending Order by Score:"")foriteminsorted_data_desc:print(f""{item['head_text']}-->{item['label']}-->{item['tail_text']}| score:{item['score']}"")Expected OutputNumber of relations: 5 Descending Order by Score: ['Apple', 'Inc.'] --> headquartered in --> ['California'] | score: 0.9854260683059692 ['Apple', 'Inc.'] --> headquartered in --> ['Cupertino'] | score: 0.9569844603538513 ['Steve', 'Wozniak'] --> co-founder --> ['Apple', 'Inc.'] | score: 0.09025496244430542 ['Steve', 'Jobs'] --> co-founder --> ['Apple', 'Inc.'] | score: 0.08805803954601288 ['Ronald', 'Wayne'] --> co-founder --> ['Apple', 'Inc.'] | score: 0.07996643334627151Example training dataNOTE that the entity indices are inclusive i.e""Binsey""is[7, 7]. This differs from spaCy where the end index is exclusive (in this case spaCy would set the indices to[7, 8])JSONL file:{""ner"": [ [7,7,""Q4914513"",""Binsey""], [11,12,""Q19686"",""River Thames""] ],""relations"": [ {""head"": {""mention"":""Binsey"",""position"": [7,7],""type"":""LOC""},# 'type' is not used -- it can be any string!""tail"": {""mention"":""River Thames"",""position"": [11,12],""type"":""Q19686""},""relation_text"":""located in or next to body of water""} ],""tokenized_text"": [""The"",""race"",""took"",""place"",""between"",""Godstow"",""and"",""Binsey"",""along"",""the"",""Upper"",""River"",""Thames"","".""] }, {""ner"": [ [9,10,""Q4386693"",""Legislative Assembly""], [1,3,""Q1848835"",""Parliament of Victoria""] ],""relations"": [ {""head"": {""mention"":""Legislative Assembly"",""position"": [9,10],""type"":""Q4386693""},""tail"": {""mention"":""Parliament of Victoria"",""position"": [1,3],""type"":""Q1848835""},""relation_text"":""part of""} ],""tokenized_text"": [""The"",""Parliament"",""of"",""Victoria"",""consists"",""of"",""the"",""lower"",""house"",""Legislative"",""Assembly"","","",""the"",""upper"",""house"",""Legislative"",""Council"",""and"",""the"",""Queen"",""of"",""Australia"","".""] }LicenseGLiRELbyJack Boylanis licensed underCC BY-NC-SA 4.0.CitationIf you use code or ideas from this project, please cite:@misc{boylan2025glirelgeneralistmodel, title={GLiREL -- Generalist Model for Zero-Shot Relation Extraction}, author={Jack Boylan and Chris Hokamp and Demian Gholipour Ghalandari}, year={2025}, eprint={2501.03172}, archivePrefix={arXiv}, primaryClass={cs.CL}, url={https://arxiv.org/abs/2501.03172}, }AboutGeneralist and Lightweight Model for Relation Extraction (Extract any relationship types from text)arxiv.org/abs/2501.03172Topicsnatural-language-processinginformation-extractionbertrelation-extractionzero-shot-learningResourcesReadmeUh oh!There was an error while loading.Please reload this page.ActivityStars212starsWatchers7watchingForks14forksReport repositoryReleases9v1.2.1LatestApr 11, 2025+ 8 releasesPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.Contributors3Uh oh!There was an error while loading.Please reload this page.LanguagesPython51.7%Jupyter Notebook48.3% Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text) Repository files navigation GLiREL : Generalist and Lightweight model for Zero-Shot Relation ExtractionGLiREL is a Relation Extraction model capable of classifying unseen relations given the entities within a text. This builds upon the excelent work done by Urchade Zaratiana, Nadi Tomeh, Pierre Holat, Thierry Charnois on theGLiNERlibrary which enables efficient zero-shot Named Entity Recognition.📄 GLiREL Paper•📄 GLiNER Paper•🤗 Demo•🤗 Available modelsInstallationpip install glirelUsageOnce you've downloaded the GLiREL library, you can import theGLiRELclass. You can then load this model usingGLiREL.from_pretrainedand predict entities withpredict_relations.fromglirelimportGLiRELimportspacymodel=GLiREL.from_pretrained(""jackboyla/glirel-large-v0"")nlp=spacy.load('en_core_web_sm')text='Derren Nesbitt had a history of being cast in ""Doctor Who"", having played villainous warlord Tegana in the 1964 First Doctor serial ""Marco Polo"".'doc=nlp(text)tokens=[token.textfortokenindoc]labels=['country of origin','licensed to broadcast to','father','followed by','characters']ner=[[26,27,'PERSON','Marco Polo'], [22,23,'Q2989412','First Doctor']]# 'type' is not used -- it can be any string!relations=model.predict_relations(tokens,labels,threshold=0.0,ner=ner,top_k=1)print('Number of relations:',len(relations))sorted_data_desc=sorted(relations,key=lambdax:x['score'],reverse=True)print(""\nDescending Or","{""route-pattern"": ""/:user_id/:repository"", ""route-controller"": ""files"", ""route-action"": ""disambiguate"", ""fetch-nonce"": ""v2:87caa7d5-c165-1aab-1fd4-eca25ade84cb"", ""current-catalog-service-hash"": ""f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb"", ""request-id"": ""B923:3EBF05:ACB15E:F31837:6839E2AD"", ""html-safe-nonce"": ""df15c727e4e349b9efaa2f6b1322734d70228998e0efd27c56cf0274f7c9253e"", ""visitor-payload"": ""eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJCOTIzOjNFQkYwNTpBQ0IxNUU6RjMxODM3OjY4MzlFMkFEIiwidmlzaXRvcl9pZCI6IjQ1NjQ0OTg2MDE3NjkyOTY1NTciLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ=="", ""visitor-hmac"": ""b86c3e12dbb09d60d23798a817704b1e609709649d6c6077ee7dcc9928aa001d"", ""hovercard-subject-tag"": ""repository:791759684"", ""github-keyboard-shortcuts"": ""repository,copilot"", ""google-site-verification"": ""Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I"", ""octolytics-url"": ""https://collector.github.com/github/collect"", ""analytics-location"": ""/<user-name>/<repo-name>"", ""viewport"": ""width=device-width"", ""description"": ""Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text) - jackboyla/GLiREL"", ""fb:app_id"": ""1401488693436528"", ""apple-itunes-app"": ""app-id=1477376905, app-argument=https://github.com/jackboyla/GLiREL"", ""twitter:image"": ""https://opengraph.githubassets.com/ad5056f509c0bcf63da636f80502c2628ed561c912b3474bcffb8acf6f9f2b74/jackboyla/GLiREL"", ""twitter:site"": ""@github"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""GitHub - jackboyla/GLiREL: Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text)"", ""twitter:description"": ""Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text) - jackboyla/GLiREL"", ""og:image"": ""https://opengraph.githubassets.com/ad5056f509c0bcf63da636f80502c2628ed561c912b3474bcffb8acf6f9f2b74/jackboyla/GLiREL"", ""og:image:alt"": ""Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text) - jackboyla/GLiREL"", ""og:image:width"": ""1200"", ""og:image:height"": ""600"", ""og:site_name"": ""GitHub"", ""og:type"": ""object"", ""og:title"": ""GitHub - jackboyla/GLiREL: Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text)"", ""og:url"": ""https://github.com/jackboyla/GLiREL"", ""og:description"": ""Generalist and Lightweight Model for Relation Extraction (Extract any relationship types from text) - jackboyla/GLiREL"", ""hostname"": ""github.com"", ""expected-hostname"": ""github.com"", ""turbo-cache-control"": ""no-preview"", ""go-import"": ""github.com/jackboyla/GLiREL git https://github.com/jackboyla/GLiREL.git"", ""octolytics-dimension-user_id"": ""70636379"", ""octolytics-dimension-user_login"": ""jackboyla"", ""octolytics-dimension-repository_id"": ""791759684"", ""octolytics-dimension-repository_nwo"": ""jackboyla/GLiREL"", ""octolytics-dimension-repository_public"": ""true"", ""octolytics-dimension-repository_is_fork"": ""false"", ""octolytics-dimension-repository_network_root_id"": ""791759684"", ""octolytics-dimension-repository_network_root_nwo"": ""jackboyla/GLiREL"", ""turbo-body-classes"": ""logged-out env-production page-responsive"", ""browser-stats-url"": ""https://api.github.com/_private/browser/stats"", ""browser-errors-url"": ""https://api.github.com/_private/browser/errors"", ""release"": ""994628876282f66f40ba0bae7848f6c92a1e1688"", ""theme-color"": ""#1e2327"", ""color-scheme"": ""light dark""}",,,,
https://www.latencyconf.io/sessions/pandas-should-go-extinct,Pandas Should Go Extinct | Latency Conference,"Pandas Should Go Extinct Just as fire was a great innovation over freezing to death, so too was Pandas a great innovation over Excel. But just as we no longer have bonfires in the middle of our houses for heating (we simply load a small dataframe into memory on windows), the time has come to move to better tools. Join me as I discuss the Polar opposite of Pandas for in-memory analytics, the database that quacks and why you probably don't need Databricks. Level 200: Experienced. Attendees should have an awareness of the topic but may not have practical experience.","{""viewport"": ""width=device-width, initial-scale=1, maximum-scale=5"", ""og:title"": ""Pandas Should Go Extinct | Latency Conference"", ""description"": ""The only local conference dedicated to building secure, high performing cloud native (or even adjacent) applications."", ""og:description"": ""The only local conference dedicated to building secure, high performing cloud native (or even adjacent) applications."", ""og:site_name"": ""Latency Conference"", ""og:type"": ""website"", ""og:url"": ""https://latencyconf.io"", ""og:image"": ""https://cdn.sanity.io/images/0th01ww5/production/6a0c79d79ae5e28e12a6c89ea8d850ac24e5819c-3963x2381.jpg"", ""astro-view-transitions-enabled"": ""true"", ""astro-view-transitions-fallback"": ""animate""}",,,,
https://orbae.adastra.eco/,Orbae,"See the land conversion impacts of agricultureOpen data, maps and insights on how your sourcing affects the EarthExplore open data See the land conversion impacts of agriculture A common language for understanding land use changeOrbae reveals what happens when agriculture expands into natural ecosystems.Working from the ground up, it calculates carbon emissions and other metrics in high resolution, then combines them to reflect any land area in the world â a farm, a country or anywhere in between. A common language for understanding land use change Orbae reveals what happens when agriculture expands into natural ecosystems. Working from the ground up, it calculates carbon emissions and other metrics in high resolution, then combines them to reflect any land area in the world â a farm, a country or anywhere in between. Clear insights for turning data into action.Prioritizeyour hotspotsTake actionat scaleTrack your progresstowards zero conversionHow it worksData built from the ground upAny time land conversion is observed from space, Orbae attributes it to the right commodity. Field per field.Find out moreOur supportersSupporters make Orbae possible.To help us keep the data open, join us.Become a supporterAll crops.Anywhere in the world.Any level of traceability.All types of land conversion.This is our ambition for Orbae.Itâs a work in progress, but weâre well on our way there.Weâre prioritizing the commodities that are well-known drivers of deforestation, then expanding to others.See what's available nowfeaturesSee your land conversion hotspots like never beforeOpen data under Creative CommonsLUC emission factors for 60+ datasets30 countries, plus subnational jurisdictions11 commodities and their productsTransparent methodologyFarm and sourcing-region data availableClear versioning and update notificationsDownloadable in ExcelEnding land conversion can't wait for perfect traceability.With Orbae, it doesn't have to.Aligned with the Greenhouse Gas Protocol and Science Based Targets initiative.Fit for reporting â and more importantly, for strategic decision making.An innovation from AdAstra Sustainability, experts in environmental accounting, data science, GIS and product development.We created Orbae because we believe that good decisions start with good data.Discover moreStart-up innovation project supported by Innosuisse, the Swiss Innovation Agency Clear insights for turning data into action.Prioritizeyour hotspotsTake actionat scaleTrack your progresstowards zero conversion How it worksData built from the ground upAny time land conversion is observed from space, Orbae attributes it to the right commodity. Field per field.Find out more Data built from the ground up Any time land conversion is observed from space, Orbae attributes it to the right commodity. Field per field. Our supportersSupporters make Orbae possible.To help us keep the data open, join us.Become a supporter Supporters make Orbae possible.To help us keep the data open, join us. All crops.Anywhere in the world.Any level of traceability.All types of land conversion.This is our ambition for Orbae.Itâs a work in progress, but weâre well on our way there.Weâre prioritizing the commodities that are well-known drivers of deforestation, then expanding to others.See what's available now Anywhere in the world. Any level of traceability. All types of land conversion. This is our ambition for Orbae. Itâs a work in progress, but weâre well on our way there. Weâre prioritizing the commodities that are well-known drivers of deforestation, then expanding to others. featuresSee your land conversion hotspots like never beforeOpen data under Creative CommonsLUC emission factors for 60+ datasets30 countries, plus subnational jurisdictions11 commodities and their productsTransparent methodologyFarm and sourcing-region data availableClear versioning and update notificationsDownloadable in Excel See your land conversion hotspots like never before Ending land conversion can't wait for perfect traceability.With Orbae, it doesn't have to.Aligned with the Greenhouse Gas Protocol and Science Based Targets initiative.Fit for reporting â and more importantly, for strategic decision making.An innovation from AdAstra Sustainability, experts in environmental accounting, data science, GIS and product development.We created Orbae because we believe that good decisions start with good data.Discover moreStart-up innovation project supported by Innosuisse, the Swiss Innovation Agency Aligned with the Greenhouse Gas Protocol and Science Based Targets initiative.Fit for reporting â and more importantly, for strategic decision making. An innovation from AdAstra Sustainability, experts in environmental accounting, data science, GIS and product development. We created Orbae because we believe that good decisions start with good data. Start-up innovation project supported by Innosuisse, the Swiss Innovation Agency 00Years00Days00hours00MinutesWhy land conversionWe have less than 5 years to stop converting landâ¨and start restoring it.Land conversion makes up an estimated 11% of global greenhouse gas emissions â the majority of which come from agriculture. The global deadline to stop forest loss and protect other natural ecosystems is set for 2030. We have less than 5 years to stop converting landâ¨and start restoring it. Land conversion makes up an estimated 11% of global greenhouse gas emissions â the majority of which come from agriculture. The global deadline to stop forest loss and protect other natural ecosystems is set for 2030. better data is hereTogether we can stop land conversion by 2030.Explore open data Together we can stop land conversion by 2030.","{""description"": ""Open data, maps and insights on how your sourcing affects the Earth. Brought to you by AdAstra Sustainability."", ""og:title"": ""Orbae"", ""og:description"": ""Open data, maps and insights on how your sourcing affects the Earth. Brought to you by AdAstra Sustainability."", ""og:image"": ""https://cdn.prod.website-files.com/65bbb359aed0115e8ec12824/67d0788be84db3cbbc64961e_26090025a8c6661b79e9e191d832d440_orbae-open-graph.webp"", ""twitter:title"": ""Orbae"", ""twitter:description"": ""Open data, maps and insights on how your sourcing affects the Earth. Brought to you by AdAstra Sustainability."", ""twitter:image"": ""https://cdn.prod.website-files.com/65bbb359aed0115e8ec12824/67d0788be84db3cbbc64961e_26090025a8c6661b79e9e191d832d440_orbae-open-graph.webp"", ""og:type"": ""website"", ""twitter:card"": ""summary_large_image"", ""viewport"": ""width=device-width, initial-scale=1""}",,,,
https://cambridge-intelligence.com/mapweave/,MapWeave - The Geospatial Visualization SDK that uncovers every connection,"MapWeaveThe geospatial visualization SDK that uncovers every connectionBuild groundbreaking apps that make geospatial connections clear, without the clutter.Unite your map, network, and timeline insights in a single view for the first time.Download the white paperWhat is MapWeave?Uniquely actionable geospatial intelligenceWeave your connected events and observations into powerful geospatial visualizations.MapWeave seamlessly integrates network, timeline and geospatial views, creating rich user experiences that uncover every connection.Geospatial insights at scaleMapWeave scales effortlessly, handling your biggest and most complex datasets with ease.Its dynamic adaptive rendering eliminates chart clutter, guiding users to the patterns, outliers and network structures they need to see, and making geospatial insights crystal clear at any zoom level.Skip the integration headacheMapWeave works seamlessly with your trusted tech stack, thanks to its flexible open architecture.Our expanding library of basemap adapters ensures compatibility with your preferred map assets, tile servers, and data services. And with interactive demos, quick-start guides and our responsive support, you’ll be up and running in no time.Want to try it for yourself?Request a free trialSolve your toughest geospatial intelligence challengesOSINT investigationsCommunications intelligenceMaritime intelligenceNetwork digital twinsCyber threat intelligenceMapWeave’s featuresTrusted byOur customers span six continents. They range from pioneering startups to Fortune 500 companies and national governments.Meet a few of our customersFrom the blogMaritime intelligence visualizationWe demonstrate graph visualization integration with Google Cloud's Spanner Graph for scalable, real-time data insightsElevate your graph and timeline data visualization: Smoother, smarter, sharperVisit the blog The geospatial visualization SDK that uncovers every connection Build groundbreaking apps that make geospatial connections clear, without the clutter. Unite your map, network, and timeline insights in a single view for the first time. Download the white paper Uniquely actionable geospatial intelligence Weave your connected events and observations into powerful geospatial visualizations. MapWeave seamlessly integrates network, timeline and geospatial views, creating rich user experiences that uncover every connection. Geospatial insights at scale MapWeave scales effortlessly, handling your biggest and most complex datasets with ease. Its dynamic adaptive rendering eliminates chart clutter, guiding users to the patterns, outliers and network structures they need to see, and making geospatial insights crystal clear at any zoom level. Skip the integration headache MapWeave works seamlessly with your trusted tech stack, thanks to its flexible open architecture. Our expanding library of basemap adapters ensures compatibility with your preferred map assets, tile servers, and data services. And with interactive demos, quick-start guides and our responsive support, you’ll be up and running in no time. Want to try it for yourself? Solve your toughest geospatial intelligence challenges Communications intelligence Maritime intelligence Network digital twins Cyber threat intelligence Our customers span six continents. They range from pioneering startups to Fortune 500 companies and national governments. Maritime intelligence visualization Maritime intelligence visualization We demonstrate graph visualization integration with Google Cloud's Spanner Graph for scalable, real-time data insights We demonstrate graph visualization integration with Google Cloud's Spanner Graph for scalable, real-time data insights Elevate your graph and timeline data visualization: Smoother, smarter, sharper Elevate your graph and timeline data visualization: Smoother, smarter, sharper Register for news & updates Registered in England and Wales with Company Number 07625370 | VAT Number 113 1740 616-8 Hills Road, Cambridge, CB2 1JP. All material © Cambridge Intelligence.Read our Privacy Policy.","{""viewport"": ""width=device-width, initial-scale=1.0"", ""google-site-verification"": ""rIWg3WSWGDBNDz2N6Up3P4Xp1gn48oNikvGmhgByaHk"", ""robots"": ""index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"", ""description"": ""Discover MapWeave: the geospatial visualization SDK that uncovers every connection. Build groundbreaking apps that make geospatial connections clear."", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""MapWeave"", ""og:description"": ""MapWeave The geospatial visualization SDK that uncovers every connection Build groundbreaking apps that make geospatial connections clear, without the"", ""og:url"": ""https://cambridge-intelligence.com/mapweave/"", ""og:site_name"": ""Cambridge Intelligence"", ""article:modified_time"": ""2025-05-15T12:57:26+00:00"", ""og:image"": ""https://cambridge-intelligence.com/wp-content/uploads/2025/05/MapWeave-featured-image-1.jpg"", ""og:image:width"": ""373"", ""og:image:height"": ""350"", ""og:image:type"": ""image/jpeg"", ""twitter:card"": ""summary_large_image"", ""twitter:site"": ""@CambridgeIntel"", ""twitter:label1"": ""Est. reading time"", ""twitter:data1"": ""4 minutes"", ""msapplication-TileImage"": ""https://cambridge-intelligence.com/wp-content/uploads/2020/06/cropped-favicon-270x270.jpg""}",,,,
https://github.com/yWorks/yfiles-jupyter-graphs-for-sparql,GitHub - yWorks/yfiles-jupyter-graphs-for-sparql: The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin.,"yWorks/yfiles-jupyter-graphs-for-sparqlPublicNotificationsYou must be signed in to change notification settingsFork1Star21The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin.www.yworks.com/jupyterLicenseMIT license21stars1forkBranchesTagsActivityStarNotificationsYou must be signed in to change notification settingsyWorks/yfiles-jupyter-graphs-for-sparqlmainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commitHistory50 Commits.github/workflows.github/workflowsexamplesexamplesimagesimagessrc/yfiles_jupyter_graphs_for_sparqlsrc/yfiles_jupyter_graphs_for_sparql.gitignore.gitignoreCODE_OF_CONDUCT.mdCODE_OF_CONDUCT.mdLICENSE.mdLICENSE.mdREADME.mdREADME.mdREADME_DEV.mdREADME_DEV.mdpyproject.tomlpyproject.tomlView all filesRepository files navigationyFiles Jupyter Graphs for SPARQLEasily visualize aSPARQLquery forRDFgraphs in a Jupyter Notebook.This packages provides an easy-to-use interface to theyFiles Graphs for Jupyterwidget to directly visualize queries.InstallationJust install it from thePython Package Indexpip install yfiles_jupyter_graphs_for_sparql==0.9.0rc1or seeREADME_DEV.mdto build it yourself.UsagefromSPARQLWrapperimportSPARQLWrapperfromyfiles_jupyter_graphs_for_sparqlimportSparqlGraphWidgetg=SparqlGraphWidget(wrapper=SPARQLWrapper(""http://dbpedia.org/sparql""))q=""""""SELECT ?sub ?p ?obWHERE {?sub ?p ?ob .}""""""g.show_query(q)SeeexamplesSupported EnvironmentsThe widget uses yFiles Graphs for Jupyter at its core, and therefore runs in any environment that is supported by it, seesupported environments.DocumentationThe main classSparqlGraphWidgetprovides the following API:ConstructorSparqlGraphWidget: Creates a new class instance with the following argumentsArgumentDescriptionDefaultlimitThe node limit which is added to all queries50wrapperA SPARQL wrapper, that is used to send queries toNonelayoutCan be used to specify a general default node and edge layout. Available algorithms are: ""circular"", ""hierarchic"", ""organic"", ""interactive_organic_layout"", ""orthogonal"", ""radial"", ""tree"", ""map"", ""orthogonal_edge_router"", ""organic_edge_router""organicFor all arguments, there is aset_[arg]andget_[arg]method.MethodsImportantIf you want to use SELECT query types, ensure you select all three triple components—subject, predicate, and object. Otherwise, a graph cannot be constructed from the selected data. For an example look at theGetting Startednotebookshow_query(query, layout: Optional[str] = None)query: Thequerythat should be visualized.layout (Optional[str]): The graph layout that is used. This overwrites the general layout in this specific graph instance. The following arguments are supported:hierarchicorganicinteractive_organic_layoutcircularcircular_straight_lineorthogonaltreeradialmaporthogonal_edge_routerorganic_edge_routerTo get an overview of the data structure, you can use the following function. The output is constrained by thelimitproperty, meaning only a partial schema may be displayed depending on the dataset.show_schema()The graph visualization can be adjusted by adding configurations to each node label or edge type with the following functions:add_subject_configuration(predicate: Union[str, list[str]], **kwargs: Dict[str, Any])predicate: The predicate of the subject this configuration should be used for.**kwargs: Visualization configuration for the given node label. The following arguments are supported:text: The text that displayed at the node. By default, the node's label is used.color: A convenience color binding for the node (see alsostylesargument).size: The size of the node.styles: A dictionary that may contain the following attributescolor,shape(one of 'ellipse', ' hexagon', 'hexagon2', 'octagon', 'pill', 'rectangle', 'round-rectangle' or 'triangle'),image.property: Allows to specify additional properties on the node, which may be bound by other bindings.type: Defines a specific ""type"" for the node as described inyFiles Graphs for Jupyterwhich affects the automatic positioning of nodes (same ""type""s are preferred to be placed next to each other).parent_configuration: Configure grouping for this node label. Seeconfigurations_example.ipynbfor examples.heat: A heat value in between 0 and 1.add_object_configuration(predicate: Union[str, list[str]], **kwargs: Dict[str, Any])predicate: The predicate of the object this configuration should be used for.**kwargs: Visualization configuration for the given node label. The following arguments are supported:text: The text that displayed at the node. By default, the node's label is used.color: A convenience color binding for the node (see alsostylesargument).size: The size of the node.styles: A dictionary that may contain the following attributescolor,shape(one of 'ellipse', ' hexagon', 'hexagon2', 'octagon', 'pill', 'rectangle', 'round-rectangle' or 'triangle'),image.property: Allows to specify additional properties on the node, which may be bound by other bindings.type: Defines a specific ""type"" for the node as described inyFiles Graphs for Jupyterwhich affects the automatic positioning of nodes (same ""type""s are preferred to be placed next to each other).parent_configuration: Configure grouping for this node label. Seeconfigurations_example.ipynbfor examples.heat: A heat value in between 0 and 1.add_predicate_configuration(type: Union[str, list[str]], **kwargs: Dict[str, Any])type: The predicate type(s) for which this configuration should be used. Supports*to address all types.**kwargs: Visualization configuration for the given predicate type. The following arguments are supported:text: The text that displayed at the edge. By default, the predicate's type is used.color: The edge's color.thickness_factor: The edge's stroke thickness factor. By default,1.property: Allows to specify additional properties on the edge, which may be bound by other bindings.heat: A heat value in between 0 and 1.add_parent_relationship_configuration(type: Union[str, list[str]], reverse: Optional[bool] = False) -> Nonetype: The predicate type that should be visualized as node grouping hierarchy instead of the actual relationship.reverse: By default the target node is considered as parent. This can be reverted with this argument.For a detailed documentation look at thecore widgetTo remove a configuration use the following functions:del_object_configuration(type): Deletes configuration for the given object predicate type.del_subject_configuration(type): Deletes configuration for the given subject predicate type.del_edge_configurations(type): Deletes configuration for the given predicate type.del_parent_predicate_configuration(type: Union[str, list[str]]) -> None: Deletes configuration for the given parent predicate type(s).How configuration bindings are resolvedThe configuration bindings (seeadd_object_configuration, add_subject_configurationoradd_predicate_configuration) are resolved as follows:If the configuration binding is a string, the package first tries to resolve it against the item's properties and uses the property value if available. If there is no property with the given key, the string value itself is used as a constant binding.In case you want to create a constant string value as binding, which also happens to be a property key, use a binding function with a constant string as return value instead.If the configuration binding is a function, the return value of the function is used as value for the respective configuration.yFiles Graphs for JupyterThe graph visualization is provided byyFiles Graphs for Jupyter, a versatile graph visualization widget for Jupyter Notebooks.It can import and visualize graphs from various popular Python packages (e.g.NetworkX,PyGraphviz,igraph) or just structurednode and edge lists.And provides a rich set of visualization options to bring your data to life (see theexample notebooks).Feature HighlightsMapping visualizationSchema visualizationGrouping visualizationHeat MappingFor a detailed feature guide, check out the main widgetexample notebooksCode of ConductThis project and everyone participating in it is governed by theCode of Conduct. By participating, you are expected to uphold this code. Please report unacceptable behavior tocontact@yworks.com.FeedbackThis widget is by no means perfect. If you find something is not working as expected we are glad to receive an issue report from you. Please make sure tosearch for existing issuesfirst and check if the issue is not an unsupported feature or known issue. If you did not find anything related, report a new issue with necessary information. Please also provide a clear and descriptive title and stick to the issue templates. Seeissues.DependenciesyFiles Graphs for JupyterLicenseSeeLICENSEfile.AboutThe open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin.www.yworks.com/jupyterTopicsvisualizationpythonsparqlrdfjupyter-notebookrdflibdiagramssparql-queryResourcesReadmeLicenseMIT licenseCode of conductCode of conductUh oh!There was an error while loading.Please reload this page.ActivityCustom propertiesStars21starsWatchers4watchingForks1forkReport repositoryReleases2v1.0.0LatestApr 3, 2025+ 1 releaseUh oh!There was an error while loading.Please reload this page.Contributors2Uh oh!There was an error while loading.Please reload this page.LanguagesPython100.0% The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin. yWorks/yfiles-jupyter-graphs-for-sparql Repository files navigation yFiles Jupyter Graphs for SPARQLEasily visualize aSPARQLquery forRDFgraphs in a Jupyter Notebook.This packages provides an easy-to-use interface to theyFiles Graphs for Jupyterwidget to directly visualize queries.InstallationJust install it from thePython Package Indexpip install yfiles_jupyter_graphs_for_sparql==0.9.0rc1or s","{""route-pattern"": ""/:user_id/:repository"", ""route-controller"": ""files"", ""route-action"": ""disambiguate"", ""fetch-nonce"": ""v2:a81839bb-82ff-1e18-17e4-9e178e7abe0a"", ""current-catalog-service-hash"": ""f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb"", ""request-id"": ""DC23:38B8D2:ABFCCC:F2C1DC:6839E2AF"", ""html-safe-nonce"": ""ac988b5440985aa7f6acdc74006ff7fb4dcd25b34e0156a0db5529b08ddb45d5"", ""visitor-payload"": ""eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJEQzIzOjM4QjhEMjpBQkZDQ0M6RjJDMURDOjY4MzlFMkFGIiwidmlzaXRvcl9pZCI6IjMwNjgxMzA3ODQ2NjIxMTkwODciLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ=="", ""visitor-hmac"": ""07de9ca67c5ebabd632745498be7e4b7ec674fdb75a38087a0d2a8893cd96a23"", ""hovercard-subject-tag"": ""repository:920152790"", ""github-keyboard-shortcuts"": ""repository,copilot"", ""google-site-verification"": ""Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I"", ""octolytics-url"": ""https://collector.github.com/github/collect"", ""analytics-location"": ""/<user-name>/<repo-name>"", ""viewport"": ""width=device-width"", ""description"": ""The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin. - yWorks/yfiles-jupyter-graphs-for-sparql"", ""fb:app_id"": ""1401488693436528"", ""apple-itunes-app"": ""app-id=1477376905, app-argument=https://github.com/yWorks/yfiles-jupyter-graphs-for-sparql"", ""twitter:image"": ""https://repository-images.githubusercontent.com/920152790/28ea3b82-242b-4f88-8873-7494feca5c66"", ""twitter:site"": ""@github"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""GitHub - yWorks/yfiles-jupyter-graphs-for-sparql: The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin."", ""twitter:description"": ""The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin. - yWorks/yfiles-jupyter-graphs-for-sparql"", ""og:image"": ""https://repository-images.githubusercontent.com/920152790/28ea3b82-242b-4f88-8873-7494feca5c66"", ""og:image:alt"": ""The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin. - yWorks/yfiles-jupyter-graphs-for-sparql"", ""og:site_name"": ""GitHub"", ""og:type"": ""object"", ""og:title"": ""GitHub - yWorks/yfiles-jupyter-graphs-for-sparql: The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin."", ""og:url"": ""https://github.com/yWorks/yfiles-jupyter-graphs-for-sparql"", ""og:description"": ""The open-source adapter for working with RDF databases and SPARQL queries in Jupyter notebooks leveraging the yFiles Graphs for Jupyter plugin. - yWorks/yfiles-jupyter-graphs-for-sparql"", ""hostname"": ""github.com"", ""expected-hostname"": ""github.com"", ""turbo-cache-control"": ""no-preview"", ""go-import"": ""github.com/yWorks/yfiles-jupyter-graphs-for-sparql git https://github.com/yWorks/yfiles-jupyter-graphs-for-sparql.git"", ""octolytics-dimension-user_id"": ""11292591"", ""octolytics-dimension-user_login"": ""yWorks"", ""octolytics-dimension-repository_id"": ""920152790"", ""octolytics-dimension-repository_nwo"": ""yWorks/yfiles-jupyter-graphs-for-sparql"", ""octolytics-dimension-repository_public"": ""true"", ""octolytics-dimension-repository_is_fork"": ""false"", ""octolytics-dimension-repository_network_root_id"": ""920152790"", ""octolytics-dimension-repository_network_root_nwo"": ""yWorks/yfiles-jupyter-graphs-for-sparql"", ""turbo-body-classes"": ""logged-out env-production page-responsive"", ""browser-stats-url"": ""https://api.github.com/_private/browser/stats"", ""browser-errors-url"": ""https://api.github.com/_private/browser/errors"", ""release"": ""994628876282f66f40ba0bae7848f6c92a1e1688"", ""theme-color"": ""#1e2327"", ""color-scheme"": ""light dark""}",,,,
https://arxiv.org/pdf/2502.13025,https://arxiv.org/pdf/2502.13025,"Agentic Deep Graph Reasoning Yields
Self-Organizing Knowledge Networks
A Preprint
Markus J. Buehler∗
Laboratory for Atomistic and Molecular Mechanics
Center for Computational Science and Engineering
Schwarzman College of Computing
Massachusetts Institute of Technology
Cambridge, MA 02139, USA
mbuehler@MIT.EDU
February 19, 2025
Abstract
Wepresentanagentic,autonomousgraphexpansionframeworkthatiterativelystructuresand
refines knowledge in situ. Unlike conventional knowledge graph construction methods relying
on static extraction or single-pass learning, our approach couples a reasoning-native large
language model with a continually updated graph representation. At each step, the system
actively generates new concepts and relationships, merges them into a global graph, and
formulatessubsequentpromptsbasedonitsevolvingstructure. Throughthisfeedback-driven
loop,themodelorganizesinformationintoascale-freenetworkcharacterizedbyhubformation,
stable modularity, and bridging nodes that link disparate knowledge clusters. Over hundreds
of iterations, new nodes and edges continue to appear without saturating, while centrality
measures and shortest path distributions evolve to yield increasingly distributed connectivity.
Our analysis reveals emergent patterns—such as the rise of highly connected “hub” concepts
and the shifting influence of “bridge” nodes—indicating that agentic, self-reinforcing graph
construction can yield open-ended, coherent knowledge structures. Applied to materials
design problems, we present compositional reasoning experiments by extracting node-specific
and synergy-level principles to foster genuinely novel knowledge synthesis, yielding cross-
domain ideas that transcend rote summarization and strengthen the framework’s potential
for open-ended scientific discovery. We discuss other applications in scientific discovery and
outline future directions for enhancing scalability and interpretability.
Keywords Artificial Intelligence · Science · Graph Theory · Category Theory · Materials Science ·
Materiomics · Language Modeling · Reasoning · Isomorphisms · Engineering
1 Introduction
Scientific inquiry often proceeds through an interplay of incremental refinement and transformative leaps,
evoking broader questions of how knowledge evolves under continual reflection and questioning. In many
accounts of discovery, sustained progress arises not from isolated insights but from an iterative process in
which prior conclusions are revisited, expressed as generalizable ideas, refined, or even reorganized as new
evidence and perspectives emerge [1]. Foundational work in category theory has formalized aspects of this
recursive structuring, showing how hierarchical representations can unify diverse knowledge domains and
enable higher-level abstractions in both the natural and social sciences [2, 3, 4]. Across engineering disciplines
∗Corresponding author.
5202
beF
81
]IA.sc[
1v52031.2052:viXra Agentic Deep Graph Reasoning
including materials science, such iterative integration of information has proven essential in synthesizing
deeply interlinked concepts.
Recent AI methods, however, often emphasize predictive accuracy and single-step outputs over the layered,
self-reflective processes that characterize human problem-solving. Impressive gains in natural language
processing, multimodal reasoning [5, 6, 7, 8, 9, 10, 11, 12], and materials science [13, 14, 15, 16, 17], including
breakthroughs in molecular biology [18] and protein folding [19, 20, 21], showcase the prowess of large-scale
models trained on vast datasets. Yet most of the early systems generate answers in a single pass, sidestepping
the symbolic, stepwise reasoning that often underpins scientific exploration. This gap has prompted a line of
research into modeling that explicitly incorporates relational modeling, reflection or multi-step inferences
[2,3,4,22,23,24,25,26,27,28],hintingatatransitionfromsingle-shotpatternrecognitiontomoreadaptive
synthesis of answers from first principles in ways that more closely resemble compositional mechanisms. Thus,
a fundamental challenge now is how can we build scientific AI systems that synthesize information rather
than memorizing it.
Graphs offer a natural substrate for this kind of iterative knowledge building. By representing concepts and
theirrelationshipsasanetwork, itbecomespossibletocapturehigher-orderstructure—suchashubs, bridging
nodes, or densely interconnected communities—that might otherwise remain implicit. This explicit relational
format also facilitates systematic expansion: each newly added node or edge can be linked back to existing
concepts, reshaping the network and enabling new paths of inference [29, 23, 27]. Moreover, graph-based
abstractions can help large language models move beyond memorizing discrete facts; as nodes accumulate and
form clusters, emergent properties may reveal cross-domain synergies or overlooked gaps in the knowledge
space.
RecentworksuggeststhatstandardTransformerarchitecturescanbeviewedasaformofGraphIsomorphism
Network (GIN), where attention operates over relational structures rather than raw token sequences [23].
Under this lens, each attention head effectively tests for isomorphisms in local neighborhoods of the graph,
offering a principled way to capture both global and local dependencies. A category-theoretic perspective
further bolsters this approach by providing a unified framework for compositional abstractions: nodes and
edgescanbetreatedasobjectsandmorphisms,respectively,whilehigher-levelconceptsemergefromfunctorial
mappings that preserve relational structure [2, 3, 4]. Taken together, these insights hint at the potential for
compositional capabilities in AI systems, where simpler building blocks can be combined and reconfigured
to form increasingly sophisticated representations, rather than relying on one-pass computations or static
ontologies. By using graph-native modeling and viewing nodes and edges as composable abstractions, such a
model may be able to recognize and reapply learned configurations in new contexts—akin to rearranging
building blocks to form unanticipated solutions. This compositional approach, strengthened by category-
theoretic insights, allows the system to not only interpolate among known scenarios but to extrapolate to
genuinely novel configurations. In effect, graph-native attention mechanisms treat interconnected concepts
as first-class entities, enabling the discovery of new behaviors or interactions that purely sequence-based
methods might otherwise overlook.
A fundamental challenge remains: How can we design AI systems that, rather than merely retrieving or
matching existing patterns, build and refine their own knowledge structures across iterations. Recent work
proposes that graphs can be useful strategies to endow AI models with relational capabilities[29, 23, 27] both
within the framework of creating graph-native attention mechanisms and by training models to use graphs as
native abstractions during learned reasoning phases. Addressing this challenge requires not only methods for
extracting concepts but also mechanisms for dynamically organizing them so that new information reshapes
what is already known. By endowing large language models with recursively expanding knowledge graph
capabilities, we aim to show how stepwise reasoning can support open-ended discovery and conceptual
reorganization. The work presented here explores how such feedback-driven graph construction may lead to
emergent,self-organizingbehaviors,sheddinglightonthepotentialfortrulyiterativeAIapproachesthatalign
more closely with the evolving, integrative nature of human scientific inquiry. Earlier work on graph-native
reasoning has demonstrated that models explicitly taught how to reason in graphs and abstractions can lead
to systems that generalize better and are more interpretable [27].
Here we explore whether we can push this approach toward ever-larger graphs, creating extensive in situ
graph reasoning loops where models spend hours or days developing complex relational structures before
responding to a task. Within such a vision, several key issues arise: Will repeated expansions naturally
preserve the network’s relational cohesion, or risk splintering into disconnected clusters? Does the continuous
addition of new concepts and edges maintain meaningful structure, or lead to saturation and redundancy?
And to what extent do bridging nodes, which may initially spark interdisciplinary links, remain influential
2 Agentic Deep Graph Reasoning
DefineInitialQuestion
(Broadquestionorspecifictopic,
e.g.,""Impact-ResistantMaterials"")
IterativeReasoningi<N
GenerateGraph-native
ReasoningTokens
<|thinking|>... <|/thinking|>
GenerateNewQuestion
ParseGraphGi
local BasedonLastExtractedAdded
(ExtractNodesandRelations) Nodes/EdgesascapturedinGi
local
MergeExtractedGraphwith
LargerGraph
(AppendNewlyAddedNodes/Edges)
G ← G ∪ Gi
local
SaveandVisualize
FinalIntegratedGraphG
Figure 1: Algorithm used for iterative knowledge extraction and graph refinement. At each iteration i, the model
generates reasoning tokens (blue). From the response, a local graph Gi is extracted (violet) and merged with
local
the global knowledge graph G (light violet). The evolving graph is stored in multiple formats for visualization and
analysis (yellow). Instead of letting the model respond to the task, a follow-up task is generated based on the latest
extracted nodes and edges in Gi (green), ensuring iterative refinement (orange), so that the model generates yet
local
more reasoning tokens, and as part of that process, new nodes and edges. The process continues until the stopping
condition i<N is met, yielding a final structured knowledge graph G (orange).
over hundreds of iterations? In the sections ahead, we investigate these questions by analyzing how our
recursively expanded knowledge graphs grow and reorganize at scale—quantifying hub formation, modular
stability, and the persistence of cross-domain c","{""description"": ""PDF document""}",,,,
https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63,Knowledge Graph(s) and LLM-based ontologies have a very good shot at unlocking GenAI in production | by EQT Ventures | eqtventures | Medium,"Multi-stage VC fund, powering the next generation of founders with the support needed to build global success stories Knowledge Graph(s) and LLM-based ontologies have a very good shot at unlocking GenAI in productionEQT VenturesFollow8 min read·Dec 19, 2024--6ListenShareBy:Julien Hobeika,Pierrick CudonnecandAlexander Fred-OjalaIn the wake of hype around ChatGPT, enterprises began dedicating budgets to generative AI (genAI) adoption. As they played around with genAI, and its potential use cases, they quickly realised that to be truly useful and effective, these models need to interact with their proprietary, “private” company data. This realization has sparked a surge of companies focused on integrating AI with enterprise data — some developing solutions to fine-tune models directly in-house, while others look to retrieval-augmented generation (RAG) as a way to incorporate company knowledge into LLM analysis and outputs.However, the deployment of “AI in production” is yet to happen. One of the main hurdles is that the quality of the data used to feed the models is lacking. Companies likeDeasieandUnstructuredare tackling this problem by focusing on metadata labelling to crack the “data foundation layer”.There is, also, another promising approach gaining attention: knowledge graphs (KGs).Graph databases are the solution to the “data foundation layer” and will unlock KGs value catch-upGraph databases have failed to capture as much value as their relational counterparts (see chart). At the scale of a single business, no graph database has achieved the same widespread adoption or impact of platforms like Snowflake or Databricks.One key reason is that relational databases power apps at scale (e.g. CRMs, ERPs etc), while graph databases do not. This is largely because no KG architecture has been able to capture and update enough data to comprehensively and accurately map a business.We believe that graph databases are the solution to enabling AI apps to move into production in the enterprise market, because they can solve the “data foundation layer” problem. The reason for this is because LLMs are a powerful way to build ontologies and semantic layers. Let’s explore why.Graph databases overcame some of the relational database limits and powered “early” AI apps, but they remain limitedWhen Leonhard Euler (1707–1783) came up with the foundation of graph theory — while trying to prove that theKönigsberg bridge problem had no solution— he likely had no idea of the immense business potential of graph databases.In the 1970s the relational database model emerged and became the dominant paradigm for decades. Relational databases excelled at handling structured tabular data — and they still do, as exemplified by Snowflake. One of the limitations of relational databases is that they struggle with complex relationships due to their reliance on joins and normalization.Enter graph databases, which represent data as nodes (entities) and edges (relationships), mirroring graph theory. Neo4j, which recently surpassed$200min ARR, is probably the most famous example of a graph database company.Graph databases are a good solution to problems that involve real-world and contextual/relationship data in domains such as supply chains, recommendation systems, and fraud detection. They often involve complex relationships that are cumbersome to model and query in traditional databases. Graph databases were designed to represent and query these relationships natively — some great startups actually use knowledge graphs as a powerful way to build their products, such asCausalyandSpread.Problems: Graph databases have failed to scale, and gen-AI use cases are still not in production in EnterprisesScaling graph databases to handle massive amounts of data is awell-documented challenge. Moreover, they are notoriously hard to productize because ofontologies. In short, ontologies define the key entities (nodes) in a domain, their attributes, and the relationships (edges) connecting them. Until LLMs came about, ontology design was largely a manual process, often handled by consultants. This manual reliance is one of the reasons whyPalantir’s Foundry, which uses a graph-based model, became valuable but was very hard to scale as a product.LLMs and transformer-based models are particularly well-suited to define ontologies. First, they excel at capturing semantic relationships (via attention mechanism). Second, LLMs are also really good at creating vector representations (embeddings) that effectively capture the hierarchical and semantic relationships (logical) between entities. And third, they’re easy to update — a must have feature for governance as well as changing fields. As a result, LLMs are a powerful way to build ontologies, enabling knowledge graphs to be built and updated much faster.After the ontology has been “cracked”, it becomes possible to infer the graph representation of an entity — be it a business unit, process or company. However, another traditional limitation of knowledge graphs lies in the definition and scaling of symbolic rules, a process that has also been largely manual. Symbolic rules refer to the logic and constraints that dictate how the elements within a graph interact. They enhance the graph’s reasoning capabilities and enable the inference of new knowledge. Just as LLMs are a powerful way to define ontologies, they are also excellent at defining symbolic rules.To recap, LLMs not only turbocharge the creation of knowledge graphs by streamlining ontology development, but are also really good at inferring the symbolic rules. What are the implications?The opportunity: Putting AI into production for the enterprise marketTaking a step back, one of the main reasons why AI has struggled to get into production in enterprises is probably the data layer. Simply put, most enterprise data, as it stands, is just not ready for LLM production. This is why companies likeDeasieare gaining traction — their focus on solving the “data foundation layer” is key to enabling LLM adoption. In the US,Unstructuredis also a strong contender, addressing the challenge that “80% of enterprise data exists in difficult-to-use formats like HTML, PDF, CSV, PNG, PPTX, and more”(as stated on their website)by extracting and transforming complex data for use with every major vector database and LLM framework.It turns out that the combination of KGs and LLMs is another compelling and potentially more powerful solution to the data foundation problem. This approach allows data to be mapped and embedded at a company or use case level, unlocking a wide range of AI and RAG use cases in the enterprise market.Why Microsoft created GraphRAG (now open source)Microsoft’s GraphRAG (now open source) uses community detection algorithms to help structure data into clusters and their relationships.As a reminder, RAG (retrieval augmented generation) is a way for a model to utilize relevant data for specific queries, without the requirement that the LLM has to have been trained on or has to remember the data. This is a powerful technique in order to ingest e.g., private and proprietary data into the LLM input prompt.Here is a simplified explanation of how RAG works:The user provides a prompt.The prompt is embedded into vectors using a pre-trained embedding model, like, BERT.The RAG application searches for similar vectors in a pre-embedded index of private data.The LLM integrates the retrieved knowledge in its input prompt and/or answerSo far, the dominant approach for RAG has beenBaselineRAG,which has a notable limitation: it struggles to connect the dots between two concepts that aresemantically distantbutlogically close. Capturing the logic that goes beyond the semantic is what KGs excel at. Enter Microsoft GraphRAG.Instead of searchingonlyfor similar text vectors, GraphRAG explores relationships in the graph (using graph embeddings or graph-specific algorithms) to retrieve connected nodes or subgraphs. In short, it captures the context and relationships much better, and is therefore well positioned to provide higher quality and more correct outputs compared to traditional RAG methods.Microsoft GraphRAG was open sourced in June 2024 (45 sec accouncement:here). However, whilst groundbreaking, it remains more of a promising solution, than a proven one that has delivered enterprise value. It seems that GraphRAG fails to scale the user inputs that enable the proper ontology definition. This limits the connections to co-occurences in documents. Setting up the semantic layer or the ontology is still somewhat cumbersome. In detail, it is resource intensive (experts, compute) -meaning it is hard to scale and maintain. It also faces difficulties to automatically decide which entities and relations are crucial. It is open source and right now doesn’t have the GtM force usually required for adoption by the enterprise market. Nevertheless, this technique has further confirmed the growing market interest for robust RAG-based solutions, validating both the timing and market appetite.There are three promising ways to solve for AI in productionMetadata labeling at scale: This approach is compelling, but metadata labelling does not necessarily capture relationship links (semantic focus that would not capture the logic).Scale AI($1bnSeries F) is probably the one of the largest companies that followed this approach. Yet, its human-based approach labeling limits its scalability (and therefore the margin profile).Building a single knowledge graph on an enterprise data lake: The second approach envisions constructing oneunique knowledge graph on top of one enterprise data lake as the solution to win the market. This is the approach of US-basedRelational AI($115m raised). In essence, this approach resolves to establish control over both the graph layer and a single semantic layer for the whole enterprise. It might be relevant in some cases, but it is alsohard to scaleand potentially not tailored enough ","{""viewport"": ""width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"", ""theme-color"": ""#000000"", ""twitter:app:name:iphone"": ""Medium"", ""twitter:app:id:iphone"": ""828256236"", ""al:ios:app_name"": ""Medium"", ""al:ios:app_store_id"": ""828256236"", ""al:android:package"": ""com.medium.reader"", ""fb:app_id"": ""542599432471018"", ""og:site_name"": ""Medium"", ""apple-itunes-app"": ""app-id=828256236, app-argument=/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63, affiliate-data=ct=smart_app_banner"", ""og:type"": ""article"", ""article:published_time"": ""2024-12-19T14:31:50.143Z"", ""title"": ""Knowledge Graph(s) and LLM-based ontologies have a very good shot at unlocking GenAI in production | by EQT Ventures | eqtventures | Medium"", ""og:title"": ""Knowledge Graph(s) and LLM-based ontologies have a very good shot at unlocking GenAI in production"", ""al:android:url"": ""medium://p/1b167533ef63"", ""al:ios:url"": ""medium://p/1b167533ef63"", ""al:android:app_name"": ""Medium"", ""description"": ""In the wake of hype around ChatGPT, enterprises began dedicating budgets to generative AI (genAI) adoption. As they played around with genAI, and its potential use cases, they quickly realised that\u2026"", ""og:description"": ""By: Julien Hobeika, Pierrick Cudonnec and Alexander Fred-Ojala"", ""og:url"": ""https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63"", ""al:web:url"": ""https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63"", ""og:image"": ""https://miro.medium.com/v2/resize:fit:1200/1*qrxO2zKjRw9aXN9CQL-fUg.png"", ""article:author"": ""https://eqtventures.medium.com"", ""author"": ""EQT Ventures"", ""robots"": ""index,noarchive,follow,max-image-preview:large"", ""referrer"": ""unsafe-url"", ""twitter:title"": ""Knowledge Graph(s) and LLM-based ontologies have a very good shot at unlocking GenAI in production"", ""twitter:site"": ""@eqtventures"", ""twitter:app:url:iphone"": ""medium://p/1b167533ef63"", ""twitter:description"": ""By: Julien Hobeika, Pierrick Cudonnec and Alexander Fred-Ojala"", ""twitter:image:src"": ""https://miro.medium.com/v2/resize:fit:1200/1*qrxO2zKjRw9aXN9CQL-fUg.png"", ""twitter:card"": ""summary_large_image"", ""twitter:creator"": ""@eqtventures"", ""twitter:label1"": ""Reading time"", ""twitter:data1"": ""8 min read""}",,,,
https://www.mongodb.com/blog/post/supercharge-ai-data-management-knowledge-graphs,Supercharge AI Data Management With Knowledge Graphs | MongoDB Blog,"Vanda AckermannFebruary 13, 2025| Updated: April 21, 2025WhyHow.AI has built andopen-sourceda platform using MongoDB, enhancing how organizations leverage knowledge graphs for data management and insights. Integrated with MongoDB, this solution offers a scalable foundation with features likevector searchand aggregation to support organizations in their AI journey.Knowledge graphs address the limitations of traditionalretrieval-augmented generation(RAG) systems, which can struggle to capture intricate relationships and contextual nuances in enterprise data. By embedding rules and relationships into a graph structure, knowledge graphs enable accurate and deterministic retrieval processes. This functionality extends beyond information retrieval: knowledge graphs also serve as foundational elements for enterprise memory, helping organizations maintain structured datasets that support future model training and insights.WhyHow.AIenhances this process by offering tools designed to combinelarge language model(LLM) workflows with Python- and JSON-native graph management. Using MongoDB’s robust capabilities, these tools help combine structured and unstructured data and search capabilities, enabling efficient querying and insights across diverse datasets. MongoDB’s modular architecture seamlessly integrates vector retrieval, full-text search, and graph structures, making it an ideal platform for RAG and unlocking the full potential of contextual data.Check out ourAI Learning Hubto learn more about building AI-powered apps with MongoDB.Creating and storing knowledge graphs with WhyHow.AI and MongoDBCreating effective knowledge graphs for RAG requires a structured approach that combines workflows from LLMs, developers, and nontechnical domain experts. Simply capturing all entities and relationships from text and relying on an LLM to organize the data can lead to a messy retrieval process that lacks utility. Instead, WhyHow.AI advocates for a schema-constrained graph creation method, emphasizing the importance of developing a context-specific schema tailored to the user’s use case. This approach ensures that the knowledge graphs focus on the specific relationships that matter most to the user’s workflow.Once the knowledge graphs are created, the flexibility of MongoDB’s schema design ensures that users are not confined to rigid structures. This adaptability enables seamless expansion and evolution of knowledge graphs as data and use cases develop. Organizations can rapidly iterate during early application development without being restricted by predefined schemas. In instances where additional structure is required, MongoDB supports schema enforcement, offering a balance between flexibility and data integrity.For instance, aligning external research with patient records is crucial to delivering personalized healthcare. Knowledge graphs bridge the gap between clinical trials, best practices, and individual patient histories. New clinical guidelines can be integrated with patient records to identify which patients would benefit most from updated treatments, ensuring that the latest practices are applied to individual care plans.Optimizing knowledge graph storage and retrieval with MongoDBHarnessing the full potential of knowledge graphs requires both effective creation tools and robust systems for storage and retrieval. Here’s how WhyHow.AI and MongoDB work together to optimize the management of knowledge graphs.Storing data in MongoDBWhyHow.AI relies on MongoDB’s document-oriented structure to organize knowledge graph data into modular, purpose-specific collections, enabling efficient and flexible queries. This approach is crucial for managing complex entity relationships and ensuring accurate provenance tracking.To support this functionality, the WhyHow.AI Knowledge Graph Studio comprises several key components:Workspacesseparate documents, schemas, graphs, and associated data by project or domain, maintaining clarity and focus.Chunksare raw text segments with embeddings for similarity searches, linked to triples and documents to provide evidence and provenance.Graph collectionstores the knowledge graph along with metadata and schema associations, all organized by workspace for centralized data management.Schemasdefine the entities, relationships, and patterns within graphs, adapting dynamically to reflect new data and keep the graph relevant.Nodesrepresent entities like people, locations, or concepts, each with unique identifiers and properties, forming the graph’s foundation.Triplesdefine subject-predicate-object relationships and store embedded vectors for similarity searches, enabling reliable retrieval of relevant facts.Querieslog user queries, including triple results and metadata, providing an immutable history for analysis and optimization.Figure 1.WhyHow.AI platform and knowledge graph illustration.To enhance data interoperability, MongoDB’s aggregation framework enables efficient linking across collections. For instance, retrieving chunks associated with a specific triple can be seamlessly achieved through an aggregation pipeline, connecting workspaces, graphs, chunks, and document collections into a cohesive data flow.Querying knowledge graphsWith the representation established, users can perform both structured and unstructured queries with the WhyHow.AI querying system. Structured queries enable the selection of specific entity types and relationships, while unstructured queries enable natural language questions to return related nodes, triples, and linked vector chunks. WhyHow.AI’s query engine embeds triples to enhance retrieval accuracy, bypassing traditional Text2Cypher methods. Through a retrieval engine that embeds triples and enables users to retrieve embedded triples with chunks tied to them, WhyHow.AI uses the best of both structured and unstructured data structures and retrieval patterns. And, with MongoDB’s built-in vector search, users can store and query vectorized text chunks alongside their graph and application data in a single, unified location.Enabling scalability, portability, and aggregationsMongoDB’s horizontal scalability ensures that knowledge graphs can grow effortlessly alongside expanding datasets. Users can also easily utilize WhyHow.AI's platform to create modular multiagent and multigraph workflows. They can deployMongoDB Atlason their preferred cloud provider or maintain control by running it in their own environments, gaining flexibility and reliability. As graph complexity increases, MongoDB’s aggregation framework facilitates diverse queries, extracting meaningful insights from multiple datasets with ease.Providing familiarity and ease of useMongoDB’s familiarity enables developers to apply their existing expertise without the need to learn new technologies or workflows. With WhyHow.AI and MongoDB, developers can build graphs with JSON data and Python-native APIs, which are perfect for LLM-driven workflows. The same database trusted for years in application development can now manage knowledge graphs, streamlining onboarding and accelerating development timelines.Taking the next stepsWhyHow.AI’s knowledge graphs overcome the limitations of traditional RAG systems by structuring data into meaningful entities, relationships, and contexts. This enhances retrieval accuracy and decision-making in complex fields. Integrated with MongoDB, these capabilities are amplified through a flexible, scalable foundation featuring modular architecture, vector search, and powerful aggregation. Together, WhyHow.AI and MongoDB help organizations unlock their data’s potential, driving insights and enabling innovative knowledge management solutions.No matter where you are in your AI journey, MongoDB can help! You can get started with your AI-powered apps by registering forMongoDB Atlasand exploring the tutorials available in ourAI Learning Hub. Otherwise, head over to ourquick-start guideto get started with MongoDB Atlas Vector Search today.Want to learn more about why MongoDB is the best choice for supporting modern AI applications? Check out our on-demand webinar, “Comparing PostgreSQL vs. MongoDB: Which is Better for AI Workloads?” presented by MongoDB Field CTO, Rick Houlihan.If your company is interested in being featured in a story like this, we’d love to hear from you. Reach out to us atai_adopters@mongodb.com.← PreviousReintroducing the Versioned MongoDB Atlas Administration APIOur MongoDB Atlas Administration API has gotten some work done in the last couple of years to become the best “Versioned” of itself. In this blog post, we’ll go over what’s changed and why migrating to the newest version can help you have a seamless experience managing MongoDB Atlas . What does the MongoDB Atlas Administration API do? MongoDB Atlas, MongoDB’s managed developer data platform, contains a range of tools and capabilities that enable developers to build their applications’ data infrastructure with confidence. As application requirements and developer teams grow, MongoDB Atlas users might want to further automate database operation management to scale their application development cycles and enhance the developer experience. The entry point to managing MongoDB Atlas in a more programmatic fashion is the legacy MongoDB Atlas Administration API. This API enables developers to manage their use of MongoDB Atlas at a control plane level. The API and its various endpoints enable developers to interact with different MongoDB Atlas resources—such as clusters, database users, or backups—and lets them perform operational tasks like creating, modifying, and deleting those resources. Additionally, the Atlas Administration API supports the MongoDB Atlas Go SDK , which empowers developers to seamlessly interact with the full range of MongoDB Atlas features and capabilities using the Go programming language. Why should I migrate to the Versioned Atlas Administration API? While it serves the same purpose as the legacy versi","{""viewport"": ""width=device-width, initial-scale=1, maximum-scale=5"", ""description"": ""Optimize AI data with WhyHow.AI and MongoDB knowledge graphs. Unlock insights, scalability, and better decision-making."", ""og:site_name"": ""MongoDB"", ""og:title"": ""Supercharge AI Data Management With Knowledge Graphs | MongoDB Blog"", ""og:description"": ""Optimize AI data with WhyHow.AI and MongoDB knowledge graphs. Unlock insights, scalability, and better decision-making."", ""og:url"": ""https://www.mongodb.com/blog/post/supercharge-ai-data-management-knowledge-graphs"", ""og:type"": ""article"", ""og:image"": ""https://webassets.mongodb.com/_com_assets/cms/Meta Image Template (1)-u5eg9cbl57.png"", ""og:image:secure_url"": ""https://webassets.mongodb.com/_com_assets/cms/Meta Image Template (1)-u5eg9cbl57.png"", ""twitter:card"": ""summary_large_image"", ""twitter:site"": ""@mongodb"", ""twitter:title"": ""Supercharge AI Data Management With Knowledge Graphs | MongoDB Blog"", ""twitter:description"": ""Optimize AI data with WhyHow.AI and MongoDB knowledge graphs. Unlock insights, scalability, and better decision-making."", ""twitter:image"": ""https://webassets.mongodb.com/_com_assets/cms/Meta Image Template (1)-u5eg9cbl57.png""}",,,,
https://enterprise-knowledge.com/the-resource-description-framework-rdf/,The Resource Description Framework (RDF) - Enterprise Knowledge,"White PaperHome:Knowledge Base:Knowledge Graphs & Data Modeling:The Resource Description Framework (RDF)The Resource Description Framework (RDF)February 24, 2025EK TeamSimply defined, a knowledge graph is a network of entities, their attributes, and how they’re related to one another. While these networks can be captured and stored in avariety of formats, most implementations leverage a graph based tool or database. However, within the world of graph databases, there are a variety of syntaxes or flavors that can be used to represent knowledge graphs. One of the most popular and ubiquitous is the Resource Description Framework (RDF), which provides a means to capture meaning, or semantics, in a way that is interpretable by both humans and machines.What is RDF?The Resource Description Framework (RDF) is a semantic web standard used to describe and model information for web resources or knowledge management systems. RDF consists of “triples,” or statements, with a subject, predicate, and object that resemble an English sentence. For example, take the English sentence: “Bess Schrader is employed by Enterprise Knowledge.” This sentence has:A subject: Bess SchraderA predicate: is employed byAn object: Enterprise KnowledgeBess Schrader and Enterprise Knowledge are two entities that are linked by the relationship “employed by.” An RDF triple representing this information would look like this:What is the goal of using RDF?RDF is asemanticweb standard, and thus has the goal of representing meaning in a way that is interpretable by both humans and machines. As humans, we process information through a combination of our experience and logical deduction. For example, I know that “Washington, D.C.” and “Washington, District of Columbia” refer to the same concept based on my experience in the world – at some point, I learned that “D.C.” was the abbreviation for “District of Columbia.” On the other hand, if I were to encounter a breathing, living object that has no legs and moves across the ground in a slithering motion, I’d probably infer that it was a snake, even if I’d never seen this particular object before. This determination would be based on the properties I associate with snakes (animal, no legs, slithers).Unlike humans, machines have no experience on which to draw conclusions, so everything needs to be explicitly defined in order for a machine to process information this way. For example, if I want a machine to infer the type of an object based on properties (e.g. “that slithering object is a snake”), I need to define what a snake is and what properties it has. If I want a machine to reconcile that “Washington, D.C.” and “Washington, District of Columbia” are the same thing, I need to define an entity that uses both of those labels.RDF allows us to create robust semantic resources, like ontologies, taxonomies, and knowledge graphs, where the meaning behind concepts is well defined in a machine readable way. These resources can then be leveraged for any use case that requires context and meaning to connect and unify data across disparate formats and systems, such assemantic layersandauto-classification.How does RDF work?Let’s go back to our single triple representing the fact that “Bess Schrader works at Enterprise Knowledge.”We can continue building out information about the entities in our (very small) knowledge graph by giving all of our subjects and objects types (which indicate the general category/class that an entity belongs to) and labels (which capture the language used to refer to the entity).These types and labels are helping us define the semantics, or meaning, of each entity. By explicitly stating that “Bess Schrader” is a person and “Enterprise Knowledge” is an organization, we’re creating the building blocks for a machine to start to make inferences about these entities based on their types.Similarly, we can create a more explicit definition of our relationship and attributes, allowing machines to better understand what the “employed by” relationship means. While the above diagram represents our predicate (or relationship) as a straight line between two entities, in RDF, our predicate is itself an entity and can have its own properties (such as type, label, and description). This is often referred to as making properties “first class citizens.”Uniform Resource Identifiers (URIs)But how do we actually make this machine readable? Diagrams in a blog are great in helping humans understand concepts, but machines need this information in a machine readable format. To make our graph machine readable, we’ll need to leverage unique identifiers.One of the key elements of any knowledge graph (RDF or otherwise) is the principle of “things, not strings.” As humans, we often use ambiguous labels (e.g. “D.C”) when referring to a concept, trusting that our audience will be able to use context to determine our meaning. However, machines often don’t have sufficient context to disambiguate strings – imagine “D.C.” has been applied as a tag to an unstructured text document. Does “D.C.” refer to the capital city of the US, the comic book publisher, “direct current,” or something else entirely? Knowledge graphs seek to reduce this ambiguity by using entities or concepts that have unique identifiers and one or more labels, instead of relying on labels themselves as unique identifiers.RDF is no exception to this principle – all RDF entities are defined using aUniform Resource Identifier (URI), which can be used to connect all of the labels, attributes, and relationships for a given entity.Using URIs, our RDF knowledge graph would look like this:These URIs make our triples machine readable by creating unambiguous identifiers for all of our subjects, predicates, and objects. URIs also enable interoperability and the ability to share information across multiple systems – because these URIs aregloballyunique, any two systems that reference the same URI should be referring to the same entity.What are the advantages to using RDF?TheRDF Specificationhas been maintained by the World Wide Web Consortium (W3C) for over two decades, meaning it is a stable, well documented framework for representing data. This makes it easy for applications and organizations to develop RDF data in an interoperable way. If you create RDF data in one tool and share it with someone else using a different RDF tool, they will still be able to easily use your data. This interoperability allows you to build on what’s already been done — you can combine yourenterprise knowledge graphwith established, open RDF datasets like Wikidata, jump-starting your analytic capabilities. This also makes data sharing and migration between internal RDF systems simple,enabling you to unify data and reducing your dependency on a single tool or vendor.The ability to treat properties as “first-class citizens” with their own properties allows you to store your data model along with your data, explaining what properties mean and how they should be used. This reduces ambiguity and confusion for both data creators, developers, and data consumers. However, this ability to treat properties as entities also allows organizations to standardize and connect existing data. RDF data models can store multiple labels for the same property, enabling them to act as a “Rosetta Stone” thattranslates metadata fields and values across systems. Connecting these disparate metadata values is crucial to being able to effectively retrieve, understand, and use enterprise data.Many implementations of RDF also support inference and reasoning, allowing you to explore previously uncaptured relationships in your data, based on logic developed in yourontology. This reasoning capability can be an incredibly powerful tool, helping you gain insights from your business logic. For example,inference and reasoning can capture information about employee expertise– a relationship that’s notoriously difficult to explicitly store. While many organizations attempt to have employees self-select their skills or areas of expertise, the completion rate of these self-selections is typically low, and even those that do complete the selection often don’t keep them up to date. Reasoning in RDF can leverage business logic to automatically infer expertise based on your organization’s data. For example, if a person has authored multiple documents that discuss a given topic, an RDF knowledge graph may infer that this person has knowledge of or expertise in that topic.What are the disadvantages to using RDF?To fully leverage the benefits of RDF, entities must be explicitly defined (see best practices below), which can require burdensome overhead. The volume and structure of these assertions, combined with the length and format ofUniform Resource Identifiers (URIs), can make getting started with RDF challenging for information professionals and developers used to working with more straightforward (albeit more ambiguous) data models. While recent advancements in generative AI have great potential to make the learning curve to RDF less onerous viahuman-in-the-loop RDF creation processes, learning to create and work with RDF still poses a challenge to many organizations.Additionally, the “triple” format (subject – predicate – object) used by RDF only allows you to connect two entities at a time, unlike labeled property graphs. For example, I can assert that “Bess Schrader -> employed by -> Enterprise Knowledge,” but it’s not very straightforward in RDF to then add additional information about that relationship, such as what role I perform at Enterprise Knowledge, my start and end dates of employment, etc. While a proposed modification to RDF calledRDF* (RDF-star)has been developed to address this, it has not been officially adopted by the W3C, and implementation of RDF* in RDF compliant tools has occurred only on an ad hoc basis.What are some best practices when using RDF to create a knowledge graph?RDF, and knowledge graphs in general, are","{""viewport"": ""width=device-width, initial-scale=1.0"", ""apple-mobile-web-app-title"": ""EK"", ""apple-mobile-web-app-status-bar-style"": ""#5A2C85"", ""theme-color"": ""#5A2C85"", ""robots"": ""index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"", ""description"": ""There are a variety of syntaxes or flavors that can be used to represent knowledge graphs. One of the most popular and ubiquitous is the Resource Description Framework (RDF), which provides a means to capture meaning, or semantics, in a way that is interpretable by both humans and machines."", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""The Resource Description Framework (RDF) - Enterprise Knowledge"", ""og:description"": ""There are a variety of syntaxes or flavors that can be used to represent knowledge graphs. One of the most popular and ubiquitous is the Resource Description Framework (RDF), which provides a means to capture meaning, or semantics, in a way that is interpretable by both humans and machines."", ""og:url"": ""https://enterprise-knowledge.com/the-resource-description-framework-rdf/"", ""og:site_name"": ""Enterprise Knowledge"", ""article:publisher"": ""https://www.facebook.com/Enterprise-Knowledge-359618484181651/"", ""article:published_time"": ""2025-02-24T19:33:53+00:00"", ""article:modified_time"": ""2025-04-14T18:32:54+00:00"", ""og:image"": ""https://enterprise-knowledge.com/wp-content/uploads/2025/02/RDF1.png"", ""author"": ""EK Team"", ""twitter:card"": ""summary_large_image"", ""twitter:creator"": ""@EKConsulting"", ""twitter:site"": ""@EKConsulting"", ""twitter:label1"": ""Written by"", ""twitter:data1"": ""EK Team"", ""twitter:label2"": ""Est. reading time"", ""twitter:data2"": ""9 minutes"", ""generator"": ""Site Kit by Google 1.147.0"", ""msapplication-TileImage"": ""https://enterprise-knowledge.com/wp-content/uploads/2022/04/EK_Icon_512x512.svg"", ""position"": ""4""}",,,,
https://medium.com/oracledevs/validating-graph-data-with-shacl-using-oracle-rdf-graph-adapter-for-eclipse-rdf4j-09327042f530,Validating Graph Data with SHACL Using Oracle RDF Graph Adapter for Eclipse RDF4J | by Matt Perry | Oracle Developers | Medium,"Aggregation of articles from Oracle engineers, Groundbreaker Ambassadors, Oracle ACEs, and Java Champions on all things Oracle technology. The views expressed are those of the authors and not necessarily of Oracle. Validating Graph Data with SHACL Using Oracle RDF Graph Adapter for Eclipse RDF4JMatt PerryFollow10 min read·Mar 5, 2025--ListenSharePhoto byMichał BożekonUnsplashData quality is a key part of any application. As such, when building an RDF graph application, a way to validate your RDF graph against a set of constraints to ensure its quality is critical. This article will look at a powerful new capability to validate RDF graphs stored in Oracle database using theEclipse RDF4JJava framework.The W3C has defined Shapes Constraint Language (SHACL) to specify constraints on RDF graphs. This is a major capability for the RDF ecosystem because it allows you to prevent pollution of your RDF graph with data that is invalid for your application. SHACL constraints are themselves expressed as RDF graphs using a specific vocabulary. These constraint graphs are called shapes graphs, and RDF graphs to be validated are called data graphs. The example shapes graph below specifies that any instance of the class:Personmust have at least one value for:nameand exactly one value for:birthDate. In addition, the object value of:namemust be of typexsd:string, and the object value of:birthDatemust be of typexsd:date.@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .@prefix sh: <http://www.w3.org/ns/shacl#> .@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .@prefix : <http://www.example.oracle.com/rdf#> .:PersonShapea sh:NodeShape ;sh:targetClass :Person ;sh:property [sh:path :name ;sh:minCount 1 ;sh:datatype xsd:string ;] ;sh:property [sh:path :birthDate ;sh:minCount 1 ;sh:maxCount 1 ;sh:datatype xsd:date ;] .Eclipse RDF4Jis a popular Java framework for building RDF graph applications, and Oracle has recently (January 2025) released an update of Oracle RDF Graph Adapter for Eclipse RDF4J. This update brings the supported version of Eclipse RDF4J from 4.2.1 to 4.3.14 and includes support forSHACL validation of RDF graphs stored in Oracle Database.The remainder of this article will show, through a step-by-step example, how to validate an RDF graph stored in Oracle Autonomous Database with Java code.Step 1: Prepare an Oracle Autonomous Database InstanceThis step will cover how to prepare your autonomous database for Oracle RDF Graph Adapter for Eclipse RDF4J. Please seeProvision an Autonomous Database Instancefor details on how to provision an autonomous database instance.We first need to create a non-admin user for our RDF application. We will use RDFUSER for this example. On the Autonomous Database Details page in the OCI Web Console, select Database Users from the Database actions drop down menu.Ensure that your application user has some quota on the DATA tablespace. You should enable Web Access for your user, and you can optionally enable Graph and OML.Next, we need to create an RDF network in RDFUSER’s schema. Log the ADMIN user out of Database Actions and log back in as your application user. Then open a SQL Worksheet from Database Actions.Execute the following SQL statement to create a semantic network named RDF_NETWORK owned by RDFUSER.exec sem_apis.create_sem_network('DATA', network_owner=>'RDFUSER', network_name=>'RDF_NETWORK');You will need to download a Wallet to use later for a JDBC connection. Click Database connection from the Autonomous Database details page.Download an Instance wallet and give a password when prompted on the subsequent page.Step 2: Prepare the Oracle RDF Graph Adapter for Eclipse RDF4J EnvironmentThis step sets up the environment for using Oracle RDF Graph Adapter for Eclipse RDF4J. As a prerequisite, ensure that you have a recent version of Java JDK 11 configured in your environment.First, download the latest Oracle RDF4J Adapter from Oracle Software Delivery Cloud. Search for “rdf4j” on the landing page.Click “REL: Oracle Adapter for Eclipse RDF4J 22.4.0.0” and then click continue. Select GENERIC for Platforms / Languages then click continue.Accept the Terms and Restrictions and then click on the file to download (V1047295–01.zip).Unzip V1047295–01.zip[user@localhost rdf4j_adapter]$ unzip V1047295-01.zipArchive: V1047295-01.zipcreating: jar/inflating: jar/oracle-rdf4j-adapter-4.3.14-20250106.jarinflating: jar/sdordf-23.6.0-20241122.jarinflating: jar/sdordf-client-23.6.0-20241122.jarinflating: jar/sdoutl-23.6.0-20241122.jarcreating: bin/inflating: bin/orardfldrcreating: javadoc/creating: javadoc/oracle/creating: javadoc/oracle/rdf4j/creating: javadoc/oracle/rdf4j/adapter/inflating: javadoc/oracle/rdf4j/adapter/Attachment.htmlinflating: javadoc/oracle/rdf4j/adapter/OracleDB.htmlinflating: javadoc/oracle/rdf4j/adapter/OracleIndexManager.html…inflating: javadoc/jquery/images/ui-icons_222222_256x240.pnginflating: javadoc/jquery/images/ui-bg_glass_75_e6e6e6_1x400.pngThere should be bin, jar, and javadoc directories, and jar should contain four jar files.[user@localhost rdf4j_adapter]$ lsbin jar javadoc V1047295-01.zip[user@localhost rdf4j_adapter]$ ls jar/oracle-rdf4j-adapter-4.3.14-20250106.jar sdordf-client-23.6.0-20241122.jarsdordf-23.6.0-20241122.jar sdoutl-23.6.0-20241122.jarCreate a directory for your RDF4J Java project. We are using RDF4J_SHACL_ADW in this example. Create a lib directory under RDF4J_SHACL_ADW to hold the jar files needed for the project. Copy the jars from Oracle RDF4J Adapter to the lib directory.[user@localhost RDF4J_SHACL_ADW]$ mkdir lib[user@localhost RDF4J_SHACL_ADW]$ cp /tmp/rdf4j_adapter/jar/*.jar ./lib[user@localhost RDF4J_SHACL_ADW]$ ls lib/oracle-rdf4j-adapter-4.3.14-20250106.jar sdordf-client-23.6.0-20241122.jarsdordf-23.6.0-20241122.jar sdoutl-23.6.0-20241122.jarNext, download the required jars for RDF4J and copy them to lib.• eclipse-rdf4j-4.3.14-onejar.jar (https://download.eclipse.org/rdf4j/)• commons-io-2.14.0.jar (https://repo.maven.apache.org/maven2/commons-io/commons-io/2.14.0/)• log4j-core-2.24.2.jar (https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-core/2.24.2/)• log4j-api-2.24.2.jar (https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-api/2.24.2/)• log4j-slf4j-impl-2.24.2.jar (https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-slf4j-impl/2.24.2/)• slf4j-api-1.7.36.jar (https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.36/)• guava-32.1.3-jre.jar (https://repo1.maven.org/maven2/com/google/guava/guava/32.1.3-jre/)• listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar (https://repo1.maven.org/maven2/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/)• failureaccess-1.0.1.jar (https://repo1.maven.org/maven2/com/google/guava/failureaccess/1.0.1/)Lastly, download JDBC jars for autonomous database. Download ojdbc8-full.tar.gz for Oracle Database 23ai fromhttps://www.oracle.com/database/technologies/appdev/jdbc-downloads.html.Unzip and then copy the following jars from the bundle to lib.• ojdbc8.jar• ucp.jar• oraclepki.jarThe final contents of the lib directory should be as follows.[user@localhost lib]$ lscommons-io-2.14.0.jareclipse-rdf4j-4.3.14-onejar.jarfailureaccess-1.0.1.jarguava-32.1.3-jre.jarlistenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jarlog4j-api-2.24.2.jarlog4j-core-2.24.2.jarlog4j-slf4j-impl-2.24.2.jarojdbc8.jaroraclepki.jaroracle-rdf4j-adapter-4.3.14-20250106.jarsdordf-23.6.0-20241122.jarsdordf-client-23.6.0-20241122.jarsdoutl-23.6.0-20241122.jarslf4j-api-1.7.36.jarucp.jarStep 3: Using Oracle RDF Graph Adapter for Eclipse RDF4J to Validate RDF DataThe Java code shown below illustrates how to use Oracle RDF4J Adapter to insert RDF data into Oracle Autonomous Database and then validate it against a SHACL shapes graph. It first adds a simple data graph to a newly created RDF Graph calledDATA_GRAPH1in the schema-private RDF network calledRDF_NETWORK. Then it uses theOracleShaclSailclass to run a transaction againstDATA_GRAPH1. RDF4J’s SHACL support evaluates SHACL constraints when transactions are committed. This transaction first loads the SHACL shapes graph from our earlier example, and when we commit the shapes graph insertion, a bulk SHACL validation runs againstDATA_GRAPH1, which contains our data graph. A SHACL validation report is then printed if any violations were found. Note thatOracleShaclSailuses the database’s SQL engine to evaluate these constraints in the database itself, giving a scalable implementation that can make full use of Oracle’s advanced features (parallelism, smart scan, etc.).In this example, we loaded our data graph into Oracle RDF Graph with RDF4J APIs. However, this is not a required workflow. The data graph could be a pre-existing RDF graph that was loaded through a variety of other methods such asbulk load,Graph Studio,RDF Server, etc.import java.io.IOException;import java.io.PrintStream;import java.io.StringReader;import java.sql.SQLException;import org.eclipse.rdf4j.common.exception.ValidationException;import org.eclipse.rdf4j.model.Model;import org.eclipse.rdf4j.model.vocabulary.RDF4J;import org.eclipse.rdf4j.repository.Repository;import org.eclipse.rdf4j.repository.RepositoryConnection;import org.eclipse.rdf4j.repository.RepositoryException;import org.eclipse.rdf4j.repository.sail.SailRepository;import org.eclipse.rdf4j.repository.sail.SailRepositoryConnection;import org.eclipse.rdf4j.rio.RDFFormat;import org.eclipse.rdf4j.rio.RDFParseException;import org.eclipse.rdf4j.rio.Rio;import org.eclipse.rdf4j.rio.WriterConfig;import org.eclipse.rdf4j.rio.helpers.BasicWriterSettings;import org.eclipse.rdf4j.sail.shacl.ShaclSail;import oracle.rdf4j.adapter.OracleDB;import oracle.rdf4j.adapter.OraclePool;import oracle.rdf4j.adapter.OracleRepository;import oracle.rdf4j.adapter.OracleSailStore;import oracle.rdf4j.adapter.shacl.OracleShaclSail;import oracle.rdf4j.","{""viewport"": ""width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"", ""theme-color"": ""#000000"", ""twitter:app:name:iphone"": ""Medium"", ""twitter:app:id:iphone"": ""828256236"", ""al:ios:app_name"": ""Medium"", ""al:ios:app_store_id"": ""828256236"", ""al:android:package"": ""com.medium.reader"", ""fb:app_id"": ""542599432471018"", ""og:site_name"": ""Medium"", ""apple-itunes-app"": ""app-id=828256236, app-argument=/oracledevs/validating-graph-data-with-shacl-using-oracle-rdf-graph-adapter-for-eclipse-rdf4j-09327042f530, affiliate-data=ct=smart_app_banner"", ""og:type"": ""article"", ""article:published_time"": ""2025-03-05T15:43:13.586Z"", ""title"": ""Validating Graph Data with SHACL Using Oracle RDF Graph Adapter for Eclipse RDF4J | by Matt Perry | Oracle Developers | Medium"", ""og:title"": ""Validating Graph Data with SHACL Using Oracle RDF Graph Adapter for Eclipse RDF4J"", ""al:android:url"": ""medium://p/09327042f530"", ""al:ios:url"": ""medium://p/09327042f530"", ""al:android:app_name"": ""Medium"", ""description"": ""Data quality is a key part of any application. As such, when building an RDF graph application, a way to validate your RDF graph against a set of constraints to ensure its quality is critical. This\u2026"", ""og:description"": ""Data quality is a key part of any application. As such, when building an RDF graph application, a way to validate your RDF graph against a\u2026"", ""og:url"": ""https://medium.com/oracledevs/validating-graph-data-with-shacl-using-oracle-rdf-graph-adapter-for-eclipse-rdf4j-09327042f530"", ""al:web:url"": ""https://medium.com/oracledevs/validating-graph-data-with-shacl-using-oracle-rdf-graph-adapter-for-eclipse-rdf4j-09327042f530"", ""og:image"": ""https://miro.medium.com/v2/da:true/resize:fit:1200/0*rovdehA8cOqVn1mv"", ""article:author"": ""https://medium.com/@matperry"", ""author"": ""Matt Perry"", ""robots"": ""index,noarchive,follow,max-image-preview:large"", ""referrer"": ""unsafe-url"", ""twitter:title"": ""Validating Graph Data with SHACL Using Oracle RDF Graph Adapter for Eclipse RDF4J"", ""twitter:site"": ""@OracleDevs"", ""twitter:app:url:iphone"": ""medium://p/09327042f530"", ""twitter:description"": ""Data quality is a key part of any application. As such, when building an RDF graph application, a way to validate your RDF graph against a\u2026"", ""twitter:image:src"": ""https://miro.medium.com/v2/da:true/resize:fit:1200/0*rovdehA8cOqVn1mv"", ""twitter:card"": ""summary_large_image"", ""twitter:label1"": ""Reading time"", ""twitter:data1"": ""10 min read""}",,,,
https://blog.kuzudb.com/post/kuzu-wasm-rag/,Fully In-Browser Graph RAG with Kuzu-Wasm,"Fully In-Browser Graph RAG with Kuzu-WasmChang LiuDevOps Engineer & Co-founder of Kùzu Inc.Semih SalihoğluCEO of Kùzu Inc. & Associate Prof. at UWaterlooMar 10, 2025exampleWe’re excited that members of our community are already building applications with theWebAssembly (Wasm)version of Kuzu, which was only released a few weeks ago! Early adopters to integrate Kuzu-Wasm includeAlibaba Graphscope, see:1and2, andKineviz, whose project will be launched soon.In this post, we’ll showcase the potential of Kuzu-Wasm by building a fully in-browser chatbot that answers questions over LinkedIn data using an advanced retrieval technique: Graph Retrieval-Augmented Generation (Graph RAG). This is achieved using Kuzu-Wasm alongsideWebLLM, a popular in-browser LLM inference engine that can run LLMs inside the browser.A quick introduction to WebAssemblyWebAssembly (Wasm) has transformed browsers into general-purpose computing platforms. Many fundamental software components, such as full-fledged databases, machine learning libraries, data visualization tools, and encryption/decryption libraries, now have Wasm versions. This enables developers to build advanced applications that run entirely in users’ browsers—without requiring backend servers. There are several benefits for building fully in-browser applications:Privacy: Users’ data never leaves their devices, ensuring complete privacy and confidentiality.Ease of Deployment: An in-browser application that uses Wasm-based components can run in any browser in a completely serverless manner.Speed: Eliminating frontend-server communication can lead to a significantly faster and more interactive user experience.With this in mind, let’s now demonstrate how to develop a relatively complex AI application completely in the browser! We’ll build afully in-browserchatbot that uses graph retrieval- augmented generation (Graph RAG) to answer natural language questions. We demonstrate this usingKuzu-WasmandWebLLM.ArchitectureThe high-level architecture of the application looks as follows:The term “Graph RAG” is used to refer to several techniques but in its simplest form the term refers to a 3-step retrieval approach. The goal is to retrieve useful context from a graph DBMS (GDBMS) to help an LLM answer natural language questions. In our application, the additional data is information about a user’s LinkedIn data consisting of their contacts, messages, companies the user or their contacts worked for. Yes, you can downloadyour own LinkedIn data(and you should, if for nothing else, to see how much of your data they have!). The schema of the graph database we use to model this data will be shown below momentarily. First, let’s go over the 3 steps of Graph RAG:QNL_{NL}NL​→\rightarrow→QCypher_{Cypher}Cypher​: A user asks a natural language question QNL_{NL}NL​, such as “Which of my contacts work at Google?“. Then, using an LLM, this question is converted to a Cypher query, e.g.,MATCH (a:Company)<-[:WorksAt]-(b:Contact) WHERE a.name = ""Google"" RETURN b, that aims to retrieve relevant data stored in the GDBMS to answer this question.QCypher_{Cypher}Cypher​→\rightarrow→Context: QCypher_{Cypher}Cypher​is executed in the GBMS and a set of records is retrieved, e.g., “Karen” and “Alice”. Let’s call these retrieved records “Context”.(QNL_{NL}NL​+ Context)→\rightarrow→ANL_{NL}NL​: Finally, the original QNL_{NL}NL​is given to the LLM along with the retrieved context and the LLM produces a natural language answer ANL_{NL}NL​, e.g., “Karen and Alice work at Google.”ImplementationData IngestionThe schema for our personal LinkedIn data’s graph is shown below:We ingest the data into Kuzu-Wasm in several steps using custom JavaScript code (see thesrc/utils/LinkedInDataConverter.jsfile in our Github repo):Upload CSV Files: Users drag and drop their LinkedIn CSV files, which are stored in Kuzu-Wasm’s virtual file system.Initial Processing: Using Kuzu’sLOAD FROMfeature, the raw CSVs are converted into JavaScript objects.Normalization: In JavaScript, we clean and standardize the data by fixing timestamps, formatting dates, and resolving inconsistent URIs.Data Insertion: The cleaned data is inserted back into Kuzu-Wasm as a set of nodes and relationships.WebLLM PromptingOur code follows the exact 3 steps above. Specifically, we prompt WebLLM twice, once to create a Cypher query QCypher_{Cypher}Cypher​, which is sent to Kuzu-Wasm. We adapted the prompts from ourLangChain-Kuzu integration, with a few modifications. Importantly, we make sure to include the schema information of the LinkedIn database from Kuzu in the prompt, which helps the LLM better understand the structure and relationships (including the directionality of the relationships) in the dataset.In this example, we represented the schema as YAML instead of raw, stringified JSON in the LLM prompt. In our anecdotal experience, for Text-to-Cypher tasks that require reasoning over the schema, we find that LLMs tend do better with YAML syntax than they do with stringified JSON. More experiments on such Text-to-Cypher tasks will be shown in future blog posts.ObservationsIt’s indeed impressive to see such a graph-based pipeline with LLMs being done entirely in the browser! There are, however, some caveats. Most importantly, in the browser, resources are restricted, which limits the sizes of different components of your application. For example, the size of the LLM you can use is limited. We tested our implementation on a MacBook Pro 2023 and a Chrome browser. We had to choose theLlama-3.1-8B-Instruct-q4f32_1-MLCmodel (seeherefor the model card), which is an instruction-tuned model in MLC format. Theq4f32_1format is the smallest of the Llama 3.1 models that has 8B parameters (the largest has 450B parameters, which is of course too large to run in the browser). For simple queries, the model performed quite well. It correctly generated Cypher queries for the LinkedIn data, such as:How many companies did I follow?Which contacts work at Kùzu, Inc?Which skills do I have?However, we saw that for more complex queries requiring joins, filtering, and aggregation, the model struggled to return a valid Cypher query. It often produced incorrect or incomplete Cypher queries for questions like: “Who endorsed me the most times?“. Token generation is also far slower than what you may be used to in state-of-the art interfaces, such as ChatGPT. In our experiments, we observed a speed of 15-20 tokens/sec, so generating answers took on average, around 10s.Live demoWe have deployed this demo so you can test it in your browser:Live Demo: Drag and drop yourLinkedIn data dumpinto the app and start querying your personal graph. The demo also visualizes your data in a node-link graph view usingvis.jsGitHub Repository: The source code is openly available so you can experiment with it further. If you see better results with different models/prompts, we’d love to hear it!Once the data is loaded, you can see a visualization that looks something like this:TakeawaysThe key takeaway from this post is that such advanced pipelines that utilize graph databases and LLMs are now possibleentirely in the browser. We expect that many of the performance limitations of today will improve over time, with the wider adoption ofWebGPU,Wasm64, and otherproposalsto improve Wasm. LLMs are also rapidly getting smaller & better, and before we know it, it will be possible to use very advanced LLMs in the browser. The next release of Kuzu will include a native vector index (it’s already available in our nightly build; seethis PRfor how to use it!). As a result, you can also store the embeddings of documents along with actual node and relationship records to enhance your graph retrievals, entirely within Kuzu. Using our upcoming vector index, you’ll be able to try all sorts of interesting RAG techniques, coupled with Kuzu-Wasm, all within the browser while keeping your data private. The sky is the limit!#kuzu#cypher#graph#rag#wasm#llm Fully In-Browser Graph RAG with Kuzu-WasmChang LiuDevOps Engineer & Co-founder of Kùzu Inc.Semih SalihoğluCEO of Kùzu Inc. & Associate Prof. at UWaterlooMar 10, 2025exampleWe’re excited that members of our community are already building applications with theWebAssembly (Wasm)version of Kuzu, which was only released a few weeks ago! Early adopters to integrate Kuzu-Wasm includeAlibaba Graphscope, see:1and2, andKineviz, whose project will be launched soon.In this post, we’ll showcase the potential of Kuzu-Wasm by building a fully in-browser chatbot that answers questions over LinkedIn data using an advanced retrieval technique: Graph Retrieval-Augmented Generation (Graph RAG). This is achieved using Kuzu-Wasm alongsideWebLLM, a popular in-browser LLM inference engine that can run LLMs inside the browser.A quick introduction to WebAssemblyWebAssembly (Wasm) has transformed browsers into general-purpose computing platforms. Many fundamental software components, such as full-fledged databases, machine learning libraries, data visualization tools, and encryption/decryption libraries, now have Wasm versions. This enables developers to build advanced applications that run entirely in users’ browsers—without requiring backend servers. There are several benefits for building fully in-browser applications:Privacy: Users’ data never leaves their devices, ensuring complete privacy and confidentiality.Ease of Deployment: An in-browser application that uses Wasm-based components can run in any browser in a completely serverless manner.Speed: Eliminating frontend-server communication can lead to a significantly faster and more interactive user experience.With this in mind, let’s now demonstrate how to develop a relatively complex AI application completely in the browser! We’ll build afully in-browserchatbot that uses graph retrieval- augmented generation (Graph RAG) to answer natural language questions. We demonstrate this usingKuzu-WasmandWebLLM.ArchitectureThe high-level architecture of the applicatio","{""theme-name"": ""bookworm-light-astro"", ""msapplication-TileColor"": ""#000000"", ""theme-color"": ""#fff"", ""generator"": ""Astro v4.0.7"", ""viewport"": ""width=device-width, initial-scale=1, maximum-scale=5"", ""title"": ""Fully In-Browser Graph RAG with Kuzu-Wasm"", ""description"": ""We demonstrate a fully in-browser Graph RAG-based chatbot that uses Kuzu-Wasm and WebLLM. The chatbot answers natural language questions over your LinkedIn data.  This post highlights the potential of fully-local knowledge graph-powered AI applications."", ""author"": ""K\u00f9zu Inc."", ""og:title"": ""Fully In-Browser Graph RAG with Kuzu-Wasm"", ""og:description"": ""We demonstrate a fully in-browser Graph RAG-based chatbot that uses Kuzu-Wasm and WebLLM. The chatbot answers natural language questions over your LinkedIn data.  This post highlights the potential of fully-local knowledge graph-powered AI applications."", ""og:type"": ""website"", ""og:url"": ""https://blog.kuzudb.com/post/kuzu-wasm-rag/"", ""og:image"": ""https://blog.kuzudb.com/img/2025-02-27-kuzu-wasm-rag/landing-page.png"", ""og:image:width"": ""128"", ""og:image:height"": ""128"", ""twitter:image"": ""https://blog.kuzudb.com/img/2025-02-27-kuzu-wasm-rag/landing-page.png"", ""twitter:title"": ""Fully In-Browser Graph RAG with Kuzu-Wasm"", ""twitter:description"": ""We demonstrate a fully in-browser Graph RAG-based chatbot that uses Kuzu-Wasm and WebLLM. The chatbot answers natural language questions over your LinkedIn data.  This post highlights the potential of fully-local knowledge graph-powered AI applications."", ""twitter:card"": ""summary_large_image"", ""astro-view-transitions-enabled"": ""true"", ""astro-view-transitions-fallback"": ""animate""}",,,,
https://blog.kuzudb.com/post/unstructured-data-to-graph-baml-kuzu/,Transforming unstructured data to a graph with BAML and Kuzu,"Transforming unstructured data to a graph with BAML and KuzuPrashanth RaoAI Engineer at Kùzu Inc.Mar 14, 2025exampleOne of the primary use cases for a property graph database like Kuzu is to explicitly model relationships between entities in your data. However, as anyone who has worked with real-world data can attest, the vast majority of data out there is not naturally clean or structured, and may be stored in a variety of unstructured formats like text files, PDF files, images and more. Historically, this has created a barrier to graph database adoption due to the challenge of reliably extracting entities (nodes) and the relationships (edges) between them from the unstructured data.It’s amply clear these days that LLMs are proving to be powerful and versatile at a large variety of tasks. In this post, we will show how to use Kuzu in combination withBAML, a domain-specific language for generating clean, structured outputs from LLMs, to help transform the unstructured data into a graph that can be used for downstream analysis and RAG. Using tools like BAML can help increase trust in your LLMs’ outputs by adding some much-needed engineering rigour downstream of the generation process. We’ll also look at some evaluation results to validate the quality and robustness of several LLMs’ outputs. The key steps in the overall workflow are summarized in the diagram below:We start with unstructured data upstream (it could be text, images, PDFs, etc.). BAML is used to prompt the LLM to generate a structured output in JSON format, which can then be persisted as a graph in a Kuzu database. Let’s understand this in more detail through a concrete example.Problem statementConsider this scenario: You are a developer working at a healthcare firm that has custom, proprietary data on drugs, including their generic names, brand names, side effects and the conditions they are used to treat. Additionally, you have a dataset of clinical notes taken by physicians that mention the side effects experienced by patients taking these drugs.The two datasets are stored in two entirely different formats: The data on drugs is stored in a PDF file1that contains tables with nested information, and the clinical notes are stored in plain text, output from a custom EMR system. Let’s take a closer look at the table inside the PDF file. There’ssomedegree of structure to the data, but it’s far from clean and consistent, and the presence of nested structures (comma-separated items, bullet points, etc.) in each make it non-trivial to extract clean data programmatically.Our task: Bring these two otherwise separate datasets together to construct a knowledge graph that can be queried downstream to answer questions about patients, drugs and their side effects.MethodologyWe could go about transforming the PDF data into a structured form in a number of ways. The most obvious approach would be to use a PDF parsing library likePyMuPDForpdfplumberto extract the data as text, and then prompt an LLM to extract entities and relationships from the text. However, this approach requires a lot of custom code to handle the idiosyncrasies of the nested data shown above, and even then, the output isn’t guaranteed to be clean and consistent enough for an LLM to reason over.A simpler and quicker way is to use a multimodal LLM like OpenAI’sgpt-4o, or its smaller cousingpt-4o-minithat take in images as input. We can use BAML to prompt these models to extract the relevant entities and relationships from animageof each page of the PDF, rather than writing a ton of custom code to preprocess the data as text. This approach of extracting entities and relationships from images is surprisingly effective, in terms of cost, quality and speed, as we’ll see below!Here’s a visual breakdown of the methodology:Let’s walk through the key steps in the following sections.1. PDF -> ImageThis simple FastAPI appis used to transform the PDF data of drugs into a series of PNG images2. The images are transformed to their base64-encoded string representations, which multimodal LLMs likegpt-4o-minican interpret well. Because each page of the PDF is represented as a separate image, we can easily scale up this approach to handle PDFs with far more pages than what’s shown in this example, concurrently processing each page to speed things up.The text data (clinical notes) is left as is, because it’s already in a clean text format that can read by an LLM.2. Extract structured data using BAMLWe are now ready to prompt the LLM to extract entities and relationships from the image and text files. In this section, we’ll break down the BAML prompts that are used for each task: information extraction from images and text.Graph schemaThe preliminary step, prior to any LLM prompting, is to sketch out a graph schema that we will use to model our domain. This is what informs our BAML schema design, shown further below.In the PDF data, each drug has a generic name and (optionally) a brand name. Each class of drugs has a set of side effects, and are used to treat a particular condition. This is all captured in the graph schema shown above. We model two kinds of drug nodes:DrugGenericandDrugBrand. Each side effect is modelled as aSymptomnode, and a particularConditionis treated by aDrugGenericnode.Additionally, the text of clinical notes consists of patients who experience side effects while taking a drug. This is captured through thePatientnode and theEXPERIENCESrelationship to theSymptomnode. Our schema design effectively combines these two separate datasets into a single graph in Kuzu!Extract from imagesBAML is a domain-specific language (DSL) that ensures type safety of an LLM’s output, providing quality structured outputs that respect the desired schema. The BAML schema (or data model) is defined in a way that aligns with the expectations of our Kuzu graph schema that’s shownabove.classDrug{generic_name stringbrand_names string[]@description(""Strip the ® character at the end of the brand names"")}classConditionAndDrug{condition stringdrugDrug[]side_effects string[]}In BAML, aclassis basically a data model that specifies the overall structure of the data (and its field types) that we want to extract. In this case, we want to extract aConditionAndDrugobject, which contains aconditionstring, an array ofDrugobjects, and an array ofside_effectsstrings. The@descriptionannotation is used to provide a hint to the LLM about how to populate the data for thebrand_namesfield.Prompts in BAML are specified asfunctions. Here’s the prompt for extracting the condition, drug names and side effects from the image of the PDF table:functionExtractFromImage(img:image)->ConditionAndDrug[]{clientOpenRouterGpt4oMiniprompt #""You are an expert at extracting healthcare and pharmaceutical information.Extract the condition, drug names and side effects from the provided table with these columns:- Reason for drug- Drug names: Generic name & (Brand name)- Side effects{{ctx.output_format}}{{ _.role(""user"") }}{{img}}""#}Every prompt consists of an LLM client (we use an OpenRouteropenai/gpt-4o-minialias here), and a prompt template that specifies the system and user prompts via a Jinja template. Thectx.output_formatis a special variable that transforms the BAML classes (data models) into a JSON-like representation with hints injected at appropriate locations, to guide the LLM towards generating a valid output. Here’s what the actual prompt looks like once it’s formatted by BAML:You are an expert at extracting healthcare and pharmaceutical information.Extract the condition, drug names and side effects from the provided table with these columns:- Reason for drug- Drug names: Generic name & (Brand name)- Side effectsAnswer with a JSON Array using this schema:[{condition: string,drug: [{generic_name: string,// Strip the ® character at the end of the brand namesbrand_names: string[],}],side_effects: string[],}]Note the comment line beginning with//just before thebrand_namesfield — this is used to nudge the LLM towards understanding that it needs to transform its output to strip the ® character at the end of the brand names, which is useless for our graph downstream. Normally, you would handle special characters like this during the postprocessing stage by writing custom code (say in Pydantic), but BAML allows you to push some of this logic into the prompt itself. Because BAMLensures types safetyin the output, our level of confidence in the LLM’s ability is higher.To reiterate: in BAML, functions are prompts, and classes are models (schemas). You then write tests that can be executed interactively or from the terminal to validate the structured output from the LLM. All of this is done in the comfort of the IDE, before you even write a line of application code!Below is a sample structured output from the BAML prompt (it’s in JSON format). As can be seen, the LLM correctly captures both the structure and the content of the input image, including the nested fields. BAML’s parser ensures that the LLM’s output is valid,parseableJSON so the downstream tools (Polars and Kuzu) can use it without any parsing errors.[{""condition"":""Pain Relief"",""drug"":[{""generic_name"":""Acetaminophen"",""brand_names"":[""Tylenol""]},{""generic_name"":""Morphine"",""brand_names"":[]}],""side_effects"":[""Confusion"",""Constipation"",""Dizziness"",""Drowsiness"",""Dry mouth"",""Queasiness"",""Rash"",""Throwing up""]}]Extract from textThe second task is to extract entities and relationships from the text data of clinical notes. We can write a BAML model and prompt to extract side effects experienced by a patient, as well as useful metadata like a drug’s dosage and frequency, all from the unstructured text.classMedication{name stringdate string@description(""Date format is YYYY-MM-DD"")dosage string@description(""Dosage of the medication"")frequency string@description(""Frequency of the medication"")}classPatientInfo{patient_id stringmedicationMedicationside_effects string[]@description(""Do not list intensity or frequency ","{""theme-name"": ""bookworm-light-astro"", ""msapplication-TileColor"": ""#000000"", ""theme-color"": ""#fff"", ""generator"": ""Astro v4.0.7"", ""viewport"": ""width=device-width, initial-scale=1, maximum-scale=5"", ""title"": ""Transforming unstructured data to a graph with BAML and Kuzu"", ""description"": ""The first step towards building Graph RAG applications is to transform unstructured data into nodes and relationships. In this post, we show how to use LLMs and BAML, an AI engineering framework, to construct a Kuzu graph from a collection of unstructured data."", ""author"": ""K\u00f9zu Inc."", ""og:title"": ""Transforming unstructured data to a graph with BAML and Kuzu"", ""og:description"": ""The first step towards building Graph RAG applications is to transform unstructured data into nodes and relationships. In this post, we show how to use LLMs and BAML, an AI engineering framework, to construct a Kuzu graph from a collection of unstructured data."", ""og:type"": ""website"", ""og:url"": ""https://blog.kuzudb.com/post/unstructured-data-to-graph-baml-kuzu/"", ""og:image"": ""https://blog.kuzudb.com/img/unstructured-data-to-graph-baml-kuzu/baml-kuzu-banner.png"", ""og:image:width"": ""128"", ""og:image:height"": ""128"", ""twitter:image"": ""https://blog.kuzudb.com/img/unstructured-data-to-graph-baml-kuzu/baml-kuzu-banner.png"", ""twitter:title"": ""Transforming unstructured data to a graph with BAML and Kuzu"", ""twitter:description"": ""The first step towards building Graph RAG applications is to transform unstructured data into nodes and relationships. In this post, we show how to use LLMs and BAML, an AI engineering framework, to construct a Kuzu graph from a collection of unstructured data."", ""twitter:card"": ""summary_large_image"", ""astro-view-transitions-enabled"": ""true"", ""astro-view-transitions-fallback"": ""animate""}",,,,
https://medium.com/@mcgeehan/building-a-hybrid-vector-search-database-with-arrow-and-duckdb-07ebc049bc1f,Building a Hybrid Vector Search Database with Arrow and DuckDB | by Thomas F McGeehan V | Medium,"Building a Hybrid Vector Search Database with Arrow and DuckDBThomas F McGeehan VFollow12 min read·Mar 10, 2025--ListenShareHow we combined HNSW for fast vector search with SQL-based metadata filtering for a next-gen AI database.Vector databases are no longer optional. As embeddings-based applications explode across industries, developers need speed, flexibility, and efficiency when storing, searching, and retrieving high-dimensional vectors. But here’s the problem:Most vector databases force you to choose between raw performance and SQL-powered filtering.That’s why we builtQuiver— a Go-powered, hybrid vector database that delivers the best of both worlds:✅ HNSW for fast, high-recall vector search✅ DuckDB for structured metadata filtering✅ Apache Arrow for efficient, zero-copy data movementWith Quiver, you can run complex queries that mix vector similarity with structured constraints — without killing performance.This article isn’t just a high-level introduction. We’re diving deep into the internals — how I integrated Apache Arrow, optimized DuckDB for metadata management, and built a high-speed HNSW index — to create a vector search engine that doesn’t compromise.Let’s get into it.Vector Databases Have a ProblemVector databases are critical infrastructure for AI applications — powering everything from semantic search and recommendation systems to image similarity and anomaly detection. But despite their importance, most solutions come with serious trade-offs.Where Existing Vector Databases Fall Short🔥 Performance vs. Flexibility Trade-offs → Most vector databases are built for either fast similarity search or rich metadata filtering — not both. If you want speed, you lose SQL-style filtering. If you want SQL filtering, you lose performance.🔥 Heavy Resource Consumption → Many solutions demand huge memory and CPU overhead to maintain vector indices, making them expensive at scale.🔥 Operational Complexity → Most vector databases require careful tuning, background maintenance processes, and periodic reindexing to stay performant.🔥 Integration Challenges → Existing solutions often sit outside an organization’s primary data stack, requiring custom pipelines and workarounds to sync with relational databases and analytical engines.How Existing Solutions Approach the ProblemCurrent vector search solutions take different approaches, each with trade-offs:Weaviate → Uses HNSW for vector search with a GraphQL-based query engine. Weaviate allows metadata filtering but stores metadata in RocksDB, which comes with additional operational overhead.Pinecone → A managed service optimized for fast retrieval, but you lose control over the underlying infrastructure and can’t easily run it locally.FAISS → A highly optimized C++ library for pure vector search — but lacks a built-in metadata store, requiring developers to pair it with an external database.pgvector → Brings vector search inside PostgreSQL, enabling SQL-based filtering, but scales poorly on large datasets due to PostgreSQL’s row-based storage.Why We Built QuiverWe wanted a vector database that didn’t force these trade-offs — one that keeps up with the best ANN search engines while supporting rich, efficient metadata filtering.✅ HNSW for high-speed vector search✅ DuckDB for SQL-powered metadata filtering✅ Apache Arrow for zero-copy, high-performance data movementQuiver avoids the overhead of external databases, scales efficiently, and fits seamlessly into modern AI and analytics stacks. Let’s break down how it works.Under the HoodQuiver is built on three key components, each designed to maximize speed, flexibility, and efficiency:1️⃣ Vector Index → An HNSW (Hierarchical Navigable Small World) graph for fast approximate nearest neighbor (ANN) search.2️⃣ Metadata Store → A DuckDB-backed SQL engine for structured metadata filtering.3️⃣ Arrow Appender → A zero-copy data pipeline powered by Apache Arrow, keeping everything memory-efficient and fast.These pieces work together to eliminate the trade-offs most vector databases force you to make — allowing queries that combine vector similarity with structured constraints without wrecking performance.Blazing-Fast Search: The Vector IndexAt the core of Quiver’s vector search engine is HNSW (Hierarchical Navigable Small World) — a graph-based ANN algorithm built for speed and scalability.HNSW is what makes Quiver’s search both fast and accurate, offering logarithmic search complexity while keeping recall high. It works by constructing a multi-layered graph where similar vectors cluster together, drastically reducing the number of comparisons needed for a query.Our Go-based implementation of HNSW is optimized for:✅ Memory efficiency → Minimizing index size without sacrificing recall.✅ High-speed inserts → Batch processing for fast vector ingestion.✅ Precision tuning → Fine-grained control over search parameters for balancing speed vs. accuracy.type Index struct {config Confighnsw *hnsw.Graph[uint64]metadata map[uint64]map[string]interface{}vectors map[uint64][]float32duckdb *DuckDBdbConn *DuckDBConn// Additional fields omitted for brevity}The HNSW graph is parameterized by several key configuration options:type Config struct {Dimension intStoragePath stringDistance DistanceMetricMaxElements uint64HNSWM int // HNSW hyperparameter MHNSWEfConstruct int // HNSW hyperparameter efConstructionHNSWEfSearch int // HNSW hyperparameter ef used during queriesBatchSize int // Number of vectors to batch before insertion// Additional fields omitted for brevity}The `HNSWM` parameter controls the maximum number of connections per node in the graph, while `HNSWEfConstruct` and `HNSWEfSearch` control the search breadth during index construction and query time, respectively. These parameters allow for fine-tuning the trade-off between search speed and accuracy.SQL Meets Vectors: The Metadata StoreWhat sets Quiver apart isn’t just fast vector search — it’s fast vector search with real SQL filtering. That’s where DuckDB comes in.Unlike traditional vector databases that rely on key-value stores or embedded document storage, Quiver uses DuckDB, an in-process analytical database built for speed. This gives us:✅ Full SQL Support → Complex metadata filtering, joins, and aggregations.✅ Columnar Storage → Optimized for analytical workloads, not just key-value lookups.✅ Blazing-Fast Queries → DuckDB is vectorized, meaning it processes queries in parallel with SIMD acceleration.✅ Minimal Overhead → No need for a heavyweight external database — DuckDB runs entirely in-memory when needed.Our DuckDB integration is designed to be lightweight but powerful, ensuring that metadata queries never become the bottleneck. This is what makes Quiver more than just a vector store — it’s a vector-native database that actually understands your data.Bridging the Gap with Apache ArrowHNSW handles fast vector search. ✅DuckDB gives us powerful SQL filtering. ✅But there’s a missing piece: efficient data movement between them.Even with a blazing-fast vector index and a high-performance metadata store, Quiver needed a way to move data seamlessly between components — without serialization overhead, unnecessary memory copies, or slow conversion steps.That’s where Apache Arrow comes in.Arrow as the Data BackboneQuiver doesn’t just use DuckDB — it integrates with it at the memory level. Instead of relying on traditional row-based data movement (which would force slow conversions and copies), we use Arrow Database Connectivity (ADBC) to communicate directly with DuckDB in Arrow-native format.type DuckDB struct {mu sync.Mutexdb adbc.Databasedriver adbc.Driveropts DuckDBOptionsconns []*DuckDBConn}type DuckDBConn struct {parent *DuckDBconn adbc.Connection}With ADBC, metadata queries return results as Arrow RecordBatches, which can be processed without ever leaving columnar memory. This means that vector search results and metadata lookups stay fast, efficient, and zero-copy.Why Apache Arrow?Most vector databases waste CPU cycles shuffling bytes around — loading, converting, and copying data between different formats. Arrow eliminates this problem by keeping everything in a single, efficient memory format.Here’s why that matters:✅ Zero-Copy Data Transfer → No serialization/deserialization overhead when moving data between Quiver’s components.✅ Columnar Storage Efficiency → DuckDB and Arrow both use columnar formats, making queries and analytics dramatically faster.✅ Interoperability → Because Arrow is a standard, Quiver can integrate seamlessly with Python, PostgreSQL, Spark, and other modern data tools.✅ SIMD-Optimized Execution → Arrow enables vectorized processing, meaning modern CPUs can scan and compute over large datasets much faster.How Quiver Uses ArrowWe leverage Arrow in two key areas:1️⃣ Ingesting Data → Bulk-loading vectors and metadata without format conversion.2️⃣ Query Results → Returning search results in an Arrow-native format, making downstream processing in analytics engines or ML pipelines much faster.By eliminating data movement bottlenecks, Arrow makes Quiver more than just a vector search engine — it’s a high-performance data pipeline that fits seamlessly into modern AI and analytics stacks.Hybrid Search: Vector Similarity Meets SQL FilteringRaw vector search is powerful — but it’s not enough.Real-world use cases demand more than just similarity matching. You don’t just want to find the most similar product images — you want to filter by price, category, stock status, or user preferences.That’s what makes Quiver different.By combining HNSW for vector search with DuckDB for structured filtering, Quiver enables hybrid search — queries that mix semantic similarity with SQL-based constraints in a way that’s both fast and flexible.For example:🔍Find the 10 most similar product images, but only include products that are in stock and priced under $50.This kind of query is impossible in most vector databases without pre-filtering or complex workarounds. Quiver makes it seamless.Tw","{""viewport"": ""width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"", ""theme-color"": ""#000000"", ""twitter:app:name:iphone"": ""Medium"", ""twitter:app:id:iphone"": ""828256236"", ""al:ios:app_name"": ""Medium"", ""al:ios:app_store_id"": ""828256236"", ""al:android:package"": ""com.medium.reader"", ""fb:app_id"": ""542599432471018"", ""og:site_name"": ""Medium"", ""apple-itunes-app"": ""app-id=828256236, app-argument=/@mcgeehan/building-a-hybrid-vector-search-database-with-arrow-and-duckdb-07ebc049bc1f, affiliate-data=ct=smart_app_banner"", ""og:type"": ""article"", ""article:published_time"": ""2025-03-10T08:12:00.210Z"", ""title"": ""Building a Hybrid Vector Search Database with Arrow and DuckDB | by Thomas F McGeehan V | Medium"", ""og:title"": ""Building a Hybrid Vector Search Database with Arrow and DuckDB"", ""al:android:url"": ""medium://p/07ebc049bc1f"", ""al:ios:url"": ""medium://p/07ebc049bc1f"", ""al:android:app_name"": ""Medium"", ""description"": ""How we combined HNSW for fast vector search with SQL-based metadata filtering for a next-gen AI database. Vector databases are no longer optional. As embeddings-based applications explode across\u2026"", ""og:description"": ""How we combined HNSW for fast vector search with SQL-based metadata filtering for a next-gen AI database."", ""og:url"": ""https://medium.com/@mcgeehan/building-a-hybrid-vector-search-database-with-arrow-and-duckdb-07ebc049bc1f"", ""al:web:url"": ""https://medium.com/@mcgeehan/building-a-hybrid-vector-search-database-with-arrow-and-duckdb-07ebc049bc1f"", ""og:image"": ""https://miro.medium.com/v2/resize:fit:1024/1*qYLQmVS3SfwBJotQ41mylg.png"", ""article:author"": ""https://medium.com/@mcgeehan"", ""author"": ""Thomas F McGeehan V"", ""robots"": ""index,noarchive,follow,max-image-preview:large"", ""referrer"": ""unsafe-url"", ""twitter:title"": ""Building a Hybrid Vector Search Database with Arrow and DuckDB"", ""twitter:site"": ""@Medium"", ""twitter:app:url:iphone"": ""medium://p/07ebc049bc1f"", ""twitter:description"": ""How we combined HNSW for fast vector search with SQL-based metadata filtering for a next-gen AI database."", ""twitter:image:src"": ""https://miro.medium.com/v2/resize:fit:1024/1*qYLQmVS3SfwBJotQ41mylg.png"", ""twitter:card"": ""summary_large_image"", ""twitter:label1"": ""Reading time"", ""twitter:data1"": ""12 min read""}",,,,
https://github.com/Manirevuri/arangodb-hackathon,GitHub - Manirevuri/arangodb-hackathon,"Manirevuri/arangodb-hackathonPublicNotificationsYou must be signed in to change notification settingsFork0Star00stars0forksBranchesTagsActivityStarNotificationsYou must be signed in to change notification settingsManirevuri/arangodb-hackathonmainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commitHistory9 CommitsUI_ImagesUI_Imagesmcp-servermcp-server.gitattributes.gitattributes.gitignore.gitignoreArangoDB_Hackathon_Presentation.pdfArangoDB_Hackathon_Presentation.pdfArangoDB_Hackathon_submission.ipynbArangoDB_Hackathon_submission.ipynbREADME.mdREADME.mdclaude_prompts.mdclaude_prompts.mdoutput.jsonoutput.jsonView all filesRepository files navigationGraphMind AI: Natural Language Query Agent for CVE Graph DatabaseWatch the video on YoutubeNote: Adding the video here as we ran into playback issues while uploading it to youtube.Project OverviewWe've developed an AI agent that can process natural language queries on a Common Vulnerabilities and Exposures (CVE) graph database. The graph contains approximately 145,000 nodes and 316,000 edges, allowing for comprehensive vulnerability analysis. We are leveraging claude's MCP integration for creating dynamic UI components.Architecture DiagramImportant Setup NotesAfter loading data into ArangoDB, truncate the product_vendor edge collectio and upload the output.json file to fix the issues associated with the original ArangoDB datasetYou may safely ignore any errors regarding issues loading 13 fields, as these are related to missing data and won't affect graph operationsFor installing and configuring the mcp-server, detailed instructions are available in the readme file within the mcp-server folderQuery ToolsOur system implements three specialized tools:txt_to_aql_to_text: Processes queries related to ArangoDB queries (AQL)text_to_nx_algorithm_to_text: Generates NetworkX code, optimizes it, and corrects any errors or timeout issuestext_to_aql_arangosearch: Performs full-text search with capabilities for proximity, fuzzy matching, token analysis, and BM25 scoringThe ReAct agent is designed to leverage these individual tools to create hybrid query mechanisms for more complex analysis tasks.Getting StartedThe provided notebook includes sample queries and outputs for each query type (AQL, ArangoSearch, NetworkX code generation, and hybrid queries).Required Environment Variablesos.environ[""OPENAI_API_KEY""] = """" os.environ[""ANTHROPIC_API_KEY""] = """" os.environ[""ARANGODB_URL""] = """" os.environ[""ARANGODB_USERNAME""] = """" os.environ[""ARANGODB_PASSWORD""] = """" os.environ[""DB_NAME""] = """" # ngrok authentication token !ngrok authtoken """"Performance ConsiderationsInstall all required packages before testingA GPU server is mandatory to test the performance of NetworkX with nx-cugraph backendMaintain optimal sampling parameters to avoid lengthy execution timesHybrid tool callingUI Screenshots from Claude ArtifactsAboutNo description, website, or topics provided.ResourcesReadmeUh oh!There was an error while loading.Please reload this page.ActivityStars0starsWatchers1watchingForks0forksReport repositoryReleasesNo releases publishedPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.LanguagesJupyter Notebook97.9%TypeScript2.1% Manirevuri/arangodb-hackathon Repository files navigation GraphMind AI: Natural Language Query Agent for CVE Graph DatabaseWatch the video on YoutubeNote: Adding the video here as we ran into playback issues while uploading it to youtube.Project OverviewWe've developed an AI agent that can process natural language queries on a Common Vulnerabilities and Exposures (CVE) graph database. The graph contains approximately 145,000 nodes and 316,000 edges, allowing for comprehensive vulnerability analysis. We are leveraging claude's MCP integration for creating dynamic UI components.Architecture DiagramImportant Setup NotesAfter loading data into ArangoDB, truncate the product_vendor edge collectio and upload the output.json file to fix the issues associated with the original ArangoDB datasetYou may safely ignore any errors regarding issues loading 13 fields, as these are related to missing data and won't affect graph operationsFor installing and configuring the mcp-server, detailed instructions are available in the readme file within the mcp-server folderQuery ToolsOur system implements three specialized tools:txt_to_aql_to_text: Processes queries related to ArangoDB queries (AQL)text_to_nx_algorithm_to_text: Generates NetworkX code, optimizes it, and corrects any errors or timeout issuestext_to_aql_arangosearch: Performs full-text search with capabilities for proximity, fuzzy matching, token analysis, and BM25 scoringThe ReAct agent is designed to leverage these individual tools to create hybrid query mechanisms for more complex analysis tasks.Getting StartedThe provided notebook includes sample queries and outputs for each query type (AQL, ArangoSearch, NetworkX code generation, and hybrid queries).Required Environment Variablesos.environ[""OPENAI_API_KEY""] = """" os.environ[""ANTHROPIC_API_KEY""] = """" os.environ[""ARANGODB_URL""] = """" os.environ[""ARANGODB_USERNAME""] = """" os.environ[""ARANGODB_PASSWORD""] = """" os.environ[""DB_NAME""] = """" # ngrok authentication token !ngrok authtoken """"Performance ConsiderationsInstall all required packages before testingA GPU server is mandatory to test the performance of NetworkX with nx-cugraph backendMaintain optimal sampling parameters to avoid lengthy execution timesHybrid tool callingUI Screenshots from Claude Artifacts GraphMind AI: Natural Language Query Agent for CVE Graph Database Watch the video on Youtube Note: Adding the video here as we ran into playback issues while uploading it to youtube. We've developed an AI agent that can process natural language queries on a Common Vulnerabilities and Exposures (CVE) graph database. The graph contains approximately 145,000 nodes and 316,000 edges, allowing for comprehensive vulnerability analysis. We are leveraging claude's MCP integration for creating dynamic UI components. Important Setup Notes Our system implements three specialized tools: The ReAct agent is designed to leverage these individual tools to create hybrid query mechanisms for more complex analysis tasks. The provided notebook includes sample queries and outputs for each query type (AQL, ArangoSearch, NetworkX code generation, and hybrid queries). Required Environment Variables Performance Considerations UI Screenshots from Claude Artifacts There was an error while loading.Please reload this page. There was an error while loading.Please reload this page. There was an error while loading.Please reload this page. There was an error while loading.Please reload this page.","{""route-pattern"": ""/:user_id/:repository"", ""route-controller"": ""files"", ""route-action"": ""disambiguate"", ""fetch-nonce"": ""v2:f12e5e60-1169-fd0a-6d7f-21cd31ff2618"", ""current-catalog-service-hash"": ""f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb"", ""request-id"": ""EF42:2D2CA7:A9D717:F04F80:6839E2B3"", ""html-safe-nonce"": ""be4ce9775d8e8f9c5efac567db8424a24e006a6a8ba7feba52fb9ecdc178926c"", ""visitor-payload"": ""eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJFRjQyOjJEMkNBNzpBOUQ3MTc6RjA0RjgwOjY4MzlFMkIzIiwidmlzaXRvcl9pZCI6IjU2ODYxOTQ1NjU4NzI5MTM5IiwicmVnaW9uX2VkZ2UiOiJpYWQiLCJyZWdpb25fcmVuZGVyIjoiaWFkIn0="", ""visitor-hmac"": ""21cc44b1804968daa771dd6c1b2404eaee7f61becd73cc669c63a5f4a684e2c9"", ""hovercard-subject-tag"": ""repository:945783917"", ""github-keyboard-shortcuts"": ""repository,copilot"", ""google-site-verification"": ""Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I"", ""octolytics-url"": ""https://collector.github.com/github/collect"", ""analytics-location"": ""/<user-name>/<repo-name>"", ""viewport"": ""width=device-width"", ""description"": ""Contribute to Manirevuri/arangodb-hackathon development by creating an account on GitHub."", ""fb:app_id"": ""1401488693436528"", ""apple-itunes-app"": ""app-id=1477376905, app-argument=https://github.com/Manirevuri/arangodb-hackathon"", ""twitter:image"": ""https://opengraph.githubassets.com/eee9795a25c99c1d511e142527aac5f7efc48b07632f17974e5721bd2b3c5655/Manirevuri/arangodb-hackathon"", ""twitter:site"": ""@github"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""GitHub - Manirevuri/arangodb-hackathon"", ""twitter:description"": ""Contribute to Manirevuri/arangodb-hackathon development by creating an account on GitHub."", ""og:image"": ""https://opengraph.githubassets.com/eee9795a25c99c1d511e142527aac5f7efc48b07632f17974e5721bd2b3c5655/Manirevuri/arangodb-hackathon"", ""og:image:alt"": ""Contribute to Manirevuri/arangodb-hackathon development by creating an account on GitHub."", ""og:image:width"": ""1200"", ""og:image:height"": ""600"", ""og:site_name"": ""GitHub"", ""og:type"": ""object"", ""og:title"": ""GitHub - Manirevuri/arangodb-hackathon"", ""og:url"": ""https://github.com/Manirevuri/arangodb-hackathon"", ""og:description"": ""Contribute to Manirevuri/arangodb-hackathon development by creating an account on GitHub."", ""hostname"": ""github.com"", ""expected-hostname"": ""github.com"", ""turbo-cache-control"": ""no-preview"", ""go-import"": ""github.com/Manirevuri/arangodb-hackathon git https://github.com/Manirevuri/arangodb-hackathon.git"", ""octolytics-dimension-user_id"": ""113291632"", ""octolytics-dimension-user_login"": ""Manirevuri"", ""octolytics-dimension-repository_id"": ""945783917"", ""octolytics-dimension-repository_nwo"": ""Manirevuri/arangodb-hackathon"", ""octolytics-dimension-repository_public"": ""true"", ""octolytics-dimension-repository_is_fork"": ""false"", ""octolytics-dimension-repository_network_root_id"": ""945783917"", ""octolytics-dimension-repository_network_root_nwo"": ""Manirevuri/arangodb-hackathon"", ""turbo-body-classes"": ""logged-out env-production page-responsive"", ""browser-stats-url"": ""https://api.github.com/_private/browser/stats"", ""browser-errors-url"": ""https://api.github.com/_private/browser/errors"", ""release"": ""994628876282f66f40ba0bae7848f6c92a1e1688"", ""theme-color"": ""#1e2327"", ""color-scheme"": ""light dark""}",,,,
https://medium.com/@tomzeppenfeldt/querying-an-erp-using-an-ai-configuration-in-graphileon-c667f21f5b51,Querying an ERP using an AI configuration in Graphileon | by Graphileon — Your path to graphs | Medium,"Querying an ERP using an AI configuration in GraphileonGraphileon — Your path to graphsFollow3 min read·Feb 4, 2025--ListenShareI just created a simple though powerful AI configuration in Graphileon to assist users querying their ERP system.What do we feed to the AI?All the AI configuration needs is the model, and a question in natural language.The model is provided through a list of patterns with a short description, like in the image below.Some of the patterns present in the graph databaseThe question is provided in natural language. For instance:Which were the 5 most recent purchase orders for ""XYZ"" ? I want to have orderdate, delivery date, supplier , PO number and quantity.The LLM (in our case OpenAI's o3-mini) returns its interpretation, an explanation, the patterns it thinks are relevant, the suggested Cypher statement and the parameters.Note that in this first step, we have not yet provided the full list of properties and their datatypes that are present on the nodes and edges of each pattern.Response of the OpenAI o3-mini in step 1In order to prepare for step 2, we loop through the relevant patterns (see ""relationshipsUsed"" in the picture above), and get for each pattern a random set of datapoints. These datapoints are anonymised, and included in the messages for the second request to the LLM, in which we ask it to review the Cypher statement and use the actual property names and datatypes as they are present in the datapoints.In the final step, Graphileon runs the generated Cypher statement against the database and displays the results. In parallel, an explanation is provided in a Markdown viewer.The final result returned by the generated queryThe explanation provided by the LLM (OpenAI o3-mini)The functionality described above only takes nine Graphileon functions:A InputView, serving as a form to enter the question.Two Request functions, accessing he OpenAI API.Two Query functions, one to fetch and anonymise the datapoints, the other to execute the generated Cypher query.An IO function, to store process data.A TableView, to display the final result.A MarkdownView, to display the explanation.The Graphileon configuration of the application. Just 9 functions. Querying an ERP using an AI configuration in GraphileonGraphileon — Your path to graphsFollow3 min read·Feb 4, 2025--ListenShareI just created a simple though powerful AI configuration in Graphileon to assist users querying their ERP system.What do we feed to the AI?All the AI configuration needs is the model, and a question in natural language.The model is provided through a list of patterns with a short description, like in the image below.Some of the patterns present in the graph databaseThe question is provided in natural language. For instance:Which were the 5 most recent purchase orders for ""XYZ"" ? I want to have orderdate, delivery date, supplier , PO number and quantity.The LLM (in our case OpenAI's o3-mini) returns its interpretation, an explanation, the patterns it thinks are relevant, the suggested Cypher statement and the parameters.Note that in this first step, we have not yet provided the full list of properties and their datatypes that are present on the nodes and edges of each pattern.Response of the OpenAI o3-mini in step 1In order to prepare for step 2, we loop through the relevant patterns (see ""relationshipsUsed"" in the picture above), and get for each pattern a random set of datapoints. These datapoints are anonymised, and included in the messages for the second request to the LLM, in which we ask it to review the Cypher statement and use the actual property names and datatypes as they are present in the datapoints.In the final step, Graphileon runs the generated Cypher statement against the database and displays the results. In parallel, an explanation is provided in a Markdown viewer.The final result returned by the generated queryThe explanation provided by the LLM (OpenAI o3-mini)The functionality described above only takes nine Graphileon functions:A InputView, serving as a form to enter the question.Two Request functions, accessing he OpenAI API.Two Query functions, one to fetch and anonymise the datapoints, the other to execute the generated Cypher query.An IO function, to store process data.A TableView, to display the final result.A MarkdownView, to display the explanation.The Graphileon configuration of the application. Just 9 functions. Querying an ERP using an AI configuration in Graphileon I just created a simple though powerful AI configuration in Graphileon to assist users querying their ERP system. What do we feed to the AI? All the AI configuration needs is the model, and a question in natural language.The model is provided through a list of patterns with a short description, like in the image below. The question is provided in natural language. For instance: Which were the 5 most recent purchase orders for ""XYZ"" ? I want to have orderdate, delivery date, supplier , PO number and quantity. The LLM (in our case OpenAI's o3-mini) returns its interpretation, an explanation, the patterns it thinks are relevant, the suggested Cypher statement and the parameters.Note that in this first step, we have not yet provided the full list of properties and their datatypes that are present on the nodes and edges of each pattern. In order to prepare for step 2, we loop through the relevant patterns (see ""relationshipsUsed"" in the picture above), and get for each pattern a random set of datapoints. These datapoints are anonymised, and included in the messages for the second request to the LLM, in which we ask it to review the Cypher statement and use the actual property names and datatypes as they are present in the datapoints. In the final step, Graphileon runs the generated Cypher statement against the database and displays the results. In parallel, an explanation is provided in a Markdown viewer. The functionality described above only takes nine Graphileon functions: Written byGraphileon — Your path to graphs Graphileon helps business consultants and information analysts to rapidly design and deploy graph-based applications by exploiting the agility of graphs.","{""viewport"": ""width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"", ""theme-color"": ""#000000"", ""twitter:app:name:iphone"": ""Medium"", ""twitter:app:id:iphone"": ""828256236"", ""al:ios:app_name"": ""Medium"", ""al:ios:app_store_id"": ""828256236"", ""al:android:package"": ""com.medium.reader"", ""fb:app_id"": ""542599432471018"", ""og:site_name"": ""Medium"", ""apple-itunes-app"": ""app-id=828256236, app-argument=/@tomzeppenfeldt/querying-an-erp-using-an-ai-configuration-in-graphileon-c667f21f5b51, affiliate-data=ct=smart_app_banner"", ""og:type"": ""article"", ""article:published_time"": ""2025-02-04T16:24:40.291Z"", ""title"": ""Querying an ERP using an AI configuration in Graphileon | by Graphileon \u2014 Your path to graphs | Medium"", ""og:title"": ""Querying  an ERP using an AI configuration in Graphileon"", ""al:android:url"": ""medium://p/c667f21f5b51"", ""al:ios:url"": ""medium://p/c667f21f5b51"", ""al:android:app_name"": ""Medium"", ""description"": ""I just created a simple though powerful AI configuration in Graphileon to assist users querying their ERP system. All the AI configuration needs is the model, and a question in natural language.\nThe\u2026"", ""og:description"": ""A simple though powerful AI configuration in Graphileon to assist users querying their ERP system."", ""og:url"": ""https://medium.com/@tomzeppenfeldt/querying-an-erp-using-an-ai-configuration-in-graphileon-c667f21f5b51"", ""al:web:url"": ""https://medium.com/@tomzeppenfeldt/querying-an-erp-using-an-ai-configuration-in-graphileon-c667f21f5b51"", ""og:image"": ""https://miro.medium.com/v2/resize:fit:1200/1*gBxgCl04i1dNKrRBZbvJUQ.png"", ""article:author"": ""https://medium.com/@tomzeppenfeldt"", ""author"": ""Graphileon \u2014 Your path to graphs"", ""robots"": ""index,noarchive,follow,max-image-preview:large"", ""referrer"": ""unsafe-url"", ""twitter:title"": ""Querying  an ERP using an AI configuration in Graphileon"", ""twitter:site"": ""@Medium"", ""twitter:app:url:iphone"": ""medium://p/c667f21f5b51"", ""twitter:description"": ""A simple though powerful AI configuration in Graphileon to assist users querying their ERP system."", ""twitter:image:src"": ""https://miro.medium.com/v2/resize:fit:1200/1*gBxgCl04i1dNKrRBZbvJUQ.png"", ""twitter:card"": ""summary_large_image"", ""twitter:label1"": ""Reading time"", ""twitter:data1"": ""3 min read""}",,,,
https://2024.connected-data.london/speakers/urbashi-mitra/,Urbashi Mitra - Connected Data London 2024,"Gordon S. Marshall Professor in Engineering, University of Southern CaliforniaUrbashi Mitra received the B.S. and the M.S. degrees from the University of California at Berkeley and her Ph.D. from Princeton University. She is the Gordon S. Marshall Professor in Engineering at the University of Southern California with appointments in Electrical Engineering and Computer Science Dr. Mitra is a Fellow of the IEEE and a Foreign member of Academia Europaea. She is a co-principal investigator of the recently funded National Science Foundation Center on Pandemic Insights. Dr. Mitra was the inaugural Editor-in-Chief for the IEEE Transactions on Molecular, Biological and Multi-scale Communications. Her honors include: the 2024 IEEE Information Theory Society’s Aaron D. Wyner Distinguished Service Award, the 2021 USC Viterbi School of Engineering Senior Research Award, the 2017 IEEE Communications Society Women in Communications Engineering Technical Achievement Award, a 2016 UK Royal Academy of Engineering Distinguished Visiting Professorship, a 2016 US Fulbright Scholar Award, 2012 Globecom Signal Processing for Communications Symposium Best Paper Award, 2012 US National Academy of Engineering Lillian Gilbreth Lectureship, Student Best Paper Award, as co-advisor, at the International Conference on Signal Processing and Communications, Bangalore India 2012, the 2009 DCOSS Applications & Systems Best Paper Award, 2001 Okawa Foundation Award, 2000 OSU College of Engineering Lumley Award for Research, 1997 OSU College of Engineering MacQuigg Award for Teaching, and a 1996 National Science Foundation CAREER Award. Her research interests are in: model-based machine learning, wireless communications, communication and sensor networks, biological communication systems, and the interface of communication, sensing and control. Causal Graph Identification: optimization, performance bounds and reward optimization Edges Track Review and Unconference Session Neo4j, the Graph Database & Analytics leader, helps organizations find hidden relationships and patterns across billions of data connections deeply, easily, and quickly. Connect the dots of your data! Ontotext helps enterprises to lower data management costs by up to 30%, enable data fabric architectures, create digital twins, utilize Graph RAG benefits, and take information delivery from days to minutes! The vendor of PoolParty Semantic Suite. Graph-based text mining, recommender systems, and data fabric solutions. yWorks specializes in the development of professional software solutions that enable the clear visualization of diagrams and networks. We’re a cloud tech company that provides organisations around the world with computing infrastructure and software to help them innovate, unlock efficiencies and become more effective. We also created the world’s first – and only – autonomous database to help organise and secure our customers’ data. Ultipa builds next-gen graph XAI & real-time database empowering smart enterprises w/ smooth digital transformations. Oxford Semantic Technologies (OST) spun out from the University of Oxford and was acquired by Samsung in 2024. OST provides AI software to extract insights from big data, solving issues like medical diagnostics and financial crime. One founder is a BCS Lovelace Medal winner. Web3 data platform built on standards. Fluree powers connected, secure, and agile data ecosystems. Senzing is the first to deliver real-time, artificial intelligence for entity resolution. Senzing software enables organizations of all sizes to gain highly accurate and valuable insights about who is who and who is related to whom in data. We partner with you, and your chosen semantic stack, to liberate your data's meaning from isolated silos. All-in-one platform to create AI agents powered by your private data and knowledge. Make GenAI prototype to production 10 times faster. We are backed by Y Combinator. Start free today: https://epsilla.com Since 2016 Neural Alpha have delivered cutting edge, sustainability centric Connected Data solutions for blue-chip corporates, financial institutions, Governments and NGOs. Our bespoke software & data solutions fuse AI, Knowledge Graphs, Taxonomies & other technologies for unprecedented insights. Graphwise, born from the merger of Ontotext and Semantic Web Company, empowers enterprises to maximize AI ROI with trusted knowledge graph and semantic AI solutions, employing over 200 people globally across North America, Europe, and APAC. Transparent, verifiable AI, Lettria lets your business docs and data deliver trustworthy AI answers. Cricket Hill: Greek Organic Premium Olive Oil, Cosmo-Local Events and Tours Want to sponsor this event?Contact Us Ready to learn from the best? This website (and some third-party tools) use cookies. These are important as they allow us to deliver an exceptional experience. By clicking 'Accept', you agree to the use of cookies. Configure| View ourPrivacy Policy If you'd prefer to only accept essential cookies, then you can do so below. Or press the 'accept' button to accept all cookies. View ourPrivacy Policy","{""description"": ""Urbashi Mitra received the B.S. and the M.S. degrees from the University of California at Berkeley and her Ph.D. from Princeton University. She is..."", ""viewport"": ""width=device-width, initial-scale=1, shrink-to-fit=no"", ""mobile-web-app-capable"": ""yes"", ""apple-mobile-web-app-status-bar-style"": ""black"", ""author"": ""HeySummit"", ""robots"": ""index,follow"", ""og:title"": ""Connected Data London 2024"", ""og:description"": ""Speaker bio and details for Urbashi Mitra"", ""og:type"": ""website"", ""og:image"": ""https://d2q846bclm63a8.cloudfront.net/media/uploads/events/connected-data-london-2024/EWMd3pBhHji423su4BbWuF.png.png"", ""og:image:secure_url"": ""https://d2q846bclm63a8.cloudfront.net/media/uploads/events/connected-data-london-2024/EWMd3pBhHji423su4BbWuF.png.png"", ""og:image:height"": ""628"", ""og:image:width"": ""1200"", ""twitter:card"": ""summary_large_image"", ""og:url"": ""https://2024.connected-data.london/speakers/urbashi-mitra/"", ""og:site_name"": ""Connected Data London 2024"", ""fb:app_id"": ""276414549655070""}",,,,
https://darrendevitt.com/all-fhir-concepts-can-be-explained-simply/,All FHIR concepts can be explained simply – Darren Devitt,"FHIR is not rocket science.There’s a quote attributed to Einstein that resonates with me: “If you can’t explain it simply, you don’t understand it well enough.”Writing these posts helps clarify my own understanding of FHIR. When all you have is 300 words there’s no room for complicating things.Here are 9 short posts I wrote over the past year on different FHIR concepts. I learned something new from each one.Let’s start at the very beginningFHIR IDs and IdentifiersThe difference between a resource’s ID and a resource’s Identifier.https://darrendevitt.com/fhir-ids-and-identifiers/CodeableConceptsHow terminology is rendered in FHIR.https://darrendevitt.com/fhir-building-blocks-codeableconcepts/Resource ReferencesHow FHIR resources connect to each other.https://darrendevitt.com/a-fhir-resource-does-not-exist-in-isolation/Element cardinalityHow many of an element there can or must be.https://darrendevitt.com/fhir-a-refresher-on-cardinality/Next, move on to the plumbingUnderstanding FHIR BundlesTransactions, searchsets and collections.https://darrendevitt.com/understanding-fhir-bundles/Ancestors: Resource and DomainResourceInheritance in FHIR — why all resources have a “meta” element.https://darrendevitt.com/fhir-ancestors-resource-and-domainresource/Finally, lift the hood on some advanced FHIR featuresFHIR Profiles made simpleThe key feature of Implementation Guides.https://darrendevitt.com/fhir-profiles-made-simple/FHIR DocumentsSharing FHIR resources in a structured and human readable way.https://darrendevitt.com/theres-real-power-and-potential-in-fhir-documents/Conditional UpdatesCreating or updating resources with a single request.https://darrendevitt.com/devs-new-to-fhir-can-be-productive-almost-immediately/Discussion---Sign up to my Weekly Email.Check out theVanya FHIR Viewerfor Windows and Mac.Related FHIR is not rocket science. There’s a quote attributed to Einstein that resonates with me: “If you can’t explain it simply, you don’t understand it well enough.” Writing these posts helps clarify my own understanding of FHIR. When all you have is 300 words there’s no room for complicating things. Here are 9 short posts I wrote over the past year on different FHIR concepts. I learned something new from each one. Let’s start at the very beginning Next, move on to the plumbing Finally, lift the hood on some advanced FHIR features Sign up to my Weekly Email. Check out theVanya FHIR Viewerfor Windows and Mac. Discover more from Darren Devitt Subscribe now to keep reading and get access to the full archive.","{""viewport"": ""width=device-width, initial-scale=1.0"", ""robots"": ""max-image-preview:large"", ""description"": ""FHIR is not rocket science. There\u2019s a quote attributed to Einstein that resonates with me: \u201cIf you can't explain it simply, you don't understand it well enough.\u201d Writing these posts helps clarify my own understanding of FHIR. When all you have is 300 words there\u2019s no room for complicating things. Here are 9 short posts\u2026"", ""msapplication-TileImage"": ""https://i0.wp.com/darrendevitt.com/wp-content/uploads/2023/11/cropped-d-logo-512X512.png?fit=270%2C270&ssl=1""}",,,,
https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e,RAG on FHIR with Knowledge Graphs | by Sam Schifman | Medium,"RAG on FHIR with Knowledge GraphsSam SchifmanFollow10 min read·Jan 31, 2024--4ListenShareImage generated by MidjourneyIn my last post,RAG on FHIR, I introduced some ideas for using FHIR to fuel Retrieval Augmented Generation (RAG). There I went into some detail about what RAG is, but in short it is using some curated data to enrich prompts sent to an Large Language Model (LLM), so that the Artificial Intelligence (AI) can generate a more accurate response. In that article, I also discussed why this makes a difference in healthcare and whyFast Healthcare Interoperable Resources(FHIR) are particularly well suited for RAG.This was a great start to being able to leverage LLMs in healthcare in a responsible way. However, it was only a start. In this article, I will continue to build on those ideas. In particular, I propose to address two limitations of that initial work:Not understanding the connected nature of healthcare data.Not understanding how important time when answering questions in healthcare.Let’s take a closer look at each of these.Healthcare Data is ConnectedOne of the great features of FHIR is that it recognizes that data in healthcare is linked in many ways. For example, a blood pressure measurement is linked to a patient, but it is also linked to the encounter (office visit) in which the reading was taken, the time it was taken, and who took it. FHIR represents this by containing References from one FHIR resource to another. This allows one to fetch all the blood pressure readings for a patient in a nice neat package, and then go back for the other data later.These links are critical to help us understand the real picture of the patient’s healthcare. For example, if that blood pressure was high, we may want to understand what medication changes the doctor made to address that. We can trace the path from the blood pressure to the encounter to the medications ordered at the encounter. But, the real question we probably want to answer is, did the treatment make a difference. To answer this we need another concept, time.Time Matters in HealthcareTo figure out if some treatment was successful or not, we need to put that treatment in the context of when it was started and what happened after that. FHIR does not apply any particular ordering to the data. However, most FHIR resources do contain dates that can provide that context. So, you can get all the blood pressure readings and sort them by date and then see if the readings after the encounter in question get better or not.RAG and Connected DataThe RAG I discussed in my last article used a Vector Index / Store to capture the meaning of each FHIR resource and allow us to search for them. In my YouTube video,RAG on FHIR, I go into some detail about how this works. However, the Vector Store has no idea about the linking of resources. So, we need a different data structure to handle that.Knowledge GraphsKnowledge Graphs (or generally Graph Data Stores) are very good at capturing this sort of linking. In this context, I am talking about a graph that stores nodes and edges that link nodes, not bar or pie charts. We can visualize a graph like this:Here we have a Knowledge Graph that contains knowledge about the speed of various things. In particular, from this graph we can see that dogs can go 45 MPH and that they are animals, which is different than vehicles. While a car can go 200 MPH, but is not an animal.Knowledge Graphs from FHIRThe above graph is a very simple example, but we can use references in FHIR to build a more complex graph about a patient’s healthcare:This is actually only part of the graph created from one FHIR bundle. I again used data generated bySynthea. In this case it is from the data set they make publicly availablehere. What I did was to read each resource, flatten it, and create a node per resource. I then looked in each resource again and pulled out any references to other resources. From these references I created edges to link the nodes. You can see all the code in theJupyter Notebook.Vector Index on Knowledge GraphYou might be wondering if I am abandoning Vector Stores completely. The answer is no. When I flatten the FHIR resources, I still create a string representation of them. This time I do that with slightly more sophisticated code, which you can see inGitHub. I then use functionality inNeo4J, the Graph Database I am using, to create a Vector Index of the nodes.You can think of it like projecting the graph into a vector space:We can now turn a question into a vector and find the node that is most likely to answer that question.What about the devourer of all things… TimeWe now have our connected data in the graph, but we still don’t have any concept of time. What we can do is go back through our resources and pull out the times. In this case I am more interested in just the date part of the time, so I just pulled dates. I then created a node per each unique date and created edges from nodes that contained that date.So, now the graph looks something like this:Each node that contains a date is linked to a node for that date. I make sure that I only create one node per specific date, so that multiple nodes that contained the same date will be linked to the same date node.Answering Questions with RAGNow I have the data structure I need to answer questions. Let’s pick a question and see how it works. For this example, I am going to ask:""How much did the colon scan on Jan. 18, 2014 cost?""In the graph there are two Colonoscopies, shown in the dark blue nodes below:Using the Vector Index, Neo4J can find these two nodes becausecolonoscopyis close enough tocolon scanin vector space.Now our problem becomes how to pick the one with the right date.Extracting the Date from the QuestionGetting what date the question is referring to is tricky. The date could be specified in many different ways:""January 1, 2014""""Jan. 1, 2014""""1/18/14""""01/18/2014""""eighteen days after the first of the year 2014""and so on...While I probably could devise some sort of regular expression that would handle most forms of dates, it would never catch everything. Instead, I decided to utilize the LLM. What I do is ask the LLM not to answer the question, but to tell me what date the question is asking about. Further, I ask it to give the answer in JSON, a format the program can understand. You can see the exact question in theJupyter Notebook.Pulling the ContextNow that I know the date, I can use it to find the right Colonoscopy. Then I want to find the correct surrounding nodes and build a string that combines all that for the LLM. Luckily, Neo4J’s integration withLangChainprovides a simple way to do this.Neo4jVectorallows me to pass aretrieval querythat can constrain and enrich the results. In my case the query looks like this:match (node)<-[]->(sc:resource)where exists {(node)-[]->(d:Date {id: '01/18/2014'})}with node.text as self, reduce(s="""", item in collect(distinct sc.text) | s + ""\n\nSecondary Entry:\n"" + item ) as ctxt, score, {} as metadata limit 1return ""Primary Entry:\n"" + self + ctxt as text, score, metadataWhat this query does is pick the node with the right date and then find all the nodes linked to that node. It then takes thetextfield from each node and builds a nice string to pass to the LLM. So we get a prompt for the LLM that looks like:System: The context below contains entries about the patient's healthcare.Please limit your answer to the information provided in the context. Do not make up facts.If you don't know the answer, just say that you don't know, don't try to make up an answer.If you are asked about the patient's name and one the entries is of type patient, you should look for the first given name and family name and answer with: [given] [family]----------------Primary Entry:The type of information in this entry is procedure. The status for this procedure is completed. The code for this procedure is Colonoscopy. This procedure was performed period start on 01/18/2014 at 12:21:21. This procedure was performed period end on 01/18/2014 at 13:03:15.Secondary Entry:The type of information in this entry is claim. The status for this claim is active. The type of this claim is professional. The use for this claim is claim. This claim was billable period start on 01/18/2014 at 12:21:21. This claim was billable period end on 01/18/2014 at 13:03:15. This claim was created on 01/18/2014 at 13:03:15. The priority for this claim is normal. The facility display for this claim is UMASS MEMORIAL HEALTHALLIANCE CLINTON HOSPITAL INC. The procedure sequence for this claim is 1. The insurance for this claim is Medicaid. The 2nd item for this claim is Encounter for check up. The 3rd item for this claim is Encounter for check up. The total for this claim is 12427.4 USD.Secondary Entry:The type of information in this entry is location. The status for this location is active. The name for this location is UMASS MEMORIAL HEALTHALLIANCE CLINTON HOSPITAL INC. The telecom system for this location is phone. The telecom value for this location is 9783683000. The address line for this location is 201 HIGHLAND ST. The address city for this location is CLINTON. The address state for this location is MA. The address postalCode for this location is 015101037. The address country for this location is US. The position longitude for this location is -71.69329092351188. The position latitude for this location is 42.42738865. The managing organization display for this location is UMASS MEMORIAL HEALTHALLIANCE CLINTON HOSPITAL INC.Secondary Entry:The type of information in this entry is encounter. The status for this encounter is finished. The class for this encounter is AMB. The type of this encounter is Encounter for check up. The participant type of this encounter is primary performer. This encounter was participant period start on 01/18/2014 at 12:21:21. This encounter was participant period end on 01/18/2014 at 13:03:15. This encounter was period start on 01/18/2014 at 12:21:21. T","{""viewport"": ""width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"", ""theme-color"": ""#000000"", ""twitter:app:name:iphone"": ""Medium"", ""twitter:app:id:iphone"": ""828256236"", ""al:ios:app_name"": ""Medium"", ""al:ios:app_store_id"": ""828256236"", ""al:android:package"": ""com.medium.reader"", ""fb:app_id"": ""542599432471018"", ""og:site_name"": ""Medium"", ""apple-itunes-app"": ""app-id=828256236, app-argument=/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e, affiliate-data=ct=smart_app_banner"", ""og:type"": ""article"", ""article:published_time"": ""2024-01-31T01:05:05.516Z"", ""title"": ""RAG on FHIR with Knowledge Graphs | by Sam Schifman | Medium"", ""og:title"": ""RAG on FHIR with Knowledge Graphs"", ""al:android:url"": ""medium://p/04d8e13ee96e"", ""al:ios:url"": ""medium://p/04d8e13ee96e"", ""al:android:app_name"": ""Medium"", ""description"": ""In my last post, RAG on FHIR, I introduced some ideas for using FHIR to fuel Retrieval Augmented Generation (RAG). There I went into some detail about what RAG is, but in short it is using some\u2026"", ""og:description"": ""In my last post, RAG on FHIR, I introduced some ideas for using FHIR to fuel Retrieval Augmented Generation (RAG). There I went into some\u2026"", ""og:url"": ""https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e"", ""al:web:url"": ""https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e"", ""og:image"": ""https://miro.medium.com/v2/resize:fit:1024/1*VhSpRE88yEQKOBzRdBtojw.png"", ""article:author"": ""https://medium.com/@samschifman"", ""author"": ""Sam Schifman"", ""robots"": ""index,noarchive,follow,max-image-preview:large"", ""referrer"": ""unsafe-url"", ""twitter:title"": ""RAG on FHIR with Knowledge Graphs"", ""twitter:site"": ""@Medium"", ""twitter:app:url:iphone"": ""medium://p/04d8e13ee96e"", ""twitter:description"": ""In my last post, RAG on FHIR, I introduced some ideas for using FHIR to fuel Retrieval Augmented Generation (RAG). There I went into some\u2026"", ""twitter:image:src"": ""https://miro.medium.com/v2/resize:fit:1024/1*VhSpRE88yEQKOBzRdBtojw.png"", ""twitter:card"": ""summary_large_image"", ""twitter:label1"": ""Reading time"", ""twitter:data1"": ""10 min read""}",,,,
https://medium.com/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98,Why Lawyers Are Uniquely Suited to Work with LLMs | by Chia Jeng Yang | Knowledge Graph RAG | Medium,"Devs and non-technical domain experts build Agentic and RAG-native knowledge graphs FeaturedWhy Lawyers Are Uniquely Suited to Work with LLMsWhat This Article Covers:Chia Jeng YangFollow9 min read·Mar 4, 2025--1ListenShareWhylawyers have a unique advantage when working with LLMsHowLLM information retrieval works — and how to spot failuresPractical examples(including a “Mock LSAT”) to debug LLM outputsThis article discusses how, despite the fact that lawyers are not engineers, a legally trained mind — when equipped with basic technical knowledge of Large Language Models (LLMs) — can uniquely contribute to their deployment and coordination. Many LLM failures stem from the way AI systems handle language. While impressive, LLMs do not think like humans.Law is one of the few professions built on structuring reasoning and maintaining consistency through language. Lawyers, with the right technical foundation can collaborate with engineers to create expert reasoning and retrieval workflows — charting processes for how LLMs should reason about specific types of legal information.AI offers lawyers the potential to create a programmatic version of themselves — one that retains their expertise but never tires or retires. By understanding LLM search processes like Retrieval Augmented Generation (RAG), lawyers can pinpoint why an LLM fails to retrieve relevant answers and use their semantic expertise to refine its output.At WhyHow.AI, we use internal tools like these to map expert reasoning flows and enhance LLM retrieval accuracy.Most LLM systems useRetrieval-Augmented Generation (RAG)to pull in external information beyond their training data. This includes searching documents, websites, and other sources before generating an answer.I think of LLMs like an intern. They can follow instructions literally, lack intuitive reasoning, and struggle to connect implicit concepts. They also have a tendency to forget information between interactions.Besides all of these, like an intern with a particular quirk in the way they think, LLMs rely on a single method — semantic similarity — to interpret questions and retrieve relevant information. Knowing this, this approach can be reverse engineered to identify failures.For example, when searching a 300-page contract for “consequential damages,” a lawyer knows:Searching for “damages” via Ctrl+F won’t work since the term may appear as “indirect losses.”Context matters — if “consequential damages” appears in definitions, it expands the scope of relevant terms.Certain standard documents (e.g., side letters in partnership agreements) must be checked, even if not explicitly referenced.Similarly, LLMs struggle when retrieving conceptually related but substantively material terms. If asked,“What liabilities does the contract impose?”, an LLM may overlook relevant sections if “consequential damages” and “indirect losses” are regarded as non-semantically similar. Lawyers, trained to be sensitive to conceptual equivalencies, can help address these gaps.Let us go in depth into how LLMs retrieve and answer questions in a RAG system so we can start looking at more complex scenarios (and more likely scenarios you may have come across).The basics of RAG that a lawyer would need to know: Chunking, Semantic Similarity, Chunk FilteringRetrieval Augmented Generation (RAG) operates in three critical stages:Chunking: Take a document, break it into pieces called chunks, and turn each chunk into numbersSemantic Similarity: Take a question, turn it into numbers and see which document chunks are semantically similar to each question mathematically. In semantic similarity, words like “dog” and “animal” are mathematically close because they share meaning, whereas unrelated terms like “horseshoe” and “quantum mechanics” are distant.Chunk Filtering/ Top-K: Take the top few document chunks (scored by semantic similarity), give them to an LLM, and let the LLM construct the answer from that subset of document chunks, given the question.That’s it — that’s essentially all a simple RAG system does. If I have learnt anything between building developer infrastructure and going through law school, it is that developers, like lawyers, use highly technical terms that belie relatively simple concepts to help enhance job security.In the below image, you can see what a chunk looks like, and you can program the size of the chunks to use. The larger the chunks, the more the information. The smaller the chunks, the smaller the information. Only a certain amount of words can fit into the LLMs context window when they construct the answer. Therefore, the larger the chunks, the less chunks you can fit into the LLM.Variable: Chunk sizeLarge chunks: Better for extracting generalized meaning and insightSmall chunks: Better for extracting specific facts, figures, or statisticsThe only other thing to know is something called the Top-K filter. This is just a fancy way of saying ‘What is the top number of document chunks we will decide to select to give to the LLM to construct its answer’.Top-K filtering determines how many document chunks an LLM uses to generate an answer. For example, if Top-K = 3, the system selects the three most relevant chunks. A higher Top-K captures more information but risks hallucinations, while a lower Top-K ensures focused answers but may miss key details.One obvious limitation is imagining that you have a question which requires information that is spread across 10 document chunks (i.e. tell me the top 10 clauses that are related to this issue) and the top-k is set to 5, meaning only the top 5 document chunks are retrieved.Variable: Top-kHigher values: More complete responses that incorporate large amounts of informationLower values: More focused, consistent answersFor example, consider the query:“What is the recommended dosage of acetaminophen for an adult?”Document 1 contains the chunk: “Take 500 mg every 4–6 hours.”Document 2 contains the chunk: “Do not exceed 3000 mg per day.”If the system retrieves onlyone chunk, the answer may be misleading. Even worse, if neither chunk explicitly mentions “acetaminophen,” they might not be retrieved at all.Onecommon trickis to ask the LLM to add metadata summaries to each chunk — a summary of the document itself (i.e. imagining that the 2 documents are “Dosage instructions for Acetaminophen” and “FDA warnings about Acetaminophen” and a similar summary is appended to each chunk). We can then imagine that the combination of each sentence with its document summary gives us a level of confidence that the chunks would be more semantically similar and be appropriately picked up.The LSATs of Debugging LLMsLet’s apply this to real-world examples. Debugging LLM retrieval is like taking the LSAT — spotting how subtle wording affects meaning and determining where retrieval goes wrong.Example A: Travel Itinerary QueryQuery: “What are the optimal itineraries for experiencing authentic, under-the-radar cultural venues in Paris beyond the standard landmarks?”Underlying Sentences in the Knowledge Base:Sentence A:“The Musée Jacquemart-André offers a rich collection of fine arts in a historic mansion setting.”Sentence B:“The Eiffel Tower and Louvre Museum remain the best attractions in Paris for experiencing authentic cultural venues in Paris.”Sentence C:“The Canal Saint-Martin area provides a vibrant, off-the-beaten-path experience with indie boutiques and local eateries.”Sentence D:“For those seeking indie cultural experiences, venues like the Maison de la Photographie and the Passage des Panoramas offer unique insights into Parisian art and history.”Intended Answer & Limitations of Semantic Similarity:The intended relevant sentences are sentences A, C & D. However, despite the query’s focus on non-mainstream venues, the retrieval system might overweight Sentence B because of the mentions of ‘Paris’ and ‘authentic cultural venues’. In semantic similarity, the weight of ‘under-the-radar’ may not overcome the weight of the other variables mentioned, even though it is obvious to a human that that variable is the most important.Potential Solutioning:For queries involving travel recommendations, a knowledge graph can be established that tags locations with specific attributes — such as “under the radar,” “popular,” “nature,” or “cultural.” These attributes function as values by which conceptual similarities can be measured for the purposes of RAG retrieval.Alongside this, an LLM dedicated to classifying the attributes can classify the question to determine the traveler’s desired experience (e.g., searching for nature-oriented venues versus cultural venues). This LLM double-checks the answer against the predefined categories, ensuring that the final output aligns with the traveler’s questions and excludes popular attractions and emphasizes under-the-radar experiences.A type of Knowledge Graph used by AirbnbSimilarly, another LLM can double-check the final answer and the original question to highlight any inconsistencies, and re-rank the chunks used.Example B: Enterprise Device Management QueryQuery: “What are the best practices for remotely deploying security patches on company-owned smartphones to ensure strict regulatory compliance, minimal service disruption, and robust data integrity?”Underlying Sentences in the Knowledge Base:Sentence A:“Enterprise-grade MDM solutions enable scheduled, phased rollouts of security patches, which helps minimize service disruption while maintaining oversight.”Sentence B:“Always make sure that your Device is receiving automatic, over-the-air updates to keep up to date with the latest in security” {This sentence was taken from a pamphlet titled ‘Consumer Device Best Practices’ where the title was many sentences away from Sentence B}Sentence C:“For corporate environments, it is essential to implement real-time monitoring and post-deployment audits as part of the remote patch deployment process to ensure data integrity and adherence to regulatory standards.”Senten","{""viewport"": ""width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"", ""theme-color"": ""#000000"", ""twitter:app:name:iphone"": ""Medium"", ""twitter:app:id:iphone"": ""828256236"", ""al:ios:app_name"": ""Medium"", ""al:ios:app_store_id"": ""828256236"", ""al:android:package"": ""com.medium.reader"", ""fb:app_id"": ""542599432471018"", ""og:site_name"": ""Medium"", ""apple-itunes-app"": ""app-id=828256236, app-argument=/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98, affiliate-data=ct=smart_app_banner"", ""og:type"": ""article"", ""article:published_time"": ""2025-05-20T22:10:04.412Z"", ""title"": ""Why Lawyers Are Uniquely Suited to Work with LLMs | by Chia Jeng Yang | Knowledge Graph RAG | Medium"", ""og:title"": ""Why Lawyers Are Uniquely Suited to Work with LLMs"", ""al:android:url"": ""medium://p/bcc66d3dce98"", ""al:ios:url"": ""medium://p/bcc66d3dce98"", ""al:android:app_name"": ""Medium"", ""description"": ""Unlock the secret to successful LLM deployment. Discover how lawyers' unique skills in structuring reasoning and language can overcome AI limitations, and learn practical tips to debug LLM outputs and refine their expertise."", ""og:description"": ""How LLM information retrieval works and the LSATs for LLMs."", ""og:url"": ""https://medium.com/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98"", ""al:web:url"": ""https://medium.com/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98"", ""og:image"": ""https://miro.medium.com/v2/da:true/resize:fit:996/0*7F2qd_PIFMsnkV3P"", ""article:author"": ""https://chiajy.medium.com"", ""author"": ""Chia Jeng Yang"", ""robots"": ""index,noarchive,follow,max-image-preview:large"", ""referrer"": ""unsafe-url"", ""twitter:title"": ""Why Lawyers Are Uniquely Suited to Work with LLMs"", ""twitter:site"": ""@Medium"", ""twitter:app:url:iphone"": ""medium://p/bcc66d3dce98"", ""twitter:description"": ""How LLM information retrieval works and the LSATs for LLMs."", ""twitter:image:src"": ""https://miro.medium.com/v2/da:true/resize:fit:996/0*7F2qd_PIFMsnkV3P"", ""twitter:card"": ""summary_large_image"", ""twitter:creator"": ""@chiajy2000"", ""twitter:label1"": ""Reading time"", ""twitter:data1"": ""9 min read""}",,,,
https://link.springer.com/journal/10506,Home | Artificial Intelligence and Law,"Artificial Intelligence and LawPublishing model:HybridSubmit your manuscript Artificial Intelligence and Law OverviewThis journal seeks papers that address the development of formal or computational models of legal knowledge, reasoning, and decision making. It also includes in-depth studies of innovative artificial intelligence systems that are being used in the legal domain, and gives space to studies addressing the legal, ethical and social implications of the use of artificial intelligence in law. It welcomes interdisciplinary approaches including not only artificial intelligence and jurisprudence, but also logic, machine learning, cognitive psychology, linguistics, or philosophy.In addition to original research contributions, this journal welcomes book reviews as well as research notes posing interesting and timely research challenges.Editors-in-ChiefKevin D. Ashley,Giovanni Sartor,Matthias Grabmair,Katie AtkinsonSocieties and partnershipsInternational Association for Artificial Intelligence and LawJournal metricsJournal Impact Factor3.1 (2023)5-year Journal Impact Factor3.6 (2023)Submission to first decision (median)37 daysDownloads436.6k (2024)Latest issueMarch 2025Volume 33, Issue 1View all volumes and issuesLatest articlesLegal text classification in Korean sexual offense cases: from traditional machine learning to large language models with XAI insightsJeongmin LeeOriginal ResearchOpen access28 May 2025Part of 1 collection:Applications and Evaluation of Large Language Models in the Legal DomainEmpirical analysis of binding precedent efficiency in Brazilian Supreme Court via case classificationRaphaël TinarrageHenrique EnnesJorge PocoOriginal ResearchOpen access26 May 2025R2GQA: retriever-reader-generator question answering system to support students understanding legal regulations in higher educationTinh Pham Phuc DoNgoc Dinh Duy CaoKiet Van NguyenOriginal Research22 May 2025Advancing prompt-based language models in the legal domain: adaptive strategies and research challengesReshma SheikSneha Ann RejiS. Jaya NirmalaReview Article15 May 2025Specialized or general AI? a comparative evaluation of LLMs’ performance in legal tasksXue GuoYuting HuangXianglin DongOriginal Research14 May 2025View all articlesThis journal has120 open access articlesSign up for alertsGet notified when new articles are published.Journal informationElectronic ISSN1572-8382Print ISSN0924-8463Abstracted and indexed inACM Digital LibraryANVURBFI ListBaiduCLOCKSSCNKICNPIECCurrent Contents/Engineering, Computing and TechnologyCurrent Contents/Social & Behavioral SciencesDBLPDimensionsEBSCOEI CompendexERIH PLUSGoogle ScholarINSPECJapanese Science and Technology Agency (JST)NaverNorwegian Register for Scientific Journals and SeriesOCLC WorldCat Discovery ServicePhilPapersPhilosopher’s IndexPorticoProQuestSCImagoSCOPUSScience Citation Index Expanded (SCIE)Social Science Citation IndexTD Net Discovery ServiceWanfang© Springer Nature B.V. OverviewThis journal seeks papers that address the development of formal or computational models of legal knowledge, reasoning, and decision making. It also includes in-depth studies of innovative artificial intelligence systems that are being used in the legal domain, and gives space to studies addressing the legal, ethical and social implications of the use of artificial intelligence in law. It welcomes interdisciplinary approaches including not only artificial intelligence and jurisprudence, but also logic, machine learning, cognitive psychology, linguistics, or philosophy.In addition to original research contributions, this journal welcomes book reviews as well as research notes posing interesting and timely research challenges.Editors-in-ChiefKevin D. Ashley,Giovanni Sartor,Matthias Grabmair,Katie AtkinsonSocieties and partnershipsInternational Association for Artificial Intelligence and LawJournal metricsJournal Impact Factor3.1 (2023)5-year Journal Impact Factor3.6 (2023)Submission to first decision (median)37 daysDownloads436.6k (2024) This journal seeks papers that address the development of formal or computational models of legal knowledge, reasoning, and decision making. It also includes in-depth studies of innovative artificial intelligence systems that are being used in the legal domain, and gives space to studies addressing the legal, ethical and social implications of the use of artificial intelligence in law. It welcomes interdisciplinary approaches including not only artificial intelligence and jurisprudence, but also logic, machine learning, cognitive psychology, linguistics, or philosophy. In addition to original research contributions, this journal welcomes book reviews as well as research notes posing interesting and timely research challenges. Societies and partnerships Latest articlesLegal text classification in Korean sexual offense cases: from traditional machine learning to large language models with XAI insightsJeongmin LeeOriginal ResearchOpen access28 May 2025Part of 1 collection:Applications and Evaluation of Large Language Models in the Legal DomainEmpirical analysis of binding precedent efficiency in Brazilian Supreme Court via case classificationRaphaël TinarrageHenrique EnnesJorge PocoOriginal ResearchOpen access26 May 2025R2GQA: retriever-reader-generator question answering system to support students understanding legal regulations in higher educationTinh Pham Phuc DoNgoc Dinh Duy CaoKiet Van NguyenOriginal Research22 May 2025Advancing prompt-based language models in the legal domain: adaptive strategies and research challengesReshma SheikSneha Ann RejiS. Jaya NirmalaReview Article15 May 2025Specialized or general AI? a comparative evaluation of LLMs’ performance in legal tasksXue GuoYuting HuangXianglin DongOriginal Research14 May 2025View all articlesThis journal has120 open access articles Legal text classification in Korean sexual offense cases: from traditional machine learning to large language models with XAI insightsJeongmin LeeOriginal ResearchOpen access28 May 2025Part of 1 collection:Applications and Evaluation of Large Language Models in the Legal Domain Legal text classification in Korean sexual offense cases: from traditional machine learning to large language models with XAI insights Empirical analysis of binding precedent efficiency in Brazilian Supreme Court via case classificationRaphaël TinarrageHenrique EnnesJorge PocoOriginal ResearchOpen access26 May 2025 Empirical analysis of binding precedent efficiency in Brazilian Supreme Court via case classification R2GQA: retriever-reader-generator question answering system to support students understanding legal regulations in higher educationTinh Pham Phuc DoNgoc Dinh Duy CaoKiet Van NguyenOriginal Research22 May 2025 R2GQA: retriever-reader-generator question answering system to support students understanding legal regulations in higher education Advancing prompt-based language models in the legal domain: adaptive strategies and research challengesReshma SheikSneha Ann RejiS. Jaya NirmalaReview Article15 May 2025 Advancing prompt-based language models in the legal domain: adaptive strategies and research challenges Specialized or general AI? a comparative evaluation of LLMs’ performance in legal tasksXue GuoYuting HuangXianglin DongOriginal Research14 May 2025 Specialized or general AI? a comparative evaluation of LLMs’ performance in legal tasks Get notified when new articles are published. Journal informationElectronic ISSN1572-8382Print ISSN0924-8463Abstracted and indexed inACM Digital LibraryANVURBFI ListBaiduCLOCKSSCNKICNPIECCurrent Contents/Engineering, Computing and TechnologyCurrent Contents/Social & Behavioral SciencesDBLPDimensionsEBSCOEI CompendexERIH PLUSGoogle ScholarINSPECJapanese Science and Technology Agency (JST)NaverNorwegian Register for Scientific Journals and SeriesOCLC WorldCat Discovery ServicePhilPapersPhilosopher’s IndexPorticoProQuestSCImagoSCOPUSScience Citation Index Expanded (SCIE)Social Science Citation IndexTD Net Discovery ServiceWanfang© Springer Nature B.V. © Springer Nature B.V.","{""applicable-device"": ""pc,mobile"", ""viewport"": ""width=device-width, initial-scale=1"", ""360-site-verification"": ""1268d79b5e96aecf3ff2a7dac04ad990"", ""format-detection"": ""telephone=no"", ""theme-color"": ""#e6e6e6"", ""keywords"": ""Artificial Intelligence and Law, Artificial Intelligence, IT Law, Media Law, Intellectual Property, Philosophy of Law, Legal Aspects of Computing, Information Storage and Retrieval"", ""description"": ""This journal seeks papers that address the development of formal or computational models of legal knowledge, reasoning, and decision making. It also includes ..."", ""og:url"": ""https://link.springer.com/journal/10506"", ""og:type"": ""website"", ""og:site_name"": ""SpringerLink"", ""og:title"": ""Artificial Intelligence and Law"", ""og:description"": ""This journal seeks papers that address the development of formal or computational models of legal knowledge, reasoning, and decision making. It also includes ..."", ""og:image"": ""https://media.springernature.com/w92/springer-static/cover/journal/10506.jpg"", ""twitter:title"": ""Artificial Intelligence and Law"", ""twitter:image:alt"": ""Artificial Intelligence and Law Cover Image"", ""twitter:description"": ""This journal seeks papers that address the development of formal or computational models of legal knowledge, reasoning, and decision making. It also includes ..."", ""twitter:image"": ""https://media.springernature.com/w92/springer-static/cover/journal/10506.jpg"", ""twitter:card"": ""summary_large_image""}",,,,
https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/,Lessons from building a prototype single-search tool for beneficial ownership registers | openownership.org,"<Back to BlogPhoto byLisa ZoeonUnsplash.Beneficial ownership (BO) data is useful only once it is in the hands of those who need it. However, ourrecent researchwith users of BO data found that lack of access to information is still one of the biggest barriers to its effective use.Our work developing theOpen Ownership Registershowed that there is demand for accessing BO information from multiple countries. Yet, only a few countries publish the bulk BO data required to power such tools.Many countriesaremaking it possible for users to search and explore BO data at a national level. But if you’re conducting an investigation into a company or person, you might not know where to look. Therefore, knowingwhethera register holds specific information andwhichregister holds that specific information could save time and resources in investigations.A little while ago, we had a simple idea – what if there was a place where you could search multiple countries’ BO registers at once? Would that be possible? Would that be useful? We spent some time over the last few months creating and testing a tool to start answering these questions.We wanted to learn:To what extent would users of international BO information find a simple signposting tool useful?What advantages (or disadvantages) might a tool like this have over the information sources they are using already?Are existing BO registers set up to enable access in this way?What can this tell us abouteffective implementation of BO reforms?This blog post describes the tool we built in light of these questions, and what we learned in the process.Initial thinkingTo start thinking about what this might look like, we developed a product vision board to consider our target audience and their needs. We then discussed what kind of product might be able to serve these needs.This exercise helped us make a few key decisions:The tool would be aimed at anyoneinvestigatingspecific companies or individualsfroma range of different countries, including law enforcement agencies, financial intelligence units, bank staff, and journalists.We would start off just bysignposting users to where they could find more information– our hypothesis was that thequantity of sources was more importantfor these users than providing BO information directly.Search by company and by personwould be important to investigators, so we would attempt to do both.We wouldonly access official registersrather than unofficial data (e.g. Panama Papers leaks). Our priority as an organisation is to provide advice to governments, so we wanted toprioritise learning lessons about official government sources.Identifying sourcesWe came up with a longlist of 33 potential sources of information – BO registers – for the tool based on the Open Ownershipmap. These potential sources either provided some level of public search functionality or were present in commercial tools like Moody’s Orbis database.We then needed to figure out which of these would be accessible. Our criteria were that the source:provided an application programming interface (API) to search companies and/or persons (technically, we may have been able to search some registers either by using browser imitation, or downloading and searching bulk information, but this would have required significantly more developer time and/or storage costs); [1]did not require user registration to search (although registering to access an API would have been fine).This left us with a list of nine accessible BO registers we could search by company name or entity ID number, and four we could search by a person’s name.Note: this list is not exhaustive – there may be other registers that we could have connected to, but these were the ones we identified in the time available.SourceCompany searchPerson searchCommentBulgaria✔️Searches of the Bulgarian company register need to be in the Cyrillic alphabet, so the tool converts the Latin alphabet to CyrillicCzechia✔️Denmark✔️✔️Technically, it is possible to search by beneficial owner, but we were often blocked by their serverEstonia✔️✔️GLEIF✔️Latvia✔️Nigeria✔️✔️Poland✔️Requires exact date of birth in order to search by person nameSlovakia✔️✔️United Kingdom✔️Provides BO information in bulk data download but it is not possible to search by beneficial owner via the APIThe toolWith these sources, we designed a simple tool. It has just a search bar and radio button which allows you to choose whether to search for a company name or a person’s name.After inputting the name of a company and selecting ""Company search"", the tool will return the list of sources and number of matches found in the source.For example, searching the company name “Aurubis” returns:It then links to each separate BO register, where the user can choose to go and recreate the search to try to access the actual BO information if they so choose.Similarly, the user can instead choose to search for a person’s name – doing so returns a similar but shorter table of registers, just those that allow a search by a person’s name:Users are then able to go and recreate the search on the relevant registers if they get a match.If you want to try it yourself, the tool is availablehere– you will need to follow the install instructions in the README file.Testing with usersAfter creating the tool, we wanted to get it in front of some real-life users of BO data in order to see if it would be something they found useful.We identified a number of types of users that might find this kind of information helpful, including:financial intelligence units;banks;journalists and civil society.We conducted a total of six interviews with relevant users. We asked each interviewee:How do you currently access international BO data, and what do you use it for?Following a demonstration of the tool, we subsequently asked:Do you think you would find the tool useful in its current form?What additional features might it need in order to be useful for you?What we learnedWe spent 11 days of developer time, plus another 20 days on design and testing. Despite the many limitations, we learned some interesting things:People found it useful – in principleAll users who tested the tool expressed that there was value in a simple signposting tool. As one bank employee said:“Even if I can see that Italy is listed and the register is closed and I still have to file a request to Italy, then that would still be useful… If I go to open sources, I don’t know what I’m looking for, I just search and search and search.”However, nobody followed up to ask for access following the demonstration, which would have been a much stronger signal of value.Connecting the tool to more sources would be more useful than retrieving the information about beneficial owners and companiesFour of the six people interviewed suggested that adding more sources within the tool would make it more useful, over and above providing information about the beneficial owners of companies or companies owned by the people searched.However, some users did ask to see the data within the tool itself, particularly if it could either visualise BO networks or enable the search of other sources for information retrieved by the initial search. For example, if an initial search for a company name would retrieve the name of a beneficial owner, the user would be able to directly conduct a second search for that beneficial owner.A simple technical solutionIt took 11 total developer days to set up 9 sources and a simple user interface. Of course, there are bugs and issues that could be ironed out with more time, but this is not a difficult technical problem. When the sources are accessible – even if poorly documented – incorporating information from a new data source is measured in days, not weeks or months.Access to sources is very limited – even amongst registers that provide some level of public accessNot many sources were accessible via this method, even amongst those that were ostensibly public. For example, while as a non-governmental organisation we were able to gain legitimate interest access to BO information via an API from the French national register, the terms of use were not clear enough as to whether we were allowed to use the information in the manner necessary to make this tool work without our users also having to apply for their own legitimate interest access – an undue burden for simple testing. Other notable sources we were unable to include (for different reasons) were Armenia and Indonesia.For a signposting tool, the ability to search by person is arguably more useful than by company. A company is only registered in one jurisdiction, and if you are investigating a company, knowing where it is registered is likely information you already have. However, a person might own a company anywhere in the world, and being signposted to where this is will be considerably more useful.Only four of the nine registers allowed users to search for the companies owned by a specific person, meaning this user need is often not met. This is perhaps not surprising, given that searching by the name of a person constitutes a higher degree of infringement on privacy.(Some) users are most interested in information from jurisdictions in their regionWhich countries users are interested in depends on two main things – where the users are based, and what they do. The bank employees interviewed were mostly interested in nearby countries, where their clients were most likely to have a presence. Those interested in investigating sanctions were more interested in where individuals had exposure, meaning that having access to more sources was preferred. Those interested in financial investigation were more interested in following chains into secrecy jurisdictions.How does the tool compare to existing ways users access beneficial ownership data?Users listed several advantages that a tool like this might have over other ways of accessing BO data from multiple countries, including:Knowing where to look: Whil","{""viewport"": ""width=device-width, initial-scale=1, maximum-scale=5"", ""description"": ""In this emerging thinking piece, our Data Analyst Manager Miranda Evans describes the lessons learned in a recent experiment by Open Ownership, building a prototype single-search tool for beneficial ownership registers."", ""og:title"": ""Lessons from building a prototype single-search tool for beneficial ownership registers"", ""og:description"": ""In this emerging thinking piece, our Data Analyst Manager Miranda Evans describes the lessons learned in a recent experiment by Open Ownership, building a prototype single-search tool for beneficial ownership registers."", ""og:site_name"": ""openownership.org"", ""og:type"": ""website"", ""og:url"": ""https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/"", ""og:image"": ""https://oo.cdn.ngo/media/images/oo-single-search-tool-blog-post-i.2e16d0ba.fill-1200x630.png"", ""og:image:width"": ""1200"", ""og:image:height"": ""630"", ""og:image:type"": ""image/jpeg"", ""og:image:url"": ""https://oo.cdn.ngo/media/images/oo-single-search-tool-blog-post-i.2e16d0ba.fill-1200x630.png"", ""og:image:secure_url"": ""https://oo.cdn.ngo/media/images/oo-single-search-tool-blog-post-i.2e16d0ba.fill-1200x630.png"", ""twitter:title"": ""Lessons from building a prototype single-search tool for beneficial ownership registers"", ""twitter:description"": ""In this emerging thinking piece, our Data Analyst Manager Miranda Evans describes the lessons learned in a recent experiment by Open Ownership, building a prototype single-search tool for beneficial ownership registers."", ""twitter:card"": ""summary_large_image"", ""twitter:site"": ""https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/"", ""twitter:creator"": ""https://twitter.com/openownership"", ""twitter:image:src"": ""https://oo.cdn.ngo/media/images/oo-single-search-tool-blog-post-i.2e16d0ba.fill-1200x630.png"", ""twitter:image:width"": ""1200"", ""twitter:image:height"": ""630"", ""apple-mobile-web-app-title"": ""openownership.org"", ""application-name"": ""openownership.org"", ""msapplication-TileColor"": ""#ffffff"", ""msapplication-config"": ""/static/images/favicons/browserconfig.e4e40b0c82d2.xml"", ""theme-color"": ""#ffffff"", ""csrf-token"": ""exOMPQtLjytHtDTCKtP6Y0pIKz4QumtP9uJ63w0WTWN0tMDLx4AJYm2Q8vVQxLcW""}",,,,
https://www.occrp.org/en/project/cyprus-confidential/billionaire-roman-abramovichs-company-set-up-fake-superyacht-chartering-scheme-in-apparent-attempt-to-evade-millions-in-taxes,Billionaire Roman Abramovich’s Company Set Up Fake Superyacht Chartering Scheme in Apparent Attempt to Evade Millions in Taxes | OCCRP,"Billionaire Roman Abramovich’s Company Set Up Fake Superyacht Chartering Scheme in Apparent Attempt to Evade Millions in Taxes People working for Abramovich designed a corporate structure to give the false impression that the billionaire’s yachts were being commercially chartered to third parties, and therefore eligible for tax breaks. Banner: James O'Brien/OCCRP Key FindingsTo take advantage of an EU tax exemption for commercial vessels, executives at Abramovich’s companies devised a complex scheme in which his superyachts were leased to ostensibly independent customers.In reality, the customers leasing the vessels were companies owned by Abramovich’s offshore trust via opaque firms in a Caribbean secrecy jurisdiction.The scheme was in place from 2005 to 2012, when Cypriot tax authorities issued a 14-million-euro bill for unpaid value-added tax that Abramovich’s lawyers unsuccessfully appealed in court. To take advantage of an EU tax exemption for commercial vessels, executives at Abramovich’s companies devised a complex scheme in which his superyachts were leased to ostensibly independent customers.In reality, the customers leasing the vessels were companies owned by Abramovich’s offshore trust via opaque firms in a Caribbean secrecy jurisdiction.The scheme was in place from 2005 to 2012, when Cypriot tax authorities issued a 14-million-euro bill for unpaid value-added tax that Abramovich’s lawyers unsuccessfully appealed in court. Leak Unveils Russian Oligarch Abramovich’s $1 Billion Art Collection. Despite Sanctions, It Has Not Been Seized or Frozen.Documents leaked from Cyprus show that, just before Russia invaded Ukraine and Abramovich was sanctioned last year, the billionaire passed the massive collection to his ex-wife. Leak Unveils Russian Oligarch Abramovich’s $1 Billion Art Collection. Despite Sanctions, It Has Not Been Seized or Frozen. Credit Suisse Banked Abramovich Fortune Held in Secret Offshore CompaniesCredit Suisse loaned hundreds of millions of dollars to Abramovich’s offshore companies, which used U.S. stocks as collateral, two new leaks reveal. The secretly-owned firms loaned each other massive sums that were mysteriously returned or written off, in what experts said could be a scheme to obscure the origin of the funds. Credit Suisse Banked Abramovich Fortune Held in Secret Offshore Companies Abramovich’s Secret Football Payments May Have Breached Financial Fair Play RulesFormer Chelsea FC owner Roman Abramovich’s offshore companies made backchannel payments worth tens of millions of dollars to football agents, clubs, scouts and directors, leaked documents reveal. Abramovich’s Secret Football Payments May Have Breached Financial Fair Play Rules A company ultimately owned by the Russian billionaire Roman Abramovich set up a fake superyacht-leasing business in Cyprus in an apparent attempt to evade millions of euros in tax, leaked files and correspondence obtained by OCCRP reveal.Between 1999 and 2010, the former Chelsea Football Club owner assembled a fleet of superyachts worth around $1.2 billion, including the world’s longest at the time, Eclipse, which boasted two helipads and a swimming pool that could turn into a dance floor.The yachts spent part of the year sailing in European waters. Operating them was expensive, and under EU law, value-added tax was due on everything needed to keep them in service — fuel, staff, port fees, maintenance, and more. But these costs were exempt from the EU tax for vessels used for commercial purposes.To claim the exemption, people working for Abramovich devised a complex scheme in which the luxury vessels were leased to what looked like independent customers paying to go on a cruise for a week or two. In reality, the companies hiring the superyachts were owned by an offshore trust whose beneficial owner was Abramovich.Cypriot tax officials later found that the yachts were not in fact used commercially, and in 2012 the country’s tax authority ordered Abramovich’s company to pay 14 million euros ($18.5 million) to cover the unpaid tax. Lawyers for the company tried to overturn the order in court, but the appeal was finally dismissed last year. Representatives for Abramovich did not respond to questions about whether the outstanding tax bill had been settled. A company ultimately owned by the Russian billionaire Roman Abramovich set up a fake superyacht-leasing business in Cyprus in an apparent attempt to evade millions of euros in tax, leaked files and correspondence obtained by OCCRP reveal.Between 1999 and 2010, the former Chelsea Football Club owner assembled a fleet of superyachts worth around $1.2 billion, including the world’s longest at the time, Eclipse, which boasted two helipads and a swimming pool that could turn into a dance floor.The yachts spent part of the year sailing in European waters. Operating them was expensive, and under EU law, value-added tax was due on everything needed to keep them in service — fuel, staff, port fees, maintenance, and more. But these costs were exempt from the EU tax for vessels used for commercial purposes.To claim the exemption, people working for Abramovich devised a complex scheme in which the luxury vessels were leased to what looked like independent customers paying to go on a cruise for a week or two. In reality, the companies hiring the superyachts were owned by an offshore trust whose beneficial owner was Abramovich.Cypriot tax officials later found that the yachts were not in fact used commercially, and in 2012 the country’s tax authority ordered Abramovich’s company to pay 14 million euros ($18.5 million) to cover the unpaid tax. Lawyers for the company tried to overturn the order in court, but the appeal was finally dismissed last year. Representatives for Abramovich did not respond to questions about whether the outstanding tax bill had been settled. A company ultimately owned by the Russian billionaire Roman Abramovich set up a fake superyacht-leasing business in Cyprus in an apparent attempt to evade millions of euros in tax, leaked files and correspondence obtained by OCCRP reveal. Between 1999 and 2010, the former Chelsea Football Club owner assembled a fleet of superyachts worth around $1.2 billion, including the world’s longest at the time, Eclipse, which boasted two helipads and a swimming pool that could turn into a dance floor. The yachts spent part of the year sailing in European waters. Operating them was expensive, and under EU law, value-added tax was due on everything needed to keep them in service — fuel, staff, port fees, maintenance, and more. But these costs were exempt from the EU tax for vessels used for commercial purposes. To claim the exemption, people working for Abramovich devised a complex scheme in which the luxury vessels were leased to what looked like independent customers paying to go on a cruise for a week or two. In reality, the companies hiring the superyachts were owned by an offshore trust whose beneficial owner was Abramovich. Cypriot tax officials later found that the yachts were not in fact used commercially, and in 2012 the country’s tax authority ordered Abramovich’s company to pay 14 million euros ($18.5 million) to cover the unpaid tax. Lawyers for the company tried to overturn the order in court, but the appeal was finally dismissed last year. Representatives for Abramovich did not respond to questions about whether the outstanding tax bill had been settled. Billionaire Roman Abramovich. Leaked emails from people working for Abramovich, discovered by The Bureau of Investigative Journalism and the BBC and shared with OCCRP, reveal an explicit intention to deceive tax inspectors. “Our structure must as clearly as possible separate the different parties so that an investigator checking on our operation would see it as a legitimate structure,” a director of Abramovich’s company wrote in an email in 2005, when the scheme began. “But we all have to recognise that a determined investigator could eventually discover this is an in-house structure with the possible consequences that would entail.” Leaked emails from people working for Abramovich, discovered by The Bureau of Investigative Journalism and the BBC and shared with OCCRP, reveal an explicit intention to deceive tax inspectors. “Our structure must as clearly as possible separate the different parties so that an investigator checking on our operation would see it as a legitimate structure,” a director of Abramovich’s company wrote in an email in 2005, when the scheme began. “But we all have to recognise that a determined investigator could eventually discover this is an in-house structure with the possible consequences that would entail.” Leaked emails from people working for Abramovich, discovered by The Bureau of Investigative Journalism and the BBC and shared with OCCRP, reveal an explicit intention to deceive tax inspectors. “Our structure must as clearly as possible separate the different parties so that an investigator checking on our operation would see it as a legitimate structure,” a director of Abramovich’s company wrote in an email in 2005, when the scheme began. “But we all have to recognise that a determined investigator could eventually discover this is an in-house structure with the possible consequences that would entail.” A Leak of Secretive Cypriot Documents A Leak of Secretive Cypriot Documents The leaked files originate from Cypriot corporate service provider MeritServus, whose managing director, Cypriot chartered accountant Demetris Ioannides, was sanctioned by the U.K. government in 2023 for setting up “murky offshore structures” for Abramovich. (Ioannides did not respond to a request for comment.) The documents were obtained by the whistleblower group Distributed Denial of Secrets and initially shared with OCCRP and The Guardian. This investigation is part of Cyprus Confidential, a global investigative collaboration led by the International Consortium of Investigative Journalists (ICI","{""viewport"": ""width=device-width, initial-scale=1"", ""description"": ""People working for Abramovich designed a corporate structure to give the false impression that the billionaire\u2019s yachts were being commercially chartered to third parties, and therefore eligible for tax breaks."", ""og:type"": ""website"", ""og:title"": ""Billionaire Roman Abramovich\u2019s Company Set Up Fake Superyacht Chartering Scheme in Apparent Attempt to Evade Millions in Taxes"", ""og:description"": ""People working for Abramovich designed a corporate structure to give the false impression that the billionaire\u2019s yachts were being commercially chartered to third parties, and therefore eligible for tax breaks."", ""og:url"": ""https://www.occrp.org/en/project/cyprus-confidential/billionaire-roman-abramovichs-company-set-up-fake-superyacht-chartering-scheme-in-apparent-attempt-to-evade-millions-in-taxes"", ""og:site_name"": ""OCCRP"", ""og:locale"": ""en_US"", ""og:locale:alternate"": ""ru_RU"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""Billionaire Roman Abramovich\u2019s Company Set Up Fake Superyacht Chartering Scheme in Apparent Attempt to Evade Millions in Taxes"", ""twitter:description"": ""People working for Abramovich designed a corporate structure to give the false impression that the billionaire\u2019s yachts were being commercially chartered to third parties, and therefore eligible for tax breaks."", ""og:image"": ""https://www.occrp.org/processed/containers/assets/investigations/abramovich/roman-abramovich-banner.jpg/12f405a4e277d352a98c584d5b39bdff/roman-abramovich-banner.jpg"", ""twitter:image"": ""https://www.occrp.org/processed/containers/assets/investigations/abramovich/roman-abramovich-banner.jpg/12f405a4e277d352a98c584d5b39bdff/roman-abramovich-banner.jpg""}",,,,
https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-contract-factory-inside-danske-bank-estonias-money-laundering-machine,‘The Contract Factory’: Inside Danske Bank Estonia’s Money Laundering Machine | OCCRP,"‘The Contract Factory’: Inside Danske Bank Estonia’s Money Laundering Machine Investigators allege 19 bankers laundered more than $1.6 billion of illicit funds, some of it from a huge Russian tax evasion scheme and a Facebook phishing scam. Banner: Alexander Welscher/dpa/Alamy Live News Azerbaijani Couple, Including President’s Cousin, Owns Properties Worth Millions in London and IbizaThe couple has agreed to forfeit over £4 million that they had received from the Azerbaijani Laundromat, a massive money laundering system, to the authorities. The properties will not be seized. Azerbaijani Couple, Including President’s Cousin, Owns Properties Worth Millions in London and Ibiza Jet-Setting DJ — and Cousin of Azerbaijan’s President Aliyev — Accused of Receiving Millions In Suspicious FundsU.K. investigators tied Izzat Khanim Javadova, known as Mikaela Jav, and her husband to the Azerbaijani Laundromat, a massive underground money movement system often used by Azerbaijan’s elite. This is the first time a member of the president’s family has been linked to it. Jet-Setting DJ — and Cousin of Azerbaijan’s President Aliyev — Accused of Receiving Millions In Suspicious Funds Agreed StatementJavanshir Feyziyev brought libel proceedings over two articles published on the OCCRP website. Skype user Maxim.Canning was a veritable one-stop-shop for anyone looking to launder illicit funds.For a fee, he would not only sell you a company registered on an offshore paradise island, but also help you to disguise who really owned it. If you needed to transfer suspect money, he could make fake contracts to give it a semblance of legality, or rapidly funnel the cash through dozens of offshore accounts.“Maxim” could even find you proxy directors to add to company paperwork — for a price.“We have for 1000 euros per piece a Kazakh until 2022,” he wrote to one client in 2014, after the documents they had provided for a different director didn’t check out.Estonian investigators say Maxim’s real name was Jevgeni Agnevštšikov, and he was one of 19 people on Danske Bank Estonia’s foreign banking team who they believe laundered more than US$1.6 billion of illicit funds for their clients.The money allegedly originated in eight schemes in Russia, Azerbaijan, the U.S., Iran, Switzerland, and Georgia, as well as a scam that defrauded Facebook out of nearly $100 million. It flowed through Danske Bank Estonia accounts between 2007 and 2015, when the bank was at the center of one of Europe’s largest ever money laundering scandals.Late last year, investigators presented a 160-page report to the 19 bankers detailing the accusations against them. The document, obtained by Estonia’s Eesti Ekspress and shared with OCCRP and Danish newspaper Berlingske, outlines the charges that prosecutors expect to file in the coming months, before the case goes to court. Only 15 are expected to face charges, however, as two were found not to have been involved and two provided evidence.Investigators allege Agnevštšikov’s bosses, Juri Kidjajev and Erik Lidmets, started selling off-the-books services in 2005, when they worked for the Estonian branch of Sampo Bank. They allegedly continued after Danske Bank bought Sampo two years later, recruiting other trusted bankers to join their team.When Danske Bank closed its foreign banking division in 2015, several of these bankers moved to other lenders in Estonia, where investigators say some continued to launder money for up to four more years.Lidmets declined to comment and reporters were unable to reach Kidjajev. Andres Simson, a lawyer for Agnevštšikov and another of the accused bankers, declined to comment while the case is ongoing, saying only: “I can confirm that my defendants deny any guilt.""Philippe Vollot, chief administrative officer at Danske Bank, said the bank was cooperating with authorities in the investigation. “Combating financial crime and money laundering is a key priority for Danske Bank. Overall, we are now in a different position with respect to combating financial crime and money laundering than when the situation developed in Estonia,” he said.State prosecutor Maria Entsik declined to comment on the contents of the report, which she said should not be disclosed before trial. She said police would soon send the full case file to prosecutors, so they could decide whether to take it forward.“To date, a total amounting to 10 million euros in assets of suspects and third parties enriched by the proceeds of crime have been seized to secure the confiscation requirements of the state,” she added. Skype user Maxim.Canning was a veritable one-stop-shop for anyone looking to launder illicit funds.For a fee, he would not only sell you a company registered on an offshore paradise island, but also help you to disguise who really owned it. If you needed to transfer suspect money, he could make fake contracts to give it a semblance of legality, or rapidly funnel the cash through dozens of offshore accounts.“Maxim” could even find you proxy directors to add to company paperwork — for a price.“We have for 1000 euros per piece a Kazakh until 2022,” he wrote to one client in 2014, after the documents they had provided for a different director didn’t check out.Estonian investigators say Maxim’s real name was Jevgeni Agnevštšikov, and he was one of 19 people on Danske Bank Estonia’s foreign banking team who they believe laundered more than US$1.6 billion of illicit funds for their clients.The money allegedly originated in eight schemes in Russia, Azerbaijan, the U.S., Iran, Switzerland, and Georgia, as well as a scam that defrauded Facebook out of nearly $100 million. It flowed through Danske Bank Estonia accounts between 2007 and 2015, when the bank was at the center of one of Europe’s largest ever money laundering scandals.Late last year, investigators presented a 160-page report to the 19 bankers detailing the accusations against them. The document, obtained by Estonia’s Eesti Ekspress and shared with OCCRP and Danish newspaper Berlingske, outlines the charges that prosecutors expect to file in the coming months, before the case goes to court. Only 15 are expected to face charges, however, as two were found not to have been involved and two provided evidence.Investigators allege Agnevštšikov’s bosses, Juri Kidjajev and Erik Lidmets, started selling off-the-books services in 2005, when they worked for the Estonian branch of Sampo Bank. They allegedly continued after Danske Bank bought Sampo two years later, recruiting other trusted bankers to join their team.When Danske Bank closed its foreign banking division in 2015, several of these bankers moved to other lenders in Estonia, where investigators say some continued to launder money for up to four more years.Lidmets declined to comment and reporters were unable to reach Kidjajev. Andres Simson, a lawyer for Agnevštšikov and another of the accused bankers, declined to comment while the case is ongoing, saying only: “I can confirm that my defendants deny any guilt.""Philippe Vollot, chief administrative officer at Danske Bank, said the bank was cooperating with authorities in the investigation. “Combating financial crime and money laundering is a key priority for Danske Bank. Overall, we are now in a different position with respect to combating financial crime and money laundering than when the situation developed in Estonia,” he said.State prosecutor Maria Entsik declined to comment on the contents of the report, which she said should not be disclosed before trial. She said police would soon send the full case file to prosecutors, so they could decide whether to take it forward.“To date, a total amounting to 10 million euros in assets of suspects and third parties enriched by the proceeds of crime have been seized to secure the confiscation requirements of the state,” she added. Skype user Maxim.Canning was a veritable one-stop-shop for anyone looking to launder illicit funds. For a fee, he would not only sell you a company registered on an offshore paradise island, but also help you to disguise who really owned it. If you needed to transfer suspect money, he could make fake contracts to give it a semblance of legality, or rapidly funnel the cash through dozens of offshore accounts. “Maxim” could even find you proxy directors to add to company paperwork — for a price. “We have for 1000 euros per piece a Kazakh until 2022,” he wrote to one client in 2014, after the documents they had provided for a different director didn’t check out. Estonian investigators say Maxim’s real name was Jevgeni Agnevštšikov, and he was one of 19 people on Danske Bank Estonia’s foreign banking team who they believe laundered more than US$1.6 billion of illicit funds for their clients. The money allegedly originated in eight schemes in Russia, Azerbaijan, the U.S., Iran, Switzerland, and Georgia, as well as a scam that defrauded Facebook out of nearly $100 million. It flowed through Danske Bank Estonia accounts between 2007 and 2015, when the bank was at the center of one of Europe’s largest ever money laundering scandals. Late last year, investigators presented a 160-page report to the 19 bankers detailing the accusations against them. The document, obtained by Estonia’s Eesti Ekspress and shared with OCCRP and Danish newspaper Berlingske, outlines the charges that prosecutors expect to file in the coming months, before the case goes to court. Only 15 are expected to face charges, however, as two were found not to have been involved and two provided evidence. Investigators allege Agnevštšikov’s bosses, Juri Kidjajev and Erik Lidmets, started selling off-the-books services in 2005, when they worked for the Estonian branch of Sampo Bank. They allegedly continued after Danske Bank bought Sampo two years later, recruiting other trusted bankers to join their team. When Danske Bank closed its foreign banking division in 2015, several of these bankers moved to other lenders in Estonia, where investigators ","{""viewport"": ""width=device-width, initial-scale=1"", ""description"": ""Investigators allege 19 bankers laundered more than $1.6 billion of illicit funds, some of it from a huge Russian tax evasion scheme and a Facebook phishing scam."", ""og:type"": ""website"", ""og:title"": ""\u2018The Contract Factory\u2019: Inside Danske Bank Estonia\u2019s Money Laundering Machine"", ""og:description"": ""Investigators allege 19 bankers laundered more than $1.6 billion of illicit funds, some of it from a huge Russian tax evasion scheme and a Facebook phishing scam."", ""og:url"": ""https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-contract-factory-inside-danske-bank-estonias-money-laundering-machine"", ""og:site_name"": ""OCCRP"", ""og:locale"": ""en_US"", ""og:locale:alternate"": ""ru_RU"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""\u2018The Contract Factory\u2019: Inside Danske Bank Estonia\u2019s Money Laundering Machine"", ""twitter:description"": ""Investigators allege 19 bankers laundered more than $1.6 billion of illicit funds, some of it from a huge Russian tax evasion scheme and a Facebook phishing scam."", ""og:image"": ""https://www.occrp.org/processed/containers/assets/azerbaijanilaundromat/Contract-Factory-Top.jpg/d525450a1c07404942db3b2525a5fe3a/Contract-Factory-Top.jpg"", ""twitter:image"": ""https://www.occrp.org/processed/containers/assets/azerbaijanilaundromat/Contract-Factory-Top.jpg/d525450a1c07404942db3b2525a5fe3a/Contract-Factory-Top.jpg""}",,,,
https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-raw-data,The Raw Data | OCCRP,"‘The Contract Factory’: Inside Danske Bank Estonia’s Money Laundering MachineInvestigators allege 19 bankers laundered more than $1.6 billion of illicit funds, some of it from a huge Russian tax evasion scheme and a Facebook phishing scam. ‘The Contract Factory’: Inside Danske Bank Estonia’s Money Laundering Machine Azerbaijani Couple, Including President’s Cousin, Owns Properties Worth Millions in London and IbizaThe couple has agreed to forfeit over £4 million that they had received from the Azerbaijani Laundromat, a massive money laundering system, to the authorities. The properties will not be seized. Azerbaijani Couple, Including President’s Cousin, Owns Properties Worth Millions in London and Ibiza Jet-Setting DJ — and Cousin of Azerbaijan’s President Aliyev — Accused of Receiving Millions In Suspicious FundsU.K. investigators tied Izzat Khanim Javadova, known as Mikaela Jav, and her husband to the Azerbaijani Laundromat, a massive underground money movement system often used by Azerbaijan’s elite. This is the first time a member of the president’s family has been linked to it. Jet-Setting DJ — and Cousin of Azerbaijan’s President Aliyev — Accused of Receiving Millions In Suspicious Funds Data Analysis by Amy Guy, Friedrich Lindenberg, Lion SummerbellThe database below contains nearly 17,000 payments made to and from the four core UK-registered companies that made up the Azerbaijani Laundromat. Their bank accounts were held at the Estonian branch of Danske Bank and were obtained by Berlinske, an OCCRP partner. They cover the period form June 2012 until the end of 2014.The records provide a rare snapshot of where the money came from, where it went, who was involved and how it was spent. Not all details can be clearly seen, but the overall picture is crystal clear.The stories in the Azerbaijani Laundromat investigation are based in part on this data. OCCRP is sharing the full database here so that readers can do their own searches.DISCLAIMER: Please note that the database may contain legitimate business transactions, and that the presence of any name in this dataset does not necessarily imply any intentional wrongdoing.If you have any questions or interesting findings, please reach out to OCCRP at[email protected]. Data Analysis by Amy Guy, Friedrich Lindenberg, Lion SummerbellThe database below contains nearly 17,000 payments made to and from the four core UK-registered companies that made up the Azerbaijani Laundromat. Their bank accounts were held at the Estonian branch of Danske Bank and were obtained by Berlinske, an OCCRP partner. They cover the period form June 2012 until the end of 2014.The records provide a rare snapshot of where the money came from, where it went, who was involved and how it was spent. Not all details can be clearly seen, but the overall picture is crystal clear.The stories in the Azerbaijani Laundromat investigation are based in part on this data. OCCRP is sharing the full database here so that readers can do their own searches.DISCLAIMER: Please note that the database may contain legitimate business transactions, and that the presence of any name in this dataset does not necessarily imply any intentional wrongdoing.If you have any questions or interesting findings, please reach out to OCCRP at[email protected]. Data Analysis by Amy Guy, Friedrich Lindenberg, Lion Summerbell The database below contains nearly 17,000 payments made to and from the four core UK-registered companies that made up the Azerbaijani Laundromat. Their bank accounts were held at the Estonian branch of Danske Bank and were obtained by Berlinske, an OCCRP partner. They cover the period form June 2012 until the end of 2014. The records provide a rare snapshot of where the money came from, where it went, who was involved and how it was spent. Not all details can be clearly seen, but the overall picture is crystal clear. The stories in the Azerbaijani Laundromat investigation are based in part on this data. OCCRP is sharing the full database here so that readers can do their own searches. DISCLAIMER: Please note that the database may contain legitimate business transactions, and that the presence of any name in this dataset does not necessarily imply any intentional wrongdoing. If you have any questions or interesting findings, please reach out to OCCRP at[email protected]. September 4, 2017September 4, 2017 Join the fight.Hold power to account. Join the fight.Hold power to account. Support from readers like you helps OCCRP expose organized crime and corruption around the world. By donating, you’ll be directly supporting investigative journalism as a public good. You’ll also gain access to exclusive insights and benefits.","{""viewport"": ""width=device-width, initial-scale=1"", ""og:type"": ""website"", ""og:title"": ""The Raw Data"", ""og:url"": ""https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-raw-data"", ""og:site_name"": ""OCCRP"", ""og:locale"": ""en_US"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""The Raw Data""}",,,,
https://blog.opencorporates.com/2025/02/13/getting-started-with-the-opencorporates-api/,Getting started with the OpenCorporates API: A beginner’s guide – OpenCorporates,"Post author:Jackson TorchiaPost published:February 13, 2025Post category:Commercial/Resources/TechPost comments:0 CommentsHave you ever needed to look up information about companies across different countries? Whether you’re in business, government, or research, the OpenCorporates API provides a powerful way to access data about millions of companies worldwide. In this guide, we’ll walk through everything you need to know to start using the API.What is OpenCorporates?OpenCorporates is the largest open database of company information in the world. Our API lets you programmatically access:Basic company information (name, registration number, status)Company filings and documentsOfficer (director) informationCorporate relationships and networksIndustry classificationsAnd much moreGetting started1. Get your API keyBefore you can start making requests, you’ll need an API key:VisitOpenCorporates’ self-serve API pageChoose your planCreate a new accountSave your API token – you’ll need it for all requests2. Understanding the basicsThe API endpoint isapi.opencorporates.com. All requests should use HTTPS, and your API token should be included as a query parameter. Here’s the basic structure:https://api.opencorporates.com/v0.4/[endpoint]?api_token=YOUR_TOKEN_HERETo make a request from this endpoint you can use:Your internet browser directly.An API platform likePostman(recommended).3. Your first API requestLet’s start with something simple – looking up a company. Here’s how to find information about a specific company:https://api.opencorporates.com/v0.4/companies/gb/00102498?api_token=YOUR_TOKEN_HEREThis URL breaks down as:/v0.4– API version/companies– the endpoint/gb– jurisdiction code (Great Britain in this case)/00102498– company numberThe response will include:Company nameRegistration detailsCurrent statusRegistered addressOfficers (directors)Filing historyCommon use cases and examples1. Searching for companiesTo search for companies by name:https://api.opencorporates.com/v0.4/companies/search?q=tesla&api_token=YOUR_TOKEN_HEREThe search is designed to be flexible:Words can be in any order (“Barclays Bank” matches “Bank Barclays”)Additional words in company names are allowedCase-insensitiveIncludes matches in previous company namesYou can refine your search with parameters like:jurisdiction_code– limit to a specific country/regioninactive– include/exclude inactive companiesorder– sort by various fields2. Looking up company officersFind information about company directors and officers:https://api.opencorporates.com/v0.4/officers/search?q=john+smith&api_token=YOUR_TOKEN_HERE3. Understanding corporate networksExplore company relationships and corporate hierarchies:https://api.opencorporates.com/v0.4/companies/gb/00102498/network?api_token=YOUR_TOKEN_HEREBest practicesMonitor your usageUse the/account_statusendpoint to track your API callsStay within daily and monthly limitsConsider upgrading your plan if you need more callsError handlingCheck HTTP status codes200: Success401: Authentication error403: Rate limit exceeded404: Company not foundPerformance tipsUse thesparse=trueparameter when you don’t need full detailsCache responses when appropriateBatch requests when possibleWorking with the resultsThe API returns JSON by default. Here’s what a basic company response looks like:{ ""api_version"": ""0.4"", ""results"": { ""company"": { ""name"": ""EXAMPLE COMPANY LTD"", ""company_number"": ""12345678"", ""jurisdiction_code"": ""gb"", ""incorporation_date"": ""2020-01-01"", ""company_type"": ""Private Limited Company"", ""current_status"": ""Active"" } } }Common challenges and solutionsCompany not foundDouble-check the jurisdiction code and company numberTry searching by name insteadConsider if the company might be registered in a different jurisdictionRate limitingImplement exponential backoffMonitor your usage with /account_statusConsider caching frequently accessed dataData consistencyCompany identifiers vary by jurisdictionSome jurisdictions provide more data than othersAlways check theopencorporates_urlfield for the authoritative web pageNext stepsNow that you understand the basics, you might want to:Explore the moreadvanced endpointslikeindustry_codesandcorporate_groupingsBuild tools to monitor company changes using theeventsendpointIntegrate company data into your applicationsUse thefilings endpointto track company documents and changesResources and supportFullAPI documentationSupport: Check the OpenCorporates website forcontact informationUpdates: Monitor the API version endpoint for changesRemember, the OpenCorporates API is a powerful tool for accessing company data, but it’s important to use it responsibly and in accordance with theterms of service.Start with simple queries, test thoroughly, and gradually build up to more complex integrations.For help with particular use cases, feel free tospeak with us today.For more informationLearn more about how OpenCorporates’ data can help you understand corporate structures and manage risk. Reach out for a demo or explore our services.Contact usShare this:Click to share on X (Opens in new window)XClick to email a link to a friend (Opens in new window)EmailClick to share on Facebook (Opens in new window)FacebookClick to print (Opens in new window)PrintClick to share on LinkedIn (Opens in new window)LinkedInLike this:LikeLoading...RelatedTags:ai,api,artificial-intelligence,business,cybersecurity,economy,entityverification,finance,news,politics,programming,rest,small business,technology,VerificationYou Might Also LikeData Briefing: Introducing Guernsey Charities, Viet Nam, Texas and MoreNovember 15, 2018Introducing OpenCorporates: a new way of seeing businessDecember 15, 2010OpenCorporates is looking for a CTODecember 9, 2015Leave a ReplyCancel replyTwitter UpdatesTweets by opencorporatesOpenCorporates tweetsTweets by OpenCorporatesOur sitesOpenCorporatesOpen LEIsOpenCharitiesOpen Company Data IndexRecent PostsWhy is it so hard to find US Company data?How to Leverage Global Data (Without the Headache of a Global Database)Is your manual KYB process driving customers to competitors?The “piecing it all together” bottleneck holding back your insurance fraud investigationsYour vendor list is full of red flags. Can you find them before regulators do?Email SubscriptionEnter your email address to subscribe to this blog and receive notifications of new posts by email.Email AddressSign me up!Join 520 other subscribersSearch this blog Post author:Jackson TorchiaPost published:February 13, 2025Post category:Commercial/Resources/TechPost comments:0 CommentsHave you ever needed to look up information about companies across different countries? Whether you’re in business, government, or research, the OpenCorporates API provides a powerful way to access data about millions of companies worldwide. In this guide, we’ll walk through everything you need to know to start using the API.What is OpenCorporates?OpenCorporates is the largest open database of company information in the world. Our API lets you programmatically access:Basic company information (name, registration number, status)Company filings and documentsOfficer (director) informationCorporate relationships and networksIndustry classificationsAnd much moreGetting started1. Get your API keyBefore you can start making requests, you’ll need an API key:VisitOpenCorporates’ self-serve API pageChoose your planCreate a new accountSave your API token – you’ll need it for all requests2. Understanding the basicsThe API endpoint isapi.opencorporates.com. All requests should use HTTPS, and your API token should be included as a query parameter. Here’s the basic structure:https://api.opencorporates.com/v0.4/[endpoint]?api_token=YOUR_TOKEN_HERETo make a request from this endpoint you can use:Your internet browser directly.An API platform likePostman(recommended).3. Your first API requestLet’s start with something simple – looking up a company. Here’s how to find information about a specific company:https://api.opencorporates.com/v0.4/companies/gb/00102498?api_token=YOUR_TOKEN_HEREThis URL breaks down as:/v0.4– API version/companies– the endpoint/gb– jurisdiction code (Great Britain in this case)/00102498– company numberThe response will include:Company nameRegistration detailsCurrent statusRegistered addressOfficers (directors)Filing historyCommon use cases and examples1. Searching for companiesTo search for companies by name:https://api.opencorporates.com/v0.4/companies/search?q=tesla&api_token=YOUR_TOKEN_HEREThe search is designed to be flexible:Words can be in any order (“Barclays Bank” matches “Bank Barclays”)Additional words in company names are allowedCase-insensitiveIncludes matches in previous company namesYou can refine your search with parameters like:jurisdiction_code– limit to a specific country/regioninactive– include/exclude inactive companiesorder– sort by various fields2. Looking up company officersFind information about company directors and officers:https://api.opencorporates.com/v0.4/officers/search?q=john+smith&api_token=YOUR_TOKEN_HERE3. Understanding corporate networksExplore company relationships and corporate hierarchies:https://api.opencorporates.com/v0.4/companies/gb/00102498/network?api_token=YOUR_TOKEN_HEREBest practicesMonitor your usageUse the/account_statusendpoint to track your API callsStay within daily and monthly limitsConsider upgrading your plan if you need more callsError handlingCheck HTTP status codes200: Success401: Authentication error403: Rate limit exceeded404: Company not foundPerformance tipsUse thesparse=trueparameter when you don’t need full detailsCache responses when appropriateBatch requests when possibleWorking with the resultsThe API returns JSON by default. Here’s what a basic company response looks like:{ ""api_version"": ""0.4"", ""results"": { ""company"": { ""name"": ""EXAMPLE COMPANY LTD"", ""company_number"": ""12345678"", ""jurisdiction_code"": ""gb"", ""incorporation_date"": ""2020-01-01"", ""company_type"": ""Private Limited Company"", ""current_st","{""robots"": ""max-image-preview:large"", ""viewport"": ""width=device-width, initial-scale=1"", ""generator"": ""Elementor 3.29.1; features: e_font_icon_svg, additional_custom_breakpoints, e_local_google_fonts, e_element_cache; settings: css_print_method-external, google_font-enabled, font_display-swap"", ""description"": ""Have you ever needed to look up information about companies across different countries? Whether you're in business, government, or research, the OpenCorporates API provides a powerful way to access data about millions of companies worldwide. In this guide, we'll walk through everything you need to know to start using the API."", ""og:type"": ""article"", ""og:title"": ""Getting started with the OpenCorporates API: A beginner\u2019s guide"", ""og:url"": ""https://blog.opencorporates.com/2025/02/13/getting-started-with-the-opencorporates-api/"", ""og:description"": ""Have you ever needed to look up information about companies across different countries? Whether you\u2019re in business, government, or research, the OpenCorporates API provides a powerful way to \u2026"", ""article:published_time"": ""2025-02-13T12:49:47+00:00"", ""article:modified_time"": ""2025-02-13T12:49:47+00:00"", ""og:site_name"": ""OpenCorporates"", ""og:image"": ""https://i0.wp.com/blog.opencorporates.com/wp-content/uploads/2025/02/api-start.jpg?fit=1000%2C675&ssl=1"", ""og:image:width"": ""1000"", ""og:image:height"": ""675"", ""og:locale"": ""en_US"", ""twitter:text:title"": ""Getting started with the OpenCorporates API: A beginner\u2019s guide"", ""twitter:image"": ""https://i0.wp.com/blog.opencorporates.com/wp-content/uploads/2025/02/api-start.jpg?fit=1000%2C675&ssl=1&w=640"", ""twitter:card"": ""summary_large_image"", ""msapplication-TileImage"": ""https://i0.wp.com/blog.opencorporates.com/wp-content/uploads/2017/10/cropped-oc-logo-square-cropped-1024x830.png?fit=270%2C270&ssl=1"", ""numberOfItems"": ""6"", ""itemListOrder"": ""Ascending""}",,,,
https://www.buzzsprout.com/242645/episodes/16799543,The sharing of suspicion,"The Dark Money FilesA series of podcasts which explain to a non-technical audience how ""Dark Money"" (e.g. money laundering, corruption, bribery, tax evasion) enters the financial system and infects everything it touches.Show MoreAll EpisodesThe Dark Money FilesThe sharing of suspicionMarch 16, 2025•Graham Barrow and Ray Blake•Season 12•Episode 3ShareShare episodeCopyStart atShow NotesChaptersSARs!Search and rescue services?Subject access requests?Sudden acute respiratory syndrome?No - suspicious activity reports! That's what we are talking about this time. And there's a lot more to them than you might think.Send us a textSupport the showFollow us on LinkedIn athttps://www.linkedin.com/company/the-dark-money-files-ltd/on Twitter athttps://twitter.com/dark_filesor see our website athttps://www.thedarkmoneyfiles.com/The Dark Money Files +Help us continue making great content for listeners everywhere.SupportStarting at $3/monthFollowApple PodcastsSpotifyAmazon MusicRSS FeedSee All The sharing of suspicion Search and rescue services? Subject access requests? Sudden acute respiratory syndrome? No - suspicious activity reports! That's what we are talking about this time. And there's a lot more to them than you might think. Follow us on LinkedIn athttps://www.linkedin.com/company/the-dark-money-files-ltd/on Twitter athttps://twitter.com/dark_filesor see our website athttps://www.thedarkmoneyfiles.com/ The Dark Money Files +","{""keywords"": ""Money Laundering, Dark Money, Corruption, Tax Evasion, AML, Financial Crime"", ""viewport"": ""width=device-width, initial-scale=1"", ""csrf-param"": ""authenticity_token"", ""csrf-token"": ""T1tl-r4_atYRq0FqUSzHDzWVWxEvehOTs83nSXGZZ7WqSq1EU49LbgyeWDpZPKXfQiB8e_jbe19sBbvV4SsP9Q"", ""description"": ""SARs!Search and rescue services?Subject access requests?Sudden acute respiratory syndrome?No - suspicious activity reports! That's what we are talking about this time. And there's a lot more to them than you might think."", ""og:site_name"": ""Buzzsprout"", ""og:url"": ""https://www.buzzsprout.com/242645/episodes/16799543"", ""og:title"": ""The sharing of suspicion - The Dark Money Files"", ""og:description"": ""SARs!Search and rescue services?Subject access requests?Sudden acute respiratory syndrome?No - suspicious activity reports! That's what we are talking about this time. And there's a lot more to them than you might think."", ""og:type"": ""video.episode"", ""og:image"": ""https://www.buzzsprout.com/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBMUl0R2c9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--341e8a9893774eedb95983c51b21ea517be54258/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdDVG9MWm05eWJXRjBPZ2hxY0djNkUzSmxjMmw2WlY5MGIxOW1hV3hzV3docEFmcHBBZnA3QmpvSlkzSnZjRG9MWTJWdWRISmxPZ3B6WVhabGNuc0dPZ3h4ZFdGc2FYUjVhVUU2RUdOdmJHOTFjbk53WVdObFNTSUpjM0puWWdZNkJrVlUiLCJleHAiOm51bGwsInB1ciI6InZhcmlhdGlvbiJ9fQ==--bfdad5b04912fa8a9db85eb3989e46c5908e2723/dmf%20new%20cover.jpg"", ""og:image:width"": ""250"", ""og:image:height"": ""250"", ""fb:app_id"": ""58375489563"", ""twitter:card"": ""player"", ""twitter:site"": ""@buzzsprout"", ""twitter:title"": ""The sharing of suspicion - The Dark Money Files"", ""twitter:description"": ""SARs!Search and rescue services?Subject access requests?Sudden acute respiratory syndrome?No - suspicious activity reports! That's what we are talking about this time. And there's a lot more to them than you might think."", ""twitter:image"": ""https://www.buzzsprout.com/rails/active_storage/representations/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBMUl0R2c9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--341e8a9893774eedb95983c51b21ea517be54258/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdDam9MWm05eWJXRjBPZ2hxY0djNkUzSmxjMmw2WlY5MGIxOW1hV3hzV3docEFuZ0ZhUUo0QlhzR09nbGpjbTl3T2d0alpXNTBjbVU2RUdSbFptRjFiSFJmZFhKc1NTSTVhSFIwY0hNNkx5OTNkM2N1WW5WNmVuTndjbTkxZEM1amIyMHZhVzFoWjJWekwyRnlkSGR2Y210elgyeGhjbWRsTG1wd1p3WTZCa1ZVT2dwellYWmxjbnNHT2d4eGRXRnNhWFI1YVVFNkVHTnZiRzkxY25Od1lXTmxTU0lKYzNKbllnWTdDMVE9IiwiZXhwIjpudWxsLCJwdXIiOiJ2YXJpYXRpb24ifX0=--2a89ede784d6e184500689d6dcbd55b204c8d4ad/dmf%20new%20cover.jpg"", ""twitter:player"": ""https://www.buzzsprout.com/242645/episodes/16799543-the-sharing-of-suspicion?client_source=twitter_card&player_type=full_screen"", ""twitter:player:width"": ""500"", ""twitter:player:height"": ""210"", ""twitter:player:stream"": ""https://dts.podtrac.com/redirect.mp3/www.buzzsprout.com/242645/episodes/16799543-the-sharing-of-suspicion.mp3?client_source=twitter_card"", ""twitter:player:stream:content_type"": ""audio/mp3"", ""apple-itunes-app"": ""app-id=1448635132""}",,,,
https://www.unodc.org/unodc/en/data-and-analysis/tip-studies.html,Study on Trafficking in Persons and Smuggling of Migrants in the Context of the Displacement caused by the War in Ukraine,"Office on Drugs and Crime Study on Trafficking in Persons and Smuggling of Migrants in the Context of the Displacement caused by the War against Ukraine Trafficking in persons, smuggling of migrants and the war against Ukraine The war against Ukraine has resulted in millions of people being displaced internally and outside the country since February 2022. This UNODC study, launched in February 2025, examines the risks and incidence of trafficking in persons and smuggling of migrants in the context of the displacement caused by the war against Ukraine, and the implications for policy and practice. The research analyses the evolution of trafficking in persons and smuggling of migrants during the years 2022 to 2024, based on relevant literature, statistics, a survey in 2023 of over 1,600 Ukrainians and non-Ukrainians displaced from Ukraine and key informant interviews in Ukraine, Germany, Poland and Switzerland. The study finds that the incidence of smuggling of migrants and trafficking in persons in the context of the displacement remain relatively low as of the time of publication. The refugee response in Europe – maintaining visa-free entry for refugees from Ukraine and facilitating rapid access to temporary protection or equivalent legal residence statuses – largely prevented smuggling of migrants, in a situation where over 6.7 million people from Ukraine sought refuge abroad. Targeted information campaigns, increased efforts to identify victims of trafficking, law enforcement cooperation and other anti-trafficking policies and actions by state and non-state actors, in Ukraine and in countries of transit and destination, may have further strengthened resilience. These measures also show significant potential for adaptation and application to other refugee displacements and migration movements in Europe and elsewhere. Nevertheless, precarious employment and accommodation situations in host countries make refugees from Ukraine vulnerable to trafficking for forced labour. The involvement of Ukrainian refugee women in prostitution and sex work in host countries also presents indications of vulnerability and sexual exploitation, including online. Read the full study here inEnglishorUkrainian. Download the special points of interest here inEnglishorUkrainian. Data and analysis for the UNODC Global Report on Trafficking in Persons is availablehere. UNODC’s data on detected victims of trafficking in persons as well as on trafficking offenders can be downloaded from the UNODC data portal,dataUNODC. The UNODC Observatory on Smuggling of Migrants can be accessedhere","{""msapplication-TileColor"": ""#2b5797"", ""theme-color"": ""#ffffff"", ""viewport"": ""width=device-width, initial-scale=1, shrink-to-fit=no"", ""og:title"": ""Study on Trafficking in Persons and Smuggling of Migrants in the Context of the Displacement caused by the War in Ukraine"", ""og:url"": ""//www.unodc.org/unodc/en/data-and-analysis/tip-studies.html"", ""og:site_name"": ""United Nations : Office on Drugs and Crime"", ""twitter:card"": ""summary_large_image"", ""og:description"": ""Study on Trafficking in Persons and Smuggling of Migrants in the Context of the Displacement caused by the War in Ukraine"", ""keywords"": ""Study on Trafficking in Persons and Smuggling of Migrants in the Context of the Displacement caused by the War in Ukraine""}",,,,
https://www.which.co.uk/news/article/scam-empire-inside-the-275m-fraud-call-centre-operations-aP3Kc4c9HWd7,Scam Empire: inside the $275m fraud call-centre operations - Which?,"05 Mar 2025Scam Empire: the $275m scam call-centres flogging bogus investmentsA new report lifts the lid on two major investment scam call centres that left almost 33,000 victims reelingCCChiara CavaglieriSenior researcher & writerTwo major call centre operations are running commercial-scale investment frauds worth at least $275m, affecting 32,934 victims across 33 different countries to date, according to a new report.TheScam Empireinvestigation is a collaborative effort by the Organized Crime and Corruption Reporting Project (OCCRP), Swedish Television and various media outlets, based on 1.9 terabytes of leaked data – including 20,000 screen recordings and over 20,000 hours of audio calls – shared by an anonymous source.Here we take you through the findings, explaining why fraud victims can't wait any longer for tech companies to face stronger regulations and sharing simple tips to help you spot an investment scam.Sign up for scam alertsOur emails will alert you to scams doing the rounds, and provide practical advice to keep you one step ahead of fraudsters.Sign up for scam alertsThe scam call centresTwo call centre operations were found to be running essentially the same scam, using similar training materials, scripts, and contracts with vendors.One is the 'A.K. Group' with at least three offices in Tbilisi, the capital of Georgia, which employed around 85 people as of April 2024. A second operation had offices in Israel, Bulgaria, Ukraine, Spain and Cyprus, employing at least 480 people as of August 2023.The call centres pushed dozens of branded investment platforms, offering investments in cryptocurrency, stocks like Tesla, or other appealing financial products.Reporters forScam Empirecontacted 182 people listed as having 'invested' money, more than 90% of whom (166 people) said they had been the victims of a scam. Even more compelling is the 20,000 hours of recorded phone calls, giving 'every indication that both operations were designed to scam large numbers of people'.Call centre staff reportedly used false identities, forged paperwork, and deceptive online advertising to entice investors. The report details staff swapping jokes and gloating about victims with each other on Telegram and Skype, as well as lavish parties and performance bonuses to celebrate their 'wins'.An investigator from Spain’s Mossos d’Esquadra, the Catalonian police, said call centres can be more lucrative than trafficking drugs because the margins are higher and the risks of being caught are much lower.Read more:how we exposed a global AI scamInvestment fraud tacticsTheScam Empirereport found that major tech companies profited from online adverts that pushed victims into these rogue investment schemes.Which? has warned for years that fraudsters use social media and online advertising as hunting grounds. We exposed Google and Microsoft's Bing for lettingscammers take out via paid-for advertsto peddle fake investments in 2021 andcalled out Facebookfor letting the same scammers repeatedly take out advertising in 2022.More recently, official bank data revealed that more than half of bank transfer scams recorded in 2023originated on Facebook, Instagram or WhatsApp, all of which are owned by parent company Meta.Remote access and screen sharing apps were also cited in theScam Empirereport, something wewarned about in 2020. Although AnyDesk is a legitimate provider, OCCRP found that call centre scammers commonly used it to access vast amounts of personal information from their victims’ computers.AnyDesk said it is 'tirelessly working to prevent' the use of its software by scammers and worked closely with law enforcement to fight against scam call centres, including adding a warning for first-time connections from suspicious accounts, though it acknowledged 'a large portion of these attacks involve social engineering where a victim is coached around these automated countermeasures we put in place'.In response to the report's findings, Google said: 'We expressly prohibit scam ads on our platforms and take swift action to suspend the offending advertiser’s account when applicable.' Meta said: 'It is against our policies to run ads that promote or facilitate scams. We stand ready to review and take action if we find violations of our policies.'Find out more:millions scammed on Facebook, Google and Instagram despite fraud pledgeFollowing the money – why don't banks stop payments?Victims were encouraged to make payments using cryptocurrencies or less strictly regulated digital payment providers and coached to bypass security checks from banking staff.The Guardianreported that Revolut, which received a UK banking licence last year, was the most mentioned (linked to 119 customers out of 403 listed in an internal Georgian call centre spreadsheet), followed by Kroo (involved with 50 victims).Last year, we expressed our concerns about how oftenRevolut is mentioned in fraud reportsto Which?. Victims are often encouraged to move money to the digital e-money provider first before being transferred again to cryptocurrency exchanges and other accounts that are difficult to trace.The most recentWhich? survey of fraud victimsfound that nearly one in five people who inadvertently sent money to scammers used cryptocurrency exchanges.For British fraud victims this means they are far less likely to be eligible for reimbursement because existing protections for fraudulent transfers are limited to UK bank transfers, not money sent via other methods such as foreign bank accounts, cryptocurrency or money transfer apps (all heavily used by fraudsters).Tracing the money is nearly impossible. TheScam Empirereport found that money trails are so convoluted that it is usually impossible to determine their final destination.Which? contacted both Revolut and Kroo about the findings.A Revolut spokesperson said: 'Across Revolut's UK customer base in 2023, we found that 60% of all reported scam cases originated on Meta owned platforms like Facebook and WhatsApp, yet these firms have no role in warning customers of such scams, nor reimbursing victims.'What is urgently needed is for Meta and other social media companies to commit to supporting victims of fraud in the same way financial institutions do to stop fraud at the source. Revolut takes steps and works hard to keep customers safe. So should social media platforms.'A Kroo spokesperson told us: 'While Kroo has less recorded scam victims compared to the first bank on the list, we take this number seriously and are constantly investing in our people and processes to support customers and reduce rates of financial crime.'Unfortunately, digital banks are more likely to be targeted by scammers because of their online-only models and access to faster and more efficient payment systems, which is reflected by the number of digital banks featured in this table...No control we design will fully mitigate the risk of fraud, and we are working alongside other banks and law enforcement organisations to raise awareness of the problem.'Find out more:why victims who pay 'the wrong way' are left with nothingWhy we need the Online Safety Act nowRocio Concha, Which? director of policy and advocacy, said: 'This important investigation lays bare the cruelty and sophistication of international scam gangs and serves as a reminder that people do not fall victim to fraud because they are careless, but because they are ruthlessly targeted by criminals.'Fraudsters find it far too easy to exploit the many weak links in protections for UK consumers – from online banks and payment firms that facilitate payments without sufficient checks, to tech giants that allow scam adverts to flood platforms used by millions of us every day and telecoms networks which fail to prevent thousands of scam calls from abroad.'The government and regulators must get a grip on the UK’s fraud epidemic by ensuring online and social media firms stop scams from appearing in the first place. The Chancellor has asked big tech firms to report back in March on what they are doing to stop scammers from operating on their sites.'This investigation clearly shows that piecemeal intervention from tech firms is not enough to stop the flood of online fraud and greater regulation and enforcement is urgently needed. Under the current timetable for the Online Safety Act, firms in scope of the fraudulent advertising duties in the Act will not be held accountable for many of the scam ads on their sites until 2027. This is simply not good enough. The Online Safety Act needs to be implemented in full as possible or the government risks letting millions more fall victim to online fraud.'key informationHow to avoid investment scamsScam Empiresays most victims are lured in by online advertisements found on Google, Facebook, or YouTube.Ads using high-tech buzzwords such as 'quantum computing', 'artificial intelligence', 'bitcoin' and 'cryptocurrency' are a red flag. Don't be swayed by news articles that promote these same products either, as these are easily faked and often citebogus celebrity endorsementfrom the likes of Elon Musk and Martin Lewis.Follow more tips from Which? to help youspot an investment scam.Ignore unexpected offersOpportunities that come to you out of the blue, whether via a cold call, online advert or through the post, are likely to be either very high-risk or an outright scam. Even if you initiated the contact yourself, don't assume you're dealing with a legitimate firm.Check the scams warning listThis can be found at fca.org.uk/scamsmart/warning-list and it's where the regulator records details of firms it knows are operating without permission or running scams. But even if a firm isn't on the list, this doesn't mean it's not a scam.Check the Financial Services RegisterThis can be found at fca.org.uk/register and it will help you to see if you're dealing with a genuine, authorised firm. Access the register via the FCA website, rather than via an email link or website of a fir","{""twitter:title"": ""Scam Empire: the $275m scam call-centres flogging bogus investments - Which?"", ""og:title"": ""Scam Empire: the $275m scam call-centres flogging bogus investments - Which?"", ""twitter:image"": ""https://media.product.which.co.uk/prod/images/ar_2to1_1500x750/7959885b2b76-scam-empire.jpg"", ""twitter:image:alt"": ""Scam Empire: the $275m scam call-centres flogging bogus investments"", ""og:image"": ""https://media.product.which.co.uk/prod/images/ar_2to1_1500x750/7959885b2b76-scam-empire.jpg"", ""description"": ""A new report lifts the lid on two major investment scam call centres that left close to 33,000 victims reeling from losses of $275m."", ""og:description"": ""A new report lifts the lid on two major investment scam call centres that left almost 33,000 victims reeling"", ""twitter:description"": ""A new report lifts the lid on two major investment scam call centres that left almost 33,000 victims reeling"", ""twitter:card"": ""summary_large_image"", ""twitter:site"": ""@whichuk"", ""twitter:creator"": ""@whichuk"", ""twitter:url"": ""https://www.which.co.uk/news/article/scam-empire-inside-the-275m-fraud-call-centre-operations-aP3Kc4c9HWd7"", ""og:type"": ""website"", ""og:url"": ""https://www.which.co.uk/news/article/scam-empire-inside-the-275m-fraud-call-centre-operations-aP3Kc4c9HWd7"", ""og:site_name"": ""Which?"", ""og:locale"": ""en_GB"", ""language"": ""en"", ""country"": ""GB"", ""bingbot"": ""noarchive"", ""fb:app_id"": ""320949621749168"", ""robots"": ""index, follow"", ""author"": ""Chiara Cavaglieri"", ""theme-color"": ""#ffffff"", ""viewport"": ""width=device-width, initial-scale=1"", ""referrer"": ""strict-origin-when-cross-origin""}",,,,
https://www.occrp.org/en/project/scam-empire/scam-operations-relied-on-third-party-marketing-companies-for-steady-stream-of-potential-victims,Scam Operations Relied on Third-Party Marketing Companies for Steady Stream of Potential Victims | OCCRP,"Scam Operations Relied on Third-Party Marketing Companies for Steady Stream of Potential Victims Two professional scam call-center operations depended on affiliate marketing firms to supply them with contact details of people who had clicked on ads for phony investment platforms. The marketers were only paid if the victims — some of whom went on to lose their life savings — were ensnared. Banner: James O'Brien/OCCRP Key FindingsLeaked files revealed hundreds of people and companies who provided third-party marketing services to two scam call center operations, one based in Georgia and the other run from Israel and Europe.The marketers’ identities were often obscured behind brand names, offshore companies, Telegram handles, and even fake employee profiles, but reporters connected multiple marketing companies to specific scam victims.The scam centers appear to have paid the marketers millions of dollars every year for their services. Leaked files revealed hundreds of people and companies who provided third-party marketing services to two scam call center operations, one based in Georgia and the other run from Israel and Europe.The marketers’ identities were often obscured behind brand names, offshore companies, Telegram handles, and even fake employee profiles, but reporters connected multiple marketing companies to specific scam victims.The scam centers appear to have paid the marketers millions of dollars every year for their services. Huge Ecosystem of Unregulated Payment Providers Helps Scammers Collect Victims’ MoneyLeaked documents reveal how scam call centers drew on a secret industry of service providers that used shell companies, proxy account holders, and sham paperwork to receive funds from their victims through accounts at major commercial banks, or turn it into cryptocurrency. Huge Ecosystem of Unregulated Payment Providers Helps Scammers Collect Victims’ Money Diamonds, Dior and Dubai Vacations: The Luxurious Lives of Georgia's Call-Center ScammersThey called themselves “skameri.” In behind-the-scenes chats, they celebrated bilking victims out of their life savings and spent their earnings on lavish vacations, jewelry, and cars. They bragged that they would never be caught. But we tracked them down. Diamonds, Dior and Dubai Vacations: The Luxurious Lives of Georgia's Call-Center Scammers Everything You Need to Know About 'Scam Empire'How many scam operations did reporters reveal? Who leaked the data? What's the evidence these are scams and not legitimate platforms? Here are the answers to the most important questions about the 'Scam Empire' project. Everything You Need to Know About 'Scam Empire' It was Tuesday, and that meant payday. Logging into a series of chat groups on encrypted messenger app Telegram, Ben — not his real name, but an alias — reminded the marketers he was helping to oversee that it was time to claim their earnings.“Share invoice plz,” he wrote in one group.“Please do it as fast as possible,” he wrote in another. “We need to send u money.”As invoices poured in, Ben posted an animated GIF from the 1970s Disney cartoon movie Robin Hood, showing the title character dressed as a beggar, asking for a few coins.The invoices were for leads that the marketers had provided to Ben and his colleagues. In marketing, the term ‘lead’ usually refers to a potential client. But these leads were much more sinister. These were potential victims. It was Tuesday, and that meant payday. Logging into a series of chat groups on encrypted messenger app Telegram, Ben — not his real name, but an alias — reminded the marketers he was helping to oversee that it was time to claim their earnings.“Share invoice plz,” he wrote in one group.“Please do it as fast as possible,” he wrote in another. “We need to send u money.”As invoices poured in, Ben posted an animated GIF from the 1970s Disney cartoon movie Robin Hood, showing the title character dressed as a beggar, asking for a few coins.The invoices were for leads that the marketers had provided to Ben and his colleagues. In marketing, the term ‘lead’ usually refers to a potential client. But these leads were much more sinister. These were potential victims. It was Tuesday, and that meant payday. Logging into a series of chat groups on encrypted messenger app Telegram, Ben — not his real name, but an alias — reminded the marketers he was helping to oversee that it was time to claim their earnings. “Share invoice plz,” he wrote in one group. “Please do it as fast as possible,” he wrote in another. “We need to send u money.” As invoices poured in, Ben posted an animated GIF from the 1970s Disney cartoon movie Robin Hood, showing the title character dressed as a beggar, asking for a few coins. The invoices were for leads that the marketers had provided to Ben and his colleagues. In marketing, the term ‘lead’ usually refers to a potential client. But these leads were much more sinister. These were potential victims. A screenshot showing ""Ben""'s chat with the affiliate marketers he manages. A screenshot showing ""Ben""'s chat with the affiliate marketers he manages. Ben and his colleagues worked for a group of call centers running a massive scam operation. The agents who worked there spent their days hoodwinking victims into believing they would make great returns if they invested in cryptocurrencies or other financial products on their platforms. This was a smokescreen — in reality, in the vast majority of cases reviewed by reporters, their money would simply vanish.In order to keep the con going, the scammers needed a steadily incoming stream of potential victims.An unprecedented leak from the heart of a merciless investment scam industry that stretches across the globe reveals how they get them: An ecosystem of marketing companies, known as affiliate marketers, serves up contact details in return for lucrative commissions.The 1.9-terabyte leak that forms the basis of this investigation was obtained by Swedish Television (SVT) and shared with OCCRP and 30 international media outlets. It reveals the inner workings of two groups of call centers: One based in Georgia, and another much larger operation with at least seven offices in Israel, Bulgaria, Ukraine, Spain, and Cyprus.The leaked records show that the marketers that supplied these scammers with leads were richly rewarded. Every lead who ended up making a deposit with the scammers was worth between $200 and $2,350, depending on which country they were from. Victims from wealthier nations like the Netherlands, Sweden, or Belgium were worth more.Records found in the leak show that, in the first seven months of 2024, affiliate marketers working with Ben’s operation — the Israeli/European group — were paid at least $7.3 million for leads. Over the same time period in 2023, they earned more than $10.3 million. Ben and his colleagues worked for a group of call centers running a massive scam operation. The agents who worked there spent their days hoodwinking victims into believing they would make great returns if they invested in cryptocurrencies or other financial products on their platforms. This was a smokescreen — in reality, in the vast majority of cases reviewed by reporters, their money would simply vanish.In order to keep the con going, the scammers needed a steadily incoming stream of potential victims.An unprecedented leak from the heart of a merciless investment scam industry that stretches across the globe reveals how they get them: An ecosystem of marketing companies, known as affiliate marketers, serves up contact details in return for lucrative commissions.The 1.9-terabyte leak that forms the basis of this investigation was obtained by Swedish Television (SVT) and shared with OCCRP and 30 international media outlets. It reveals the inner workings of two groups of call centers: One based in Georgia, and another much larger operation with at least seven offices in Israel, Bulgaria, Ukraine, Spain, and Cyprus.The leaked records show that the marketers that supplied these scammers with leads were richly rewarded. Every lead who ended up making a deposit with the scammers was worth between $200 and $2,350, depending on which country they were from. Victims from wealthier nations like the Netherlands, Sweden, or Belgium were worth more.Records found in the leak show that, in the first seven months of 2024, affiliate marketers working with Ben’s operation — the Israeli/European group — were paid at least $7.3 million for leads. Over the same time period in 2023, they earned more than $10.3 million. Ben and his colleagues worked for a group of call centers running a massive scam operation. The agents who worked there spent their days hoodwinking victims into believing they would make great returns if they invested in cryptocurrencies or other financial products on their platforms. This was a smokescreen — in reality, in the vast majority of cases reviewed by reporters, their money would simply vanish. In order to keep the con going, the scammers needed a steadily incoming stream of potential victims. An unprecedented leak from the heart of a merciless investment scam industry that stretches across the globe reveals how they get them: An ecosystem of marketing companies, known as affiliate marketers, serves up contact details in return for lucrative commissions. The 1.9-terabyte leak that forms the basis of this investigation was obtained by Swedish Television (SVT) and shared with OCCRP and 30 international media outlets. It reveals the inner workings of two groups of call centers: One based in Georgia, and another much larger operation with at least seven offices in Israel, Bulgaria, Ukraine, Spain, and Cyprus. The leaked records show that the marketers that supplied these scammers with leads were richly rewarded. Every lead who ended up making a deposit with the scammers was worth between $200 and $2,350, depending on which country they were from. Victims from wealthier nations like the Netherlands, Sweden, o","{""viewport"": ""width=device-width, initial-scale=1"", ""description"": ""Two professional scam call-center operations depended on affiliate marketing firms to supply them with contact details of people who had clicked on ads for phony investment platforms. The marketers were only paid if the victims \u2014 some of whom went on to lose their life savings \u2014 were ensnared."", ""og:type"": ""website"", ""og:title"": ""Scam Operations Relied on Third-Party Marketing Companies for Steady Stream of Potential Victims"", ""og:description"": ""Two professional scam call-center operations depended on affiliate marketing firms to supply them with contact details of people who had clicked on ads for phony investment platforms. The marketers were only paid if the victims \u2014 some of whom went on to lose their life savings \u2014 were ensnared."", ""og:url"": ""https://www.occrp.org/en/project/scam-empire/scam-operations-relied-on-third-party-marketing-companies-for-steady-stream-of-potential-victims"", ""og:site_name"": ""OCCRP"", ""og:locale"": ""en_US"", ""og:locale:alternate"": ""ru_RU"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""Scam Operations Relied on Third-Party Marketing Companies for Steady Stream of Potential Victims"", ""twitter:description"": ""Two professional scam call-center operations depended on affiliate marketing firms to supply them with contact details of people who had clicked on ads for phony investment platforms. The marketers were only paid if the victims \u2014 some of whom went on to lose their life savings \u2014 were ensnared."", ""og:image"": ""https://www.occrp.org/processed/containers/assets/investigations/scam-empire/scam-empire-affiliates-final2.jpg/3d8ee6be1d9cfac8dde71f811876ad98/scam-empire-affiliates-final2.jpg"", ""twitter:image"": ""https://www.occrp.org/processed/containers/assets/investigations/scam-empire/scam-empire-affiliates-final2.jpg/3d8ee6be1d9cfac8dde71f811876ad98/scam-empire-affiliates-final2.jpg""}",,,,
https://github.com/DAD-CDM/dad-cdm-tsc/blob/main/DAD-CDM-Key-Findings-202502.md,dad-cdm-tsc/DAD-CDM-Key-Findings-202502.md at main · DAD-CDM/dad-cdm-tsc · GitHub,DAD-CDM/dad-cdm-tscPublicNotificationsYou must be signed in to change notification settingsFork1Star4,"{""route-pattern"": ""/:user_id/:repository/blob/*name(/*path)"", ""route-controller"": ""blob"", ""route-action"": ""show"", ""fetch-nonce"": ""v2:e5b92c3f-d96b-e108-88b4-527b5b9aee6e"", ""current-catalog-service-hash"": ""f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb"", ""request-id"": ""E6FC:22595F:B18874:F962B0:6839E2C1"", ""html-safe-nonce"": ""1ee6aafd71229ec4091a461ffa4c6293290a5d1cfed8bdeadb1249bec35f404f"", ""visitor-payload"": ""eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJFNkZDOjIyNTk1RjpCMTg4NzQ6Rjk2MkIwOjY4MzlFMkMxIiwidmlzaXRvcl9pZCI6Ijg2ODg3NzI5NTgxNDQ1NTM2NjUiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ=="", ""visitor-hmac"": ""63ddca9412c338e8284aaff00b168bb7e7d5289e2c1c5112f5264acd21557d52"", ""hovercard-subject-tag"": ""repository:947956781"", ""github-keyboard-shortcuts"": ""repository,source-code,file-tree,copilot"", ""google-site-verification"": ""Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I"", ""octolytics-url"": ""https://collector.github.com/github/collect"", ""analytics-location"": ""/<user-name>/<repo-name>/blob/show"", ""viewport"": ""width=device-width"", ""description"": ""Repository for the work of the DAD-CDM Technical Steering Committee (TSC) - dad-cdm-tsc/DAD-CDM-Key-Findings-202502.md at main \u00b7 DAD-CDM/dad-cdm-tsc"", ""fb:app_id"": ""1401488693436528"", ""apple-itunes-app"": ""app-id=1477376905, app-argument=https://github.com/DAD-CDM/dad-cdm-tsc/blob/main/DAD-CDM-Key-Findings-202502.md"", ""twitter:image"": ""https://opengraph.githubassets.com/1c13876311a756fa1fa093b64a8e8f9f93bc2eb0791082b3486db3b6583e0737/DAD-CDM/dad-cdm-tsc"", ""twitter:site"": ""@github"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""dad-cdm-tsc/DAD-CDM-Key-Findings-202502.md at main \u00b7 DAD-CDM/dad-cdm-tsc"", ""twitter:description"": ""Repository for the work of the DAD-CDM Technical Steering Committee (TSC) - DAD-CDM/dad-cdm-tsc"", ""og:image"": ""https://opengraph.githubassets.com/1c13876311a756fa1fa093b64a8e8f9f93bc2eb0791082b3486db3b6583e0737/DAD-CDM/dad-cdm-tsc"", ""og:image:alt"": ""Repository for the work of the DAD-CDM Technical Steering Committee (TSC) - DAD-CDM/dad-cdm-tsc"", ""og:image:width"": ""1200"", ""og:image:height"": ""600"", ""og:site_name"": ""GitHub"", ""og:type"": ""object"", ""og:title"": ""dad-cdm-tsc/DAD-CDM-Key-Findings-202502.md at main \u00b7 DAD-CDM/dad-cdm-tsc"", ""og:url"": ""https://github.com/DAD-CDM/dad-cdm-tsc/blob/main/DAD-CDM-Key-Findings-202502.md"", ""og:description"": ""Repository for the work of the DAD-CDM Technical Steering Committee (TSC) - DAD-CDM/dad-cdm-tsc"", ""hostname"": ""github.com"", ""expected-hostname"": ""github.com"", ""turbo-cache-control"": ""no-cache"", ""go-import"": ""github.com/DAD-CDM/dad-cdm-tsc git https://github.com/DAD-CDM/dad-cdm-tsc.git"", ""octolytics-dimension-user_id"": ""138060244"", ""octolytics-dimension-user_login"": ""DAD-CDM"", ""octolytics-dimension-repository_id"": ""947956781"", ""octolytics-dimension-repository_nwo"": ""DAD-CDM/dad-cdm-tsc"", ""octolytics-dimension-repository_public"": ""true"", ""octolytics-dimension-repository_is_fork"": ""false"", ""octolytics-dimension-repository_network_root_id"": ""947956781"", ""octolytics-dimension-repository_network_root_nwo"": ""DAD-CDM/dad-cdm-tsc"", ""turbo-body-classes"": ""logged-out env-production page-responsive"", ""browser-stats-url"": ""https://api.github.com/_private/browser/stats"", ""browser-errors-url"": ""https://api.github.com/_private/browser/errors"", ""release"": ""994628876282f66f40ba0bae7848f6c92a1e1688"", ""theme-color"": ""#1e2327"", ""color-scheme"": ""light dark""}",,,,
https://bods-data.openownership.org/source/gleif_version_0_4/,Beneficial ownership data analysis tools,"Beneficial ownership data analysis tools GLEIF - BODS version 0.4(2025-03-11) TheGlobal Legal Entity Identifier Foundation(GLEIF) is tasked with supporting the implementation and use of the_Legal Entity Identifier (LEI). GLEIF “enables smarter, less costly and more reliable decisions about who to do business with” by providing “open, standardised and high quality legal entity reference data” to uniquely identify companies. This open data includes itsLevel 2 Dataon who owns whom. The corporate ownership data collected and published openly by GLEIF is not beneficial ownership data as it does not identify the natural persons at the end of ownership chains but Open Ownership has mapped a combination of Level 1 and Level 2 Data toversion 0.4 of our Beneficial Ownership Data Standardin order to analyse and learn more from layering this data on top of beneficial ownership data sources. On Github, you can see how Open Ownership hasmapped, transformed and republishedthis data in line with theBeneficial Ownership Data Standard. We have also published adata use guidewith information about how we have represented change over time and how specific fields have been mapped. These mappings are currently a work in progress and should be treated with caution. This dataset is published under theCreative Commons CC0 1.0 Universal (CC0 1.0) Public Domain Dedication licence. Downloads and links to hosted databases relationship_statement relationship_recorddetails_interests relationship_source_assertedby relationship_annotations entity_recorddetails_identifiers entity_recorddetails_addresses entity_source_assertedby Sample data from `relationship_statement` table. Sample data from `relationship_recorddetails_interests` table. Sample data from `relationship_source_assertedby` table. Sample data from `relationship_annotations` table. Sample data from `entity_statement` table. Sample data from `entity_annotations` table. Sample data from `entity_recorddetails_identifiers` table. Sample data from `entity_recorddetails_addresses` table. Sample data from `entity_source_assertedby` table.","{""viewport"": ""width=device-width, initial-scale=1, shrink-to-fit=no""}",,,,
https://eiti.org/using-eiti-data,Using EITI data | EITI,"Table of contentsEITI disclosures provide vital insights into the governance of natural resources, offering a foundation for accountability, transparency and better decision-making. EITI data can help governments, civil society and other stakeholders identify trends, address challenges and seize opportunities for reform. The examples below illustrate how data from EITI implementing countries has been used, by analysing specific data points relevant to each country’s unique context. In this way, EITI data can shine a light on key issues, sparking debates grounded in trusted data, and shaping policies that promote sustainable and equitable resource management.For more information on using EITI data, or to suggest other examples to include, contact the EITI data team at[email protected].Data use caseMali: License processing times3 Apr 2023Data use caseZambia: Comparing licensing rules vs practice15 Apr 2020Blog postSicomines: How the EITI in DRC helped secure 4 billion in additional revenue25 Mar 2024Blog postDigging deeper: How Armenia is leading the way in beneficial ownership transparency22 Oct 2024Data use caseRepublic of the Congo: Oil revenue projections6 Mar 2023Data use caseNigeria: Reforming extractive revenue collection1 Dec 2019Data use caseNigeria: Oil sales vs market price1 Jan 2023Data use caseRepublic of the Congo: Oil revenue projections6 Mar 2023Data use caseCôte d’Ivoire: Crude oil for natural gas swaps1 Jan 2023Blog postDemocratic Republic of the Congo: Pioneering reporting on state-owned extractive companies30 Jun 2021Data use caseIraq: Oil revenue sharing1 Jan 2023 Table of contentsEITI disclosures provide vital insights into the governance of natural resources, offering a foundation for accountability, transparency and better decision-making. EITI data can help governments, civil society and other stakeholders identify trends, address challenges and seize opportunities for reform. The examples below illustrate how data from EITI implementing countries has been used, by analysing specific data points relevant to each country’s unique context. In this way, EITI data can shine a light on key issues, sparking debates grounded in trusted data, and shaping policies that promote sustainable and equitable resource management.For more information on using EITI data, or to suggest other examples to include, contact the EITI data team at[email protected].Data use caseMali: License processing times3 Apr 2023Data use caseZambia: Comparing licensing rules vs practice15 Apr 2020Blog postSicomines: How the EITI in DRC helped secure 4 billion in additional revenue25 Mar 2024Blog postDigging deeper: How Armenia is leading the way in beneficial ownership transparency22 Oct 2024Data use caseRepublic of the Congo: Oil revenue projections6 Mar 2023Data use caseNigeria: Reforming extractive revenue collection1 Dec 2019Data use caseNigeria: Oil sales vs market price1 Jan 2023Data use caseRepublic of the Congo: Oil revenue projections6 Mar 2023Data use caseCôte d’Ivoire: Crude oil for natural gas swaps1 Jan 2023Blog postDemocratic Republic of the Congo: Pioneering reporting on state-owned extractive companies30 Jun 2021Data use caseIraq: Oil revenue sharing1 Jan 2023 EITI disclosures provide vital insights into the governance of natural resources, offering a foundation for accountability, transparency and better decision-making. EITI data can help governments, civil society and other stakeholders identify trends, address challenges and seize opportunities for reform. The examples below illustrate how data from EITI implementing countries has been used, by analysing specific data points relevant to each country’s unique context. In this way, EITI data can shine a light on key issues, sparking debates grounded in trusted data, and shaping policies that promote sustainable and equitable resource management.For more information on using EITI data, or to suggest other examples to include, contact the EITI data team at[email protected]. EITI disclosures provide vital insights into the governance of natural resources, offering a foundation for accountability, transparency and better decision-making. EITI data can help governments, civil society and other stakeholders identify trends, address challenges and seize opportunities for reform. The examples below illustrate how data from EITI implementing countries has been used, by analysing specific data points relevant to each country’s unique context. In this way, EITI data can shine a light on key issues, sparking debates grounded in trusted data, and shaping policies that promote sustainable and equitable resource management. For more information on using EITI data, or to suggest other examples to include, contact the EITI data team at[email protected]. Data use caseMali: License processing times3 Apr 2023Data use caseZambia: Comparing licensing rules vs practice15 Apr 2020 Mali: License processing times Zambia: Comparing licensing rules vs practice Blog postSicomines: How the EITI in DRC helped secure 4 billion in additional revenue25 Mar 2024 Sicomines: How the EITI in DRC helped secure 4 billion in additional revenue Blog postDigging deeper: How Armenia is leading the way in beneficial ownership transparency22 Oct 2024 Digging deeper: How Armenia is leading the way in beneficial ownership transparency Data use caseRepublic of the Congo: Oil revenue projections6 Mar 2023Data use caseNigeria: Reforming extractive revenue collection1 Dec 2019Data use caseNigeria: Oil sales vs market price1 Jan 2023 Republic of the Congo: Oil revenue projections Nigeria: Reforming extractive revenue collection Nigeria: Oil sales vs market price Data use caseRepublic of the Congo: Oil revenue projections6 Mar 2023 Republic of the Congo: Oil revenue projections Data use caseCôte d’Ivoire: Crude oil for natural gas swaps1 Jan 2023Blog postDemocratic Republic of the Congo: Pioneering reporting on state-owned extractive companies30 Jun 2021 Côte d’Ivoire: Crude oil for natural gas swaps Democratic Republic of the Congo: Pioneering reporting on state-owned extractive companies Data use caseIraq: Oil revenue sharing1 Jan 2023 Iraq: Oil revenue sharing","{""description"": ""Examples of how EITI disclosures are analysed and used to address key challenges and inform policies on natural resource governance."", ""og:site_name"": ""EITI"", ""og:title"": ""Using EITI data"", ""og:description"": ""Examples of how EITI disclosures are analysed and used to address key challenges and inform policies on natural resource governance."", ""og:image"": ""https://eiti.org/sites/default/files/styles/open_graph_image/public/2025-01/shutterstock_667598698.jpg?itok=ZcCBkPs6"", ""og:image:width"": ""1200"", ""og:image:height"": ""630"", ""og:image:alt"": ""Analysis of data graphs"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""Using EITI data"", ""twitter:description"": ""Examples of how EITI disclosures are analysed and used to address key challenges and inform policies on natural resource governance."", ""twitter:image:alt"": ""Analysis of data graphs"", ""twitter:image"": ""https://eiti.org/sites/default/files/styles/open_graph_image/public/2025-01/shutterstock_667598698.jpg?itok=ZcCBkPs6"", ""Generator"": ""Drupal 10 (https://www.drupal.org)"", ""MobileOptimized"": ""width"", ""HandheldFriendly"": ""true"", ""viewport"": ""width=device-width, initial-scale=1.0"", ""msapplication-TileColor"": ""#ffffff"", ""msapplication-TileImage"": ""/ms-icon-144x144.png"", ""theme-color"": ""#1e1e46""}",,,,
https://mweiti.gov.mw/index.php/reports/details/761,Report Details | Malawi Extractive Industry Transparency Initiative | MWEITI,"facebooktwitteryoutube Study and Other ReportsBeneficial Ownership Study ReportThe study report examines the legal, institutional and regulatory framework governing Malawi beneficial ownership disclosure. It identifies gaps and challenges related to accessibility of beneficial ownership information by various stakeholders, including competent authorities and law enforcement agencies in Malawi. It also provides recommendations on implementing beneficial ownership disclosure in accordance with EITI International standard, 2023.November 2024DownloadThere are no highlights Study and Other ReportsBeneficial Ownership Study ReportThe study report examines the legal, institutional and regulatory framework governing Malawi beneficial ownership disclosure. It identifies gaps and challenges related to accessibility of beneficial ownership information by various stakeholders, including competent authorities and law enforcement agencies in Malawi. It also provides recommendations on implementing beneficial ownership disclosure in accordance with EITI International standard, 2023.November 2024DownloadThere are no highlights Study and Other ReportsBeneficial Ownership Study ReportThe study report examines the legal, institutional and regulatory framework governing Malawi beneficial ownership disclosure. It identifies gaps and challenges related to accessibility of beneficial ownership information by various stakeholders, including competent authorities and law enforcement agencies in Malawi. It also provides recommendations on implementing beneficial ownership disclosure in accordance with EITI International standard, 2023.November 2024DownloadThere are no highlights Beneficial Ownership Study Report The study report examines the legal, institutional and regulatory framework governing Malawi beneficial ownership disclosure. It identifies gaps and challenges related to accessibility of beneficial ownership information by various stakeholders, including competent authorities and law enforcement agencies in Malawi. It also provides recommendations on implementing beneficial ownership disclosure in accordance with EITI International standard, 2023. NewsMining Industry in MalawiMon 28 Oct 2024The mining industry of Malawi, includes a number of gemstones and other minerals. The…Inadequate Power a Setback to Mining Industry in MalawiWed 25 Sep 2024Minister of Energy, Ibrahim Matola, says that Malawi has inadequate power for mining…Govt to rake in K238bn in Two Mining Deals SignedTue 30 Jul 2024Malawi is set to make about K238 billion from the decision of giving a go-ahead to…Government, Mining Companies Sign Mining Development AgreementsSun 28 Jul 2024Government through Ministry of Mining and Ministry of Finance has finally signed…Covid-19 Hits Extractive Industry HardFri 04 Jun 2021The year 2020 has been a very challenging one for the extractive industry, a report by…More News Mining Industry in MalawiMon 28 Oct 2024The mining industry of Malawi, includes a number of gemstones and other minerals. The…Inadequate Power a Setback to Mining Industry in MalawiWed 25 Sep 2024Minister of Energy, Ibrahim Matola, says that Malawi has inadequate power for mining…Govt to rake in K238bn in Two Mining Deals SignedTue 30 Jul 2024Malawi is set to make about K238 billion from the decision of giving a go-ahead to…Government, Mining Companies Sign Mining Development AgreementsSun 28 Jul 2024Government through Ministry of Mining and Ministry of Finance has finally signed…Covid-19 Hits Extractive Industry HardFri 04 Jun 2021The year 2020 has been a very challenging one for the extractive industry, a report by…More News Mining Industry in Malawi The mining industry of Malawi, includes a number of gemstones and other minerals. The… Inadequate Power a Setback to Mining Industry in Malawi Minister of Energy, Ibrahim Matola, says that Malawi has inadequate power for mining… Govt to rake in K238bn in Two Mining Deals Signed Malawi is set to make about K238 billion from the decision of giving a go-ahead to… Government, Mining Companies Sign Mining Development Agreements Government through Ministry of Mining and Ministry of Finance has finally signed… Covid-19 Hits Extractive Industry Hard The year 2020 has been a very challenging one for the extractive industry, a report by… ©MWEITI. Site developed byIdias Corporation Ltd ©MWEITI. Site developed byIdias Corporation Ltd","{""description"": ""The Ministry of Finance and Economic Affairs has the mandate to formulate economic and fiscal policies that seek to manage government financial and material resources and provide strategic guidance on economic and development planning"", ""keywords"": ""Ministry of Finance and Economic Affairs, Malawi, MoFEA, economic policies, fiscal policies, economic growth, economic development, macroeconomic stability, financial management, socio-economic development, Malawi, Malawi Government"", ""Generator"": ""Drupal 8 (https://www.drupal.org)"", ""MobileOptimized"": ""width"", ""HandheldFriendly"": ""true"", ""viewport"": ""width=device-width, initial-scale=1.0""}",,,,
https://globalenergymonitor.org/projects/global-energy-ownership-tracker/,Global Energy Ownership Tracker - Global Energy Monitor,"Global Energy Ownership TrackerThe Global Energy Ownership Tracker provides information on the chain of ownership for various energy projects. The data maps each level of the chain from the direct owner (as in, the lowest-level identified owner in the chain of ownership) up to their highest-level ultimate parents (e.g., corporations, investment firms, and governments). Ownership links are reported with the percentage of ownership, including owners that have controlling interest as well as those with minority, non-controlling interests (if over a threshold of 5% ownership).This asset ownership data set covers nine of GEM’s trackers:The Global Coal Plant TrackerThe Global Oil and Gas Plant TrackerThe Global Coal Mine TrackerThe Global Iron & Steel TrackerThe Global Bioenergy Plant TrackerThe Global Iron Ore Mines TrackerNatural Gas Transmission pipelines from theGlobal Gas Infrastructure TrackerCrude oil and natural gas liquid transmission pipelines from theGlobal Oil Infrastructure TrackerGlobal Cement and Concrete Tracker(coming soon shortly after the first Global Cement and Concrete Tracker release scheduled for July 2025)Details about how each tracker identifies their assets and what methodologies they follow can be found on each of their respective pages of the GEM website linked above.The Global Energy Ownership Tracker is updated after each new release of these underlying trackers. The most recent release of this data was in May 2025 and contains ownership data for Coal Plants, Oil and Gas Plants, Bioenergy Plants, Iron and Steel Plants, Coal Mines, Iron Ore Mines, and Natural Gas Pipelines.To learn about the various components of each GEM tracker, readAbout GEM’s Trackers. To receive notifications from this project, please sign up for ourmailing list. If you have questions about this project, pleasecontactthe Project Manager, Anna Mowat. The Global Energy Ownership Tracker provides information on the chain of ownership for various energy projects. The data maps each level of the chain from the direct owner (as in, the lowest-level identified owner in the chain of ownership) up to their highest-level ultimate parents (e.g., corporations, investment firms, and governments). Ownership links are reported with the percentage of ownership, including owners that have controlling interest as well as those with minority, non-controlling interests (if over a threshold of 5% ownership). This asset ownership data set covers nine of GEM’s trackers: Details about how each tracker identifies their assets and what methodologies they follow can be found on each of their respective pages of the GEM website linked above. The Global Energy Ownership Tracker is updated after each new release of these underlying trackers. The most recent release of this data was in May 2025 and contains ownership data for Coal Plants, Oil and Gas Plants, Bioenergy Plants, Iron and Steel Plants, Coal Mines, Iron Ore Mines, and Natural Gas Pipelines. To learn about the various components of each GEM tracker, readAbout GEM’s Trackers. To receive notifications from this project, please sign up for ourmailing list. If you have questions about this project, pleasecontactthe Project Manager, Anna Mowat.","{""viewport"": ""width=device-width, initial-scale=1, shrink-to-fit=no"", ""robots"": ""index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""Global Energy Ownership Tracker"", ""og:description"": ""The Global Energy Ownership Tracker provides information on the chain of ownership for various energy projects. The data maps each level of the chain from the direct owner (as in, the lowest-level identified owner in the chain of ownership) up to their highest-level ultimate parents (e.g., corporations, investment firms, and governments). Ownership links are reported \u2026 Continued"", ""og:url"": ""https://globalenergymonitor.org/projects/global-energy-ownership-tracker/"", ""og:site_name"": ""Global Energy Monitor"", ""article:modified_time"": ""2025-05-06T18:18:58+00:00"", ""og:image"": ""https://globalenergymonitor.org/wp-content/uploads/2024/03/Global-Energy-Ownership-Tracker-FIN-WEB.png"", ""og:image:width"": ""1540"", ""og:image:height"": ""856"", ""og:image:type"": ""image/png"", ""twitter:card"": ""summary_large_image"", ""twitter:site"": ""@GlobalEnergyMon"", ""twitter:label1"": ""Est. reading time"", ""twitter:data1"": ""2 minutes"", ""generator"": ""Give v4.2.0"", ""msapplication-TileImage"": ""https://globalenergymonitor.org/wp-content/uploads/2020/12/cropped-site-icon-270x270.png""}",,,,
https://www.moodys.com/web/en/us/kyc/resources/insights/how-ai-is-enhancing-ubo-discovery-and-support-reporting-requirements-globally.html,How AI is Transforming Beneficial Ownership Discovery,"Blog6 ways AI is enhancing UBO discovery and complex investigations for human decisions -interview with an MLROFeb 11, 2025As the financial industry continues to experience the transformative effects of artificial intelligence (AI) and Augmented Intelligence on its risk management frameworks, there is no better time to review and anticipate AI, whether it involves machine learning (ML), deep learning (DL), or Generative AI (GenAI).AI technologies can help Compliance teams perform tasks requiring human intelligence across numerous processes. These technologies can continuously enhance and augment the accuracy and speed of human-led decision-making.Compliance tools powered by AI technologies can support key processes across the customer lifecycle, including:perpetual KYC,enhanced due diligence,intelligent screening,risk monitoring, andinvestigation.They can also contribute to prevention and detection capabilities while maximizing the use of data available to Financial Institutions (FI).This article draws from a series of exchanges between Olivier Morlet, a money laundering reporting officer (MLRO) and member of the Global Coalition to Fight Financial Crime (GCFFC), and Moody’s Industry Practice Lead, Francis Marinier.They review six impacts of AI on two key areas - regulatory compliance – specifically around UBO discovery - and social responsibility:1. Improved data analysis and pattern recognition for UBO discoveryAI algorithms can analyze vast amounts of complex ownership data to identify and understand connections and form patterns. Natural language processing also enables relevant information to be processed and extracted from large volumes of unstructured text in seconds. When applied to beneficial ownership, this can help indicate hidden ownership structures. This allows reporting officers to uncover deliberately tenuous or obscured connections between entities and individuals that would be difficult to detect through human analysis alone.The changes introduced by the latest generation AI/ML can transform financial crime, possibly leading to faster standardization of use cases, such as customer screening.The development of unsupervised-training-based programs, which include algorithms and neural networks of parameters, is increasingly being applied in the industry for tasks such as detection, scoring, and investigation.Early AI methodologies built on supervised model training were often used alongside traditional rule-based systems. However, there is a growing shift towards using unsupervised models to identify patterns, similarities, and/or anomalies within groups of aggregated data while helping to reduce false positives and optimize overall efficiency.2. Automated beneficial owner search and discoveryIn Moody’s recentstudy into Entity Verification, 46% of respondents identify improving data quality and accuracy as a key challenge in the field AI-enabled solutions can automate searching for and identifying beneficial owners from multiple data sources. Machine learning models can be trained to recognize indicators of beneficial ownership in corporate filings, shareholder documents, and other records. They can also help calculate ownership percentages within connected, circular ownership structures.AI can extract data from relevant corporate registries, standardize it, and utilize entity resolution techniques to determine when different records refer to the same entity, facilitating entity consolidation. It can streamline data collection and integrate information to generate comprehensive ownership structure maps, establishing connections between entities, such as shared addresses, directorships, and other factors.AI can significantly enhance transparency concerning beneficial ownership when worldwide BO registers lack consistency in completeness, format, and accessibility. Harnessing AI alongside a commitment to data completeness and accuracy is quickly emerging as a powerful tool for transparency to assist all who are in the fight against financial crime.3. Social network analysis (SNA)AI-powered social network analysis (SNA) examines the relationships between entities and individuals to uncover potential beneficial ownership connections among many other links between subjects of interest. This approach helps visualize complex ownership structures, identify central nodes that may represent actual beneficial owners, and develop robust, extended network investigations. Since the early 2010s, these extensive network investigations have increasingly utilized the ‘follow the money’ principle to trace financial connections.Today, SNA can support the identification of Ultimate Beneficial Owners (UBOs) in the following 5 ways:1. Mapping complex ownership structuresSNA allows for the visualization and analysis of complex ownership networks. By representing entities as nodes and ownership relationships as edges, SNA can map intricate corporate structures and reveal:Direct and indirect ownership linksShell companies and intermediariesCircular ownership patternsThis visual representation can make tracking ownership chains to UBOs more efficient.2. Identifying key players and influencersSNA techniques, like centrality analysis, can highlight the most influential and connected entities within an ownership network. This can reveal:Individuals or entities with a high degree of centrality (many direct ownership links)Entities with high betweenness centrality that serve as bridges connecting the different parts of the networkNodes with high closeness centrality that have short paths to many other entitiesThese central nodes are often good candidates for UBOs, or entities closely linked to UBOs.3. Detecting suspicious patternsBy analyzing the structure and characteristics of ownership networks, SNA can flag potentially suspicious patterns that may indicate attempts to obscure beneficial ownership, such as:Unusually complex or opaque structuresCircular ownership arrangementsEntities or individuals that appear frequently across multiple networks4. Supporting risk assessmentSNA metrics can be used to quantify risk factors related to beneficial ownership, for example:The number of layers between an entity and its UBOsThe geographic spread of entities in the networkConnections to high-risk jurisdictions or politically exposed personsThis data can feed into risk-scoring models to prioritize further investigation or enhanced due diligence.5. Enhancing due diligenceThe network perspective provided by SNA can guide and focus due diligence efforts. It allows investigators to:Identify key entities and relationships for further researchUnderstand the broader context of an entity's ownership and controlTrace indirect links that may not be apparent from standard corporate recordsBy leveraging SNA techniques and visualization, such as Maxsight™ Investigations, parties engaged in the fight against financial crime can more effectively reveal complex ownership structures, identify UBOs, and detect potential interweaved criminal methodologies to circumvent sanctions, evade tax, defraud through shell companies or layer proceeds of crime. This support reinforces extensive network investigation and provides an opportunity to engage and report nexuses.Moody’s has significantly invested in supporting organizations utilizing network visualization with models that detect risk in entire company structures based on a global ownership database. Here is a visual representation of an anonymized investigation, encompassing UK, US SDN, and EU sanctions regime breaches, the use of shell companies, and laundering the proceeds of crime.4. Processing unstructured dataMany beneficial ownership records exist as unstructured data, such as PDF documents. AI techniques like optical character recognition (OCR) and natural language processing (NLP) can convert these into structured, searchable data. This makes it easier to trace ownership chains.Data quality is crucial for the success of AI/ML projects. It affects accuracy, reliability, and effectiveness of training models and programs. Improving data processes and integrating external data sources are crucial for enhancing the quality and effectiveness of AI-enabled tools.This capability is key to areas like making cross-border payments faster, cheaper, more transparent, and more inclusive while maintaining their safety and security in the future.A key illustration of this benefit is using hybrid data (structured and unstructured) in screening address fields. The Payments Market Practice Group (PMPG) proposed this change in 2024 as part of the FATF Recommendation 16 consultation. Swift and leading Payment Market Infrastructures (PMIs) accepted it for implementation from November 2025 onwards.5. Public-Private partnerships (PPPs)Enhancing the fight against the full range of predicate offenses, such as corruption and tax evasion, human trafficking, or terrorism financing, and integrating new ones, such as failing to prevent fraud or sanctions circumvention, requires technology and data-led solutions beyond traditional methods.The transformative potential of AI/ML compliance tools is an ongoing conversation between regulators and institutions to set the AI/ML scene in ethical, technical, and practical terms. This is the Public Private Partnership approach.The crux is for financial institutions to begin transforming AI/ML compliance journeys under the encouragement and supervision of regulators to ensure the safe deployment of new technologies.This also creates a growing need for compliance officers versed in regulatory frameworks who are innovative, data-driven, and AI/ML savvy. These skills are essential in navigating the nuanced challenges of modern financial institutions, which need to be armed with a solid risk-based approach. Their expertise can help foster an environment where compliance is more than a regulatory requirement; it becomes a dynamic component of strategic decision-making.6. Addressing AI/ML bias i","{""description"": ""How AI is helping to transforming Beneficial Ownership (BO) discovery and support reporting requirements globally - Moody's"", ""template"": ""content-page-v2"", ""viewport"": ""width=device-width, initial-scale=1"", ""og:title"": ""How AI is Transforming Beneficial Ownership Discovery"", ""og:type"": ""website""}",,,,
https://oecdstatistics.blog/2019/07/04/the-adima-database-on-multinational-enterprises/,The ADIMA database on Multinational Enterprises,"Digitalisation,Globalisation,Multinationals,TaxThe ADIMA database on Multinational EnterprisesJuly 4, 2019April 19, 2023byoecdstatistics3minute readBy Graham Pilgrim (Graham.PILGRIM@oecd.org), Statistics and Data Directorate (OECD)Multinational Enterprises (MNEs) have been at the forefront of changes in the global economy over the last few decades, as trade and investment barriers have been removed and transportation and communication costs have declined. In a world of global value chains, understanding MNEs – where they are, how they operate, and where they pay taxes – has never been more important. However, surprisingly few official statistics are currently available on individual MNEs.To fill this gap the OECD has begun to develop a new database – theAnalytical Database on Individual Multinationals and Affiliates (ADIMA)– using a number of open “big data” sources that can provide new insights on individual MNEs and their global profiles.What is ADIMAADIMA has four components:Physical Register: Offering a comprehensive view of each MNE and its subsidiaries.Digital Register: Showing all websites belonging to each MNE.Indicators: Providing harmonised data at the global level for each MNE.Monitor: Identifying events like large company restructurings that can give early warnings of potential significant impacts on trade, GDP and FDI data.This information already covers 100 of the world’s largest MNEs, and more will be addedin future releases.What does ADIMA tell us on taxes?At an aggregate level, ADIMA shows that in 2016 the 100 MNEs covered in the the database (ADIMA-100) generated nearly $10 trillion in revenues (almost 20% of global GDP), earned $730 billion in profits and paid $185 billion in taxes. But you can also drill down and get more targeted information. For example, although the average Effective Tax Rate (ETR) of the ADIMA-100 was about 25%, it was significantly lower for MNEs producing computers and electronics, and pharmaceuticals, who have substantial intangible assets that they can locate in lower-tax economies (Figure 1).Figure 1: Dispersion of effective tax rates for the ADIMA-100Note: Low refers to ETR values less than 23%, Medium refers to ETR values between 23% and 33%, and High refers to ETR values greater than 33%. These values were chosen so that a third of the ADIMA-100 population was present in each classification.Where are firms physically located?The physical register provided by ADIMA describes how MNEs structure their physical operations across countries. Here ADIMA’s innovative tools and variety of data sources go beyond the information typically available in company reports (Figure 2), enabling deeper analysis and a mechanism to help profile firms and their affiliates in national and international statistical business registers. For example, companies’ annual reports show that 74 of the ADIMA-100 have a physical presence in the United Kingdom, with an additional 11 MNEs identified using complementary sources (e.g. Legal Entity Identifier, Website Hyperlink Graphs, Server Security Certificates and WikiData), bringing the number of ADIMA-100 MNEs operating in the United Kingdom up to 85.What about MNEs’ digital presence?Physical presence may not reflect digital presence, that is, and in particular for firms whose only penetration into markets is through country-specific websites (i.e. no physical presence). This matters, especially for statistics on highly digitalised MNEs, as the provision of digitised services blurs the traditional line between companies with a foreign presence and those that trade across borders which may affect the comparability of international data on trade and national income.Digital channels are comparable in scale to physical channels: the ADIMA Digital Register captures 20,000 websites while the ADIMA Physical Register captures 26,000 subsidiaries. In smaller countries the digital presence is often more important: for example, only 10 of the ADIMA-100 are physically present in Estonia but a further 19 mainly “digitalised” companies have an electronic presence (Figure 2).Figure 2: Coverage by source for OECD countries by ADIMA-100 MNEsLooking at another interesting example, annual Reports for Alphabet, Google’s parent company, show subsidiaries in two OECD countries but ADIMA’s physical and digital registers record subsidiaries and/or national websites in all OECD countries. For any given domain name, advertising revenue may be recorded as either a domestic or a cross-border transaction. The choice may depend on whether the country-specific site has been legally registered in that country.Next StepsThe OECD plans to collaborate with interested official statistical agencies to improve both national statistics on MNEs and ADIMA data. The collaborations should also consolidate the tools developed in ADIMA, extend its coverage of MNEs, improve its methods and incorporate new data sources.The measure explainedThe OECD Analytical Database on Individual Multinationals and Affiliates (ADIMA) is a new data framework offering information on both the physical and digital presence of MNEs by country. It combines information from traditional sources such as companies’ Annual Reports with newly emerging sources such as the Legal Entity Identifier, Website Hyperlink Graphs, WikiData, OpenStreetMap and Server Security Certificates.Where to find the underlying data?Physical RegisterDigital RegisterIndicatorsMonitorFurther readingAnalytical Database on Individual Multinationals and Affiliates (ADIMA)Measuring MNEs using big data: Introducing ADIMA(PowerPoint)Methodology overviewMeasuring MNEs using Big Data: The OECD Analytical Database on Individual Multinationals and their Affiliates (ADIMA)Back to homeShare this:Click to share on X (Opens in new window)XClick to share on Facebook (Opens in new window)FacebookMoreClick to share on LinkedIn (Opens in new window)LinkedInClick to share on WhatsApp (Opens in new window)WhatsAppLike this:LikeLoading...RelatedFollow usStay up to dateType your email…SubscribeTweets by OECD_StatOur latest podcastOECD·Does healthcare deliver for patients? Insights from OECD’s PaRIS initiativeExplore content by topicArtificial IntelligenceClimate ChangeConsumer ConfidenceCovid-19DevelopmentDigitalisationEconomic GrowthEconomic indicatorsEducationEnvironmentFeaturedFrançaisGenderGlobalisationGovernmentHousingInequalityInflationLabour MarketMachine LearningMigrationMultinationalsNational AccountsNew DataPolicymakingPricesProductivitySMEsSocietySurveysTaxTradeUkraineWell-being Digitalisation,Globalisation,Multinationals,TaxThe ADIMA database on Multinational EnterprisesJuly 4, 2019April 19, 2023byoecdstatistics3minute readBy Graham Pilgrim (Graham.PILGRIM@oecd.org), Statistics and Data Directorate (OECD)Multinational Enterprises (MNEs) have been at the forefront of changes in the global economy over the last few decades, as trade and investment barriers have been removed and transportation and communication costs have declined. In a world of global value chains, understanding MNEs – where they are, how they operate, and where they pay taxes – has never been more important. However, surprisingly few official statistics are currently available on individual MNEs.To fill this gap the OECD has begun to develop a new database – theAnalytical Database on Individual Multinationals and Affiliates (ADIMA)– using a number of open “big data” sources that can provide new insights on individual MNEs and their global profiles.What is ADIMAADIMA has four components:Physical Register: Offering a comprehensive view of each MNE and its subsidiaries.Digital Register: Showing all websites belonging to each MNE.Indicators: Providing harmonised data at the global level for each MNE.Monitor: Identifying events like large company restructurings that can give early warnings of potential significant impacts on trade, GDP and FDI data.This information already covers 100 of the world’s largest MNEs, and more will be addedin future releases.What does ADIMA tell us on taxes?At an aggregate level, ADIMA shows that in 2016 the 100 MNEs covered in the the database (ADIMA-100) generated nearly $10 trillion in revenues (almost 20% of global GDP), earned $730 billion in profits and paid $185 billion in taxes. But you can also drill down and get more targeted information. For example, although the average Effective Tax Rate (ETR) of the ADIMA-100 was about 25%, it was significantly lower for MNEs producing computers and electronics, and pharmaceuticals, who have substantial intangible assets that they can locate in lower-tax economies (Figure 1).Figure 1: Dispersion of effective tax rates for the ADIMA-100Note: Low refers to ETR values less than 23%, Medium refers to ETR values between 23% and 33%, and High refers to ETR values greater than 33%. These values were chosen so that a third of the ADIMA-100 population was present in each classification.Where are firms physically located?The physical register provided by ADIMA describes how MNEs structure their physical operations across countries. Here ADIMA’s innovative tools and variety of data sources go beyond the information typically available in company reports (Figure 2), enabling deeper analysis and a mechanism to help profile firms and their affiliates in national and international statistical business registers. For example, companies’ annual reports show that 74 of the ADIMA-100 have a physical presence in the United Kingdom, with an additional 11 MNEs identified using complementary sources (e.g. Legal Entity Identifier, Website Hyperlink Graphs, Server Security Certificates and WikiData), bringing the number of ADIMA-100 MNEs operating in the United Kingdom up to 85.What about MNEs’ digital presence?Physical presence may not reflect digital presence, that is, and in particular for firms whose only penetration into markets is through country-specific websites (i.e. no physical presence). This matters, especially for statistics on","{""viewport"": ""width=device-width, initial-scale=1"", ""robots"": ""max-image-preview:large"", ""description"": ""Multinational Enterprises (MNEs) have been at the forefront of changes in the global economy over the last few decades, as trade and investment barriers have been removed and transportation and communication costs have declined. In a world of global value chains, understanding MNEs \u2013 where they are, how they operate, and where they pay taxes..."", ""og:type"": ""article"", ""og:title"": ""The ADIMA database on Multinational Enterprises"", ""og:url"": ""https://oecdstatistics.blog/2019/07/04/the-adima-database-on-multinational-enterprises/"", ""og:description"": ""Multinational Enterprises (MNEs) have been at the forefront of changes in the global economy over the last few decades, as trade and investment barriers have been removed and transportation and com\u2026"", ""article:published_time"": ""2019-07-04T09:00:29+00:00"", ""article:modified_time"": ""2023-04-19T08:25:38+00:00"", ""og:image"": ""https://i0.wp.com/oecdstatistics.blog/wp-content/uploads/2023/04/pexels-philipp-birmes-830891-1.jpg?fit=1200%2C799&ssl=1"", ""og:image:width"": ""1200"", ""og:image:height"": ""799"", ""og:locale"": ""en_US"", ""twitter:text:title"": ""The ADIMA database on Multinational Enterprises"", ""twitter:image"": ""https://i0.wp.com/oecdstatistics.blog/wp-content/uploads/2023/04/pexels-philipp-birmes-830891-1.jpg?fit=1200%2C799&ssl=1&w=640"", ""twitter:card"": ""summary_large_image"", ""msapplication-TileImage"": ""https://i0.wp.com/oecdstatistics.blog/wp-content/uploads/2022/06/1652176658698.jpeg?fit=200%2C200&ssl=1""}",,,,
https://oecdstatistics.blog/2025/02/21/monitoring-multinational-enterprises-how-the-oecd-and-unsd-are-harnessing-open-data/,Monitoring multinational enterprises: How the OECD and UNSD are harnessing open data,"Featured,Globalisation,Multinationals,New DataMonitoring multinational enterprises: How the OECD and UNSD are harnessing open dataFebruary 21, 2025April 15, 2025byoecdstatistics4minute readby Graham Pilgrim (graham.pilgrim@oecd.org) and Eugene Chang (eugene.chang@oecd.org), OECD Statistics and Data DirectorateMultinational Enterprises (MNEs) are key actors in the global economy. In 2023, the top 500 MNEs generated over USD 21 trillion in revenues, greater than the combined GDP of the European Union. They play an increasing role in our lives, whether you are purchasing a new car, asking Generative AI for recipe inspiration, or streaming your favourite song. However, despite their monumental scale, the cross-border nature of their activities means National Statistical Offices (NSOs) only hold information relating to their jurisdiction. Confidentiality concerns often prevent the sharing of this information, making it difficult to see the global picture.The OECD-UNSD Multinational Enterprise Information PlatformTo overcome this, the OECD and United Nations Statistics Division (UNSD) developed the Multinational Enterprise Information Platform (MEIP), relying solely on publicly available information. The Platform is updated annually, with the third release, covering the period to 31stDecember 2023, now available.The Platform gathers information on the world’s 500 largest MNEs by market capitalisation, facilitating a comprehensive view of their physical and digital presence, and provides a one-stop-shop for data on MNEs and their global networks. In total the platform matches over 130,000 subsidiaries and 120,000 websites to the 500 MNEs.A key benefit of the Platform is the ability to drill down into an individual MNE, without confidentiality concerns. For example, you might want to distinguish the international presences of Nvidia and Intel. Starting with Intel, we can identify 94 subsidiaries, with 31 in the United States and the rest spread over 26 other jurisdictions. Their digital presence is even more dispersed, with 133 websites across 51 jurisdictions. Meanwhile, Nvidia have a narrower physical presence (13 identified subsidiaries in 7 jurisdictions) and digital presence (79 websites across 29 jurisdictions).But this is only the beginning:Explore the dashboardfor insights on the companies that interest you.MNEs in the newsNumerous elections, events, and megatrends made 2024 an eventful year. Our updated news database usesGDELT– a database of roughly 200 million worldwide news articles using text analytics to extract information relating to companies, locations, individuals and topics – to map news articles to the top 500 MNEs.In total, over 4 million articles mention one of our 500 MNEs explicitly, roughly 2% of the articles in GDELT. Combined, these MNEs receive more mentions than any individual country. One of the top trending topics of 2024 was Artificial Intelligence, with over 150,000 articles – interestingly, 34% of these articles also mentioned one of our 500 MNEs, demonstrating their important roles in AI development and use.The importance of our 500 MNEs varies widely by jurisdiction. For example, of the 2.6 million articles mentioning the United States just over 10% also mention one of our 500 MNEs. This may not be surprising, given almost half our companies are headquartered in the United States. However, this number is higher for China (12%) and India (11%), suggesting that although a significant number of MNEs in our sample may not be headquartered there, these two countries play a noteworthy role in the functioning of these MNEs.Figure 1.Importance of 500 MEIP MNEs by jurisdictionThis news database also allows users to examine individual companies, for example, looking for spikes in media coverage which could correspond to mergers, acquisitions, or controversy. One such example is Abu Dhabi National Oil Company (ADNOC) which announced its agreement to purchase Covestro in October 2024. This transaction represented a significant investment by the United Arab Emirates in a German Headquartered company.What’s nextThe Multinational Enterprise Information Platform (MEIP) is a robust foundation on which data can be linked and new insights built. However, this is an ongoing project, and our work is not finished.This year we integrated additional data fromthe Danish business registry, which has significantly enhanced our understanding of the activities of the 500 largest MNEs within Denmark. The registry makes available email addresses and MEIP looks for connections using the domain of each email. For example, Spotify Denmark ApS (Registry Number:3385348) has a contact email ofcopenhagen@spotify.com, meaning MEIP is now able to match this company to Spotify AB (Figure 2).Figure 2. Connecting Spotify AB to Spotify Denmark ApS using the Danish business registryOur implementation of this approach demonstrates that relatively low-cost methods, which do not break confidentiality requirements or require the implementation of a public beneficial ownership register, could be implemented on a wider scale. Other jurisdictions could make similar data available either publicly or directly to the OECD and UNSD for the purposes of profiling MNEs.In the coming months and years OECD and UNSD will be working to link new data sources and refine the tools through which users can explore the data. For example, we are exploring the integration of financial variables sourced from structured data sources so that users can quantify revenue, profit, and employees for each company.Share this:Click to share on X (Opens in new window)XClick to share on Facebook (Opens in new window)FacebookMoreClick to share on LinkedIn (Opens in new window)LinkedInClick to share on WhatsApp (Opens in new window)WhatsAppLike this:LikeLoading...RelatedLeave a ReplyCancel replyFollow usStay up to dateType your email…SubscribeTweets by OECD_StatOur latest podcastOECD·Does healthcare deliver for patients? Insights from OECD’s PaRIS initiativeExplore content by topicArtificial IntelligenceClimate ChangeConsumer ConfidenceCovid-19DevelopmentDigitalisationEconomic GrowthEconomic indicatorsEducationEnvironmentFeaturedFrançaisGenderGlobalisationGovernmentHousingInequalityInflationLabour MarketMachine LearningMigrationMultinationalsNational AccountsNew DataPolicymakingPricesProductivitySMEsSocietySurveysTaxTradeUkraineWell-being Featured,Globalisation,Multinationals,New DataMonitoring multinational enterprises: How the OECD and UNSD are harnessing open dataFebruary 21, 2025April 15, 2025byoecdstatistics4minute readby Graham Pilgrim (graham.pilgrim@oecd.org) and Eugene Chang (eugene.chang@oecd.org), OECD Statistics and Data DirectorateMultinational Enterprises (MNEs) are key actors in the global economy. In 2023, the top 500 MNEs generated over USD 21 trillion in revenues, greater than the combined GDP of the European Union. They play an increasing role in our lives, whether you are purchasing a new car, asking Generative AI for recipe inspiration, or streaming your favourite song. However, despite their monumental scale, the cross-border nature of their activities means National Statistical Offices (NSOs) only hold information relating to their jurisdiction. Confidentiality concerns often prevent the sharing of this information, making it difficult to see the global picture.The OECD-UNSD Multinational Enterprise Information PlatformTo overcome this, the OECD and United Nations Statistics Division (UNSD) developed the Multinational Enterprise Information Platform (MEIP), relying solely on publicly available information. The Platform is updated annually, with the third release, covering the period to 31stDecember 2023, now available.The Platform gathers information on the world’s 500 largest MNEs by market capitalisation, facilitating a comprehensive view of their physical and digital presence, and provides a one-stop-shop for data on MNEs and their global networks. In total the platform matches over 130,000 subsidiaries and 120,000 websites to the 500 MNEs.A key benefit of the Platform is the ability to drill down into an individual MNE, without confidentiality concerns. For example, you might want to distinguish the international presences of Nvidia and Intel. Starting with Intel, we can identify 94 subsidiaries, with 31 in the United States and the rest spread over 26 other jurisdictions. Their digital presence is even more dispersed, with 133 websites across 51 jurisdictions. Meanwhile, Nvidia have a narrower physical presence (13 identified subsidiaries in 7 jurisdictions) and digital presence (79 websites across 29 jurisdictions).But this is only the beginning:Explore the dashboardfor insights on the companies that interest you.MNEs in the newsNumerous elections, events, and megatrends made 2024 an eventful year. Our updated news database usesGDELT– a database of roughly 200 million worldwide news articles using text analytics to extract information relating to companies, locations, individuals and topics – to map news articles to the top 500 MNEs.In total, over 4 million articles mention one of our 500 MNEs explicitly, roughly 2% of the articles in GDELT. Combined, these MNEs receive more mentions than any individual country. One of the top trending topics of 2024 was Artificial Intelligence, with over 150,000 articles – interestingly, 34% of these articles also mentioned one of our 500 MNEs, demonstrating their important roles in AI development and use.The importance of our 500 MNEs varies widely by jurisdiction. For example, of the 2.6 million articles mentioning the United States just over 10% also mention one of our 500 MNEs. This may not be surprising, given almost half our companies are headquartered in the United States. However, this number is higher for China (12%) and India (11%), suggesting that although a significant number of MNEs in our sample may not be headquartered there, these two countries play a noteworthy role in the functioning o","{""viewport"": ""width=device-width, initial-scale=1"", ""robots"": ""max-image-preview:large"", ""description"": ""Multinational Enterprises (MNEs) are key actors in the global economy. In 2023, the top 500 MNEs generated over USD 21 trillion in revenues, greater than the \u00a0combined GDP of the European Union. To overcome this, the OECD and United Nations Statistics Division (UNSD) developed the Multinational Enterprise Information Platform (MEIP). The Platform is updated annually,\u2026"", ""og:type"": ""article"", ""og:title"": ""Monitoring multinational enterprises: How the OECD and UNSD are harnessing open data"", ""og:url"": ""https://oecdstatistics.blog/2025/02/21/monitoring-multinational-enterprises-how-the-oecd-and-unsd-are-harnessing-open-data/"", ""og:description"": ""Multinational Enterprises (MNEs) are key actors in the global economy. In 2023, the top 500 MNEs generated over USD 21 trillion in revenues, greater than the \u00a0combined GDP of the European Union. To\u2026"", ""article:published_time"": ""2025-02-21T08:53:19+00:00"", ""article:modified_time"": ""2025-04-15T13:29:49+00:00"", ""og:image"": ""https://i0.wp.com/oecdstatistics.blog/wp-content/uploads/2025/02/shutterstock_1340818388.jpg?fit=1200%2C800&ssl=1"", ""og:image:width"": ""1200"", ""og:image:height"": ""800"", ""og:locale"": ""en_US"", ""twitter:text:title"": ""Monitoring multinational enterprises: How the OECD and UNSD are harnessing open data"", ""twitter:image"": ""https://i0.wp.com/oecdstatistics.blog/wp-content/uploads/2025/02/shutterstock_1340818388.jpg?fit=1200%2C800&ssl=1&w=640"", ""twitter:card"": ""summary_large_image"", ""msapplication-TileImage"": ""https://i0.wp.com/oecdstatistics.blog/wp-content/uploads/2022/06/1652176658698.jpeg?fit=200%2C200&ssl=1""}",,,,
https://www.taxobservatory.eu/publication/the-end-of-londongrad-ownership-transparency-and-offshore-investment-in-real-estate/,The End of Londongrad? Ownership transparency and Offshore Investment in Real Estate - Eutax,"The End of Londongrad? Ownership transparency and Offshore Investment in Real Estate The End of Londongrad? Ownership transparency and Offshore Investment in Real Estate Authors:David Szakonyi, Matthew Collin, and Florian M. HollenbachThis paper studies the impact of beneficial ownership transparency in the British real estate market. In an effort to reduce illicit investment following the invasion of Ukraine, the UK government announced a new law in 2022 requiring offshore companies that owned domestic real estate to identify their ultimate owners in a public register. Using a difference-in-difference framework, we find that new property purchases by companies registered in tax havens fell relative to those made via non-havens, a result consistent with transparency raising the costs of illicit investment.These declines persist even after dropping tax havens favored by Russians, suggesting that the reform drove the decline, rather than sanctions. We do not find strong evidence of price effects nor substitution into ownership through suspicious domestic companies. While the policy does appear to have been effective at deterring some anonymous investment into the British property market, incomplete implementation led some clients to still successfully shield their ownership information, implying scope for better design and enforcement in the future. This paper studies the impact of beneficial ownership transparency in the British real estate market. In an effort to reduce illicit investment following the invasion of Ukraine, the UK government announced a new law in 2022 requiring offshore companies that owned domestic real estate to identify their ultimate owners in a public register. Using a difference-in-difference framework, we find that new property purchases by companies registered in tax havens fell relative to those made via non-havens, a result consistent with transparency raising the costs of illicit investment. These declines persist even after dropping tax havens favored by Russians, suggesting that the reform drove the decline, rather than sanctions. We do not find strong evidence of price effects nor substitution into ownership through suspicious domestic companies. While the policy does appear to have been effective at deterring some anonymous investment into the British property market, incomplete implementation led some clients to still successfully shield their ownership information, implying scope for better design and enforcement in the future. Download Working Paper","{""viewport"": ""width=device-width, initial-scale=1"", ""robots"": ""index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""The End of Londongrad? Ownership transparency and Offshore Investment in Real Estate - Eutax"", ""og:url"": ""https://www.taxobservatory.eu/publication/the-end-of-londongrad-ownership-transparency-and-offshore-investment-in-real-estate/"", ""og:site_name"": ""Eutax"", ""article:modified_time"": ""2025-03-12T10:45:51+00:00"", ""twitter:card"": ""summary_large_image"", ""generator"": ""WPML ver:4.6.9 stt:1,4;""}",,,,
https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_a_new_era_of_private_sector_collaboration_to_detect_economic_crime_-_policy_discussion_paper_-_march_2025_-_final.pdf,https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_a_new_era_of_private_sector_collaboration_to_detect_economic_crime_-_policy_discussion_paper_-_march_2025_-_final.pdf,"Future of Financial Intelligence Sharing (FFIS)
Policy Discussion Paper:
A new era of private sector collaboration to fight
economic crime
March 2025 A new era of private sector collaboration to fight economic
crime
Author: Nick J Maxwell
About
This paper is produced by the Future of Financial Intelligence Sharing (FFIS) research programme as
part of our mission to conduct independent research into the role of public-private and private-to-
private financial information sharing in detecting, preventing and disrupting crime. The FFIS
programme is a research partnership within the Royal United Services Institute (RUSI) Centre for
Finance and Security.
Founded in 1831, RUSI is the world’s oldest and the UK’s leading defence and security think tank. Its
mission is to inform, influence and enhance public debate on securing a safer and more stable world.
RUSI is a research-led institute, producing independent, practical and innovative analysis to address
today’s complex challenges.
London | Brussels | Nairobi | Doha | Tokyo | Washington, DC
Acknowledgements
The FFIS programme would like to thank all those who contributed to this Discussion Paper and our
broader research programme.
Sponsors of this research paper are gratefully acknowledged:
• Deloitte
• FNA
• HSBC
• Mastercard
• Nasdaq Verafin
• Swift
For more details about the FFIS programme, please visit www.future-fis.com.
Page 2 Citation and use
This work is licensed under a Creative Commons Attribution – Non-Commercial – No-Derivatives 4.0
International Licence. For more information, see <http://creativecommons.org/licenses/by-nc-
nd/4.0/>.
This paper is made publicly available and is intended to support a public-interest policy debate
related to the effectiveness, efficiency and data proportionality of methods and approaches to detect
and disrupt economic crime.
All information in this paper was believed to be correct by the author as of 6 January 2025.
Nevertheless, the FFIS programme cannot accept responsibility for the consequences of the use of
any information contained herein for alternative purposes and other contexts. The views and
recommendations expressed in this publication are those of the author and do not reflect the views
of RUSI or any other institution.
Reference citation: Maxwell, N (2025). ‘A new era of private sector collaboration to fight
economic crime’, Future of Financial Intelligence Sharing (FFIS) research programme.
Page 3 Contents
Executive Summary 6
Introduction and definitions 10
_______
Chapter 1.
Recent legislative changes to support private sector collaboration to detect economic crime risk
1.1. The context for policy change to enable private-to-private collaboration 13
1.2. Understanding the legal frameworks for AML collaboration in the U.S., Mexico, Singapore,
the UK, the EU and Canada in 2024:
i. USA 16
ii. Mexico 19
iii. Singapore 22
iv. UK 25
v. EU 28
vi. Canada 31
1.3. Comparing legislative frameworks for ECR collaboration 33
1.4. The different legislative frameworks promote different AML collaborative capabilities 36
1.5. Private-to-private information sharing related to fraud attack and scam transaction
(FAST) money laundering 39
1.6. The transformative potential of privacy enhancing technologies 42
1.7. Enabling partnership growth: the role for the public sector 43
_______
Chapter 2.
Economic crime risk collaboration at the cross-border level
2.1. The current landscape for international ECR P2P cooperative frameworks 47
2.2. Options to strengthen cross-border frameworks for P2P ECR collaboration:
i. Support FATF leadership in recognising the importance of private-to-private ECR
collaboration at the cross-border level. 54
ii. Update the conception of ‘payment transparency’ within FATF to cover risk
information and tracing capabilities. 56
iii. Utilise the G20’s cross-border payment reform process as an engine for cross-border
economic crime collaboration. 58
iv. Develop an inter-governmental treaty-basis for international cross-border
fraud information sharing. 60
v. Establish, or clarify, fraud-risk cross-border information sharing legal gateways
on a bi-lateral basis between countries. 62
vi. Enhance cross-border use of the current ECR P2P legislation. 65
vii. Maximise use of public-public and intra-group (private sector) enterprise-wide
sharing across borders to connect insights through various national public-private
partnerships. 67
viii. Support third-party analytical ECR platforms to share their insights across borders. 70
ix. Expand on existing cross-border public-private partnerships. 72
x. Deploy privacy enhancing technologies in cross-border ECR use-cases to share insight
on risk, without sharing personal data. 75
_______
Conclusions 78
Page 4 Glossary
Mexico Banking Association ABM
Artificial intelligence AI
Anti-money laundering, countering the financing of terrorism AML/CFT
The EU AML Authority Regulation AMLAR
The EU AML Regulation AMLR
Authorised push payment fraud APP
The Bank for International Settlements BIS
Bank Negara Malaysia BNM
Singapore's 'Collaborative Sharing of ML/TF Information & Cases' COSMIC
Counter proliferation financing CPF
The UK Economic Crime and Corporate Transparency Act ECCTA
Economic crime-related ECR
Europol Financial Intelligence Public Private Partnership EFIPPP
The EU AML Authority EU AMLA
Fraud attack and scam transaction money laundering FAST
Financial Action Taskforce FATF
The Future of Financial Intelligence Sharing FFIS
Financial Information Sharing Partnership FISP
Government Financial Intelligence Unit FIU
Financial Network Analytics Ltd FNA
Financial Stability Board FSB
General Data Protection Regulation GDPR
The J5 Joint Chiefs of Tax Enforcement and the Global Financial Institutions Partnership GFIP
Swift Industry Pilot Group IPG
Law Enforcement Agency LEA
Mexico's Ley de Instituciones de Crédito LIC
Monetary Authority of Singapore MAS
Malaysia's ‘National Fraud Portal’ NFP
National Risk Assessment NRA
Private-to-private P2P
Payments Network Malaysia PayNet
Canada's Proceeds of Crime and Terrorist Financing Act legislation PCMLTFA
Privacy enhancing technologies PETs
Mexico's Plataforma de Intercambio de Información Preventiva PIIP
Public-public cooperation PPC
Public-private partnership PPP
The Royal United Services Institute RUSI
Mexico's Ministry of Finance SHCP
The U.S. AML Act U.S. AMLA
Page 5","{""description"": ""PDF document""}",,,,
https://www.kharon.com/brief/outbound-investment-rules-china-hong-kong,New U.S. Outbound Investment Rules Target China. How Can You Assess Risk? | Kharon,"The U.S. investment rules present a complex challenge for investors and private industry, even before Trump’s planned expansion.","{""viewport"": ""width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"", ""robots"": ""index,follow"", ""description"": ""The U.S. investment rules present a complex challenge for investors and private industry, even before Trump\u2019s planned expansion."", ""og:title"": ""New U.S. Outbound Investment Rules Target China. How Can You Assess Risk? | Kharon  "", ""og:description"": ""The U.S. investment rules present a complex challenge for investors and private industry, even before Trump\u2019s planned expansion."", ""og:url"": ""https://www.kharon.com/brief/outbound-investment-rules-china-hong-kong"", ""og:type"": ""null"", ""og:image"": ""https://dbi08h1l6ojmx.cloudfront.net/OutboundCaseStudyLead.png"", ""keywords"": ""outbound investment, China, Hong Kong, U.S. investment, America First, compliance"", ""next-head-count"": ""14""}",,,,
https://www.gao.gov/products/gao-25-107403,Illicit Finance: Treasury's Initial Safeguards for Allowing Access to Information on Corporate Ownership | U.S. GAO,"GAO-25-107403Published: Feb 20, 2025. Publicly Released: Feb 20, 2025.Jump To:Fast FactsU.S. companies aren't usually required to publicly name the people who own them. This lack of transparency can be attractive to criminals laundering money or hiding illegal activities.In 2024, the Treasury Department started to require that some companies report owner identity information to its Financial Crimes Enforcement Network.Treasury also recently began granting a few law enforcement agencies access to this data. Treasury has been developing oversight policies to protect the data from unauthorized use.In future annual reports, we will be monitoring Treasury's efforts to share and protect this data.Skip to HighlightsHighlightsWhat GAO FoundBeneficial owners are individuals who, directly or indirectly, own or control a certain percentage of, or exercise substantial control over, a company or other legal entity. The Financial Crimes Enforcement Network (FinCEN) collects and shares information about beneficial owners to help safeguard the U.S. financial system from illicit use and to support law enforcement investigations, among other purposes. In December 2023, FinCEN adopted a rule that allows authorized users (such as federal agencies engaged in national security, intelligence, or law enforcement activity) to access this information if they establish data-safeguarding procedures for it. GAO found that the rule incorporated all the Corporate Transparency Act's requirements for protecting the security and confidentiality of beneficial ownership information.In spring 2024, FinCEN launched the first phase of its five-phase process to grant access to beneficial ownership information by selecting six federal agencies for a pilot, partly to test its IT system. To be approved for access, FinCEN required each agency to sign a memorandum of understanding specifying safeguards they would implement to protect the data. Agencies also had to submit an initial report describing safeguarding procedures and certify they complied with the rule's protection requirements. As of October 2024, four of the six agencies had submitted the necessary documents (see table).Federal Agencies Approved to Access Beneficial Ownership Information, as of October 29, 2024Agencies granted accessFederal Bureau of InvestigationInternal Revenue Service-Criminal InvestigationsU.S. Postal Inspection ServiceU.S. Secret ServiceAgency staff with access100System searches conductedNearly 1,700Source: Financial Crimes Enforcement Network. | GAO-25-107403In September 2024, FinCEN began the second phase, enabling about 200 additional federal agencies to request access to beneficial ownership information. Based on feedback from the pilot, FinCEN revised its memorandum of understanding to clarify certain compliance requirements. FinCEN also created a procedure for reviewing and granting agency requests for information. Agencies must still sign a memorandum of understanding, report on their safeguarding procedures, and certify compliance with information protection requirements.FinCEN officials told GAO they have been developing policies and procedures for overseeing users' access and safeguarding practices. This oversight is to include conducting annual audits, monitoring how users search the data, and reviewing reports submitted by authorized users. FinCEN plans to assess the need for additional oversight mechanisms as the access program is fully implemented. GAO will continue to monitor FinCEN's implementation of its oversight policies and procedures.Why GAO Did This StudyThe Corporate Transparency Act, enacted in 2021, requires certain legal entities to report their beneficial ownership information to FinCEN. This requirement supports U.S. efforts to prevent bad actors from concealing or benefiting from ill-gotten gains through shell companies or other opaque ownership structures. The act required FinCEN to adopt a rule to safeguard this information from unauthorized use.The Corporate Transparency Act also includes a provision for GAO to determine whether FinCEN's safeguards, procedures, and use of beneficial ownership information, as established in its access rule, are consistent with requirements of the act. This report is the first in a series of seven annual reports.This report examines (1) whether FinCEN's access rule included Corporate Transparency Act requirements for protecting the security and confidentiality of beneficial ownership information, (2) the extent to which FinCEN granted agencies access to beneficial ownership information in compliance with the act, and (3) FinCEN's oversight of agencies' access to and use of the information.GAO reviewed the Corporate Transparency Act and FinCEN's beneficial ownership information access rule; analyzed FinCEN's policies, procedures, and other documents related to the access program; and interviewed FinCEN and other agency officials.For more information, contact Michael E. Clements at (202) 512-8678 orclementsm@gao.gov.Full ReportView Full Report OnlineHighlights Page (1 page)Full Report (22 pages)Accessible PDF (20 pages)GAO ContactsMichael ClementsDirectorFinancial Markets and Community Investmentclementsm@gao.govMedia InquiriesSarah KaczmarekManaging DirectorOffice of Public Affairsmedia@gao.govPublic InquiriesContact UsTopicsBusiness Regulation and Consumer ProtectionConfidential informationFederal agenciesInformation accessInformation systemsLaw enforcementProgram transparencyPolicies and proceduresU.S. financial systemCompliance oversightConfidential communications GAO-25-107403Published: Feb 20, 2025. Publicly Released: Feb 20, 2025. U.S. companies aren't usually required to publicly name the people who own them. This lack of transparency can be attractive to criminals laundering money or hiding illegal activities. In 2024, the Treasury Department started to require that some companies report owner identity information to its Financial Crimes Enforcement Network. Treasury also recently began granting a few law enforcement agencies access to this data. Treasury has been developing oversight policies to protect the data from unauthorized use. In future annual reports, we will be monitoring Treasury's efforts to share and protect this data. Beneficial owners are individuals who, directly or indirectly, own or control a certain percentage of, or exercise substantial control over, a company or other legal entity. The Financial Crimes Enforcement Network (FinCEN) collects and shares information about beneficial owners to help safeguard the U.S. financial system from illicit use and to support law enforcement investigations, among other purposes. In December 2023, FinCEN adopted a rule that allows authorized users (such as federal agencies engaged in national security, intelligence, or law enforcement activity) to access this information if they establish data-safeguarding procedures for it. GAO found that the rule incorporated all the Corporate Transparency Act's requirements for protecting the security and confidentiality of beneficial ownership information. In spring 2024, FinCEN launched the first phase of its five-phase process to grant access to beneficial ownership information by selecting six federal agencies for a pilot, partly to test its IT system. To be approved for access, FinCEN required each agency to sign a memorandum of understanding specifying safeguards they would implement to protect the data. Agencies also had to submit an initial report describing safeguarding procedures and certify they complied with the rule's protection requirements. As of October 2024, four of the six agencies had submitted the necessary documents (see table). Federal Agencies Approved to Access Beneficial Ownership Information, as of October 29, 2024 Agencies granted access Federal Bureau of Investigation Internal Revenue Service-Criminal Investigations U.S. Postal Inspection Service Agency staff with access System searches conducted Source: Financial Crimes Enforcement Network. | GAO-25-107403 In September 2024, FinCEN began the second phase, enabling about 200 additional federal agencies to request access to beneficial ownership information. Based on feedback from the pilot, FinCEN revised its memorandum of understanding to clarify certain compliance requirements. FinCEN also created a procedure for reviewing and granting agency requests for information. Agencies must still sign a memorandum of understanding, report on their safeguarding procedures, and certify compliance with information protection requirements. FinCEN officials told GAO they have been developing policies and procedures for overseeing users' access and safeguarding practices. This oversight is to include conducting annual audits, monitoring how users search the data, and reviewing reports submitted by authorized users. FinCEN plans to assess the need for additional oversight mechanisms as the access program is fully implemented. GAO will continue to monitor FinCEN's implementation of its oversight policies and procedures. Why GAO Did This Study The Corporate Transparency Act, enacted in 2021, requires certain legal entities to report their beneficial ownership information to FinCEN. This requirement supports U.S. efforts to prevent bad actors from concealing or benefiting from ill-gotten gains through shell companies or other opaque ownership structures. The act required FinCEN to adopt a rule to safeguard this information from unauthorized use. The Corporate Transparency Act also includes a provision for GAO to determine whether FinCEN's safeguards, procedures, and use of beneficial ownership information, as established in its access rule, are consistent with requirements of the act. This report is the first in a series of seven annual reports. This report examines (1) whether FinCEN's access rule included Corporate Transparency Act requirements for protecting the security and confidentiality of beneficial ownership information, (2) the extent to w","{""description"": ""U.S. companies aren't usually required to publicly name the people who own them. This lack of transparency can be attractive to criminals laundering..."", ""og:type"": ""Website"", ""og:url"": ""https://www.gao.gov/products/gao-25-107403"", ""og:title"": ""Illicit Finance: Treasury's Initial Safeguards for Allowing Access to Information on Corporate Ownership"", ""og:description"": ""U.S. companies aren't usually required to publicly name the people who own them. This lack of transparency can be attractive to criminals laundering..."", ""og:image"": ""https://www.gao.gov/assets/extracts/1922243c6edac12ad8537c43f680e925/Fast-Facts_107403-jys.png"", ""og:image:type"": ""image/webp"", ""og:image:width"": ""650"", ""og:image:height"": ""391"", ""og:image:alt"": ""Cybersecurity icons superimposed over a person working on a laptop"", ""article:author"": ""U.S. Government Accountability Office"", ""twitter:card"": ""summary_large_image"", ""twitter:description"": ""U.S. companies aren't usually required to publicly name the people who own them. This lack of transparency can be attractive to criminals laundering..."", ""twitter:site"": ""@USGAO"", ""twitter:title"": ""Illicit Finance: Treasury's Initial Safeguards for Allowing Access to Information on Corporate Ownership"", ""twitter:creator"": ""@USGAO"", ""twitter:image"": ""https://www.gao.gov/assets/extracts/1922243c6edac12ad8537c43f680e925/Fast-Facts_107403-jys.png"", ""google-site-verification"": ""DYnuddE3AFcfpYP2PxJTAaM3l6DWACaXSND0tF5D8-4"", ""Generator"": ""Drupal 10 (https://www.drupal.org)"", ""MobileOptimized"": ""width"", ""HandheldFriendly"": ""true"", ""viewport"": ""width=device-width, initial-scale=1.0""}",,,,
https://hoeringsportalen.dk/Hearing/Details/69602,Høringsdetaljer - Høringsportalen,"HøringHøringHøring over forslag til lov om ændring af lov om Det Centrale Virksomhedsregister, selskabsloven og forskellige andre love (Ændring af adgangen til oplysninger om reelle ejere som følge af 6. hvidvaskdirektiv)Officiel titelHøring over forslag til lov om ændring af lov om Det Centrale Virksomhedsregister, selskabsloven og forskellige andre love (Ændring af adgangen til oplysninger om reelle ejere som følge af 6. hvidvaskdirektiv)BeskrivelseHermed sendes udkast til lovforslag om ændring af lov om Det Centrale Virksomhedsregister, selskabsloven og forskellige andre love (Ændring af adgangen til oplysninger om reelle ejere som følge af 6. hvidvaskdirektiv) i høring.Lovforslaget forventes fremsat APR I 2025.Lovforslaget gennemfører dele af Europa-Parlamentets og Rådets direktiv (EU) 2024/1640 af 31. maj 2024 om de mekanismer, som medlemsstaterne skal indføre for at forebygge anvendelse af det finansielle system til hvidvask af penge eller finansiering af terrorisme, om ændring af direktiv (EU) 2019/1937 og om ændring og ophævelse af direktiv (EU) 2015/849 (6. hvidvaskdirektiv). 6. hvidvaskdirektiv har bl.a. til formål at sikre efterlevelse af EU-dommen af 22. november 2022 i de forenede sager C-37/20 og C-601/20, hvorefter adgangen til oplysninger om reelle ejere for den brede offentlighed blev kendt ugyldig. 6. hvidvaskdirektivs bestemmelser, der sikrer efterlevelse af dommen, skal implementeres senest den 10. juli 2025. Herudover fastsætter direktivet bestemmelser om, hvem der kan få adgang til reelejer oplysningerne og kontrollen hermed, som skal implementeres den 10. juli 2026.Lovforslaget er udformet med henblik på at sikre, at oplysninger om reelt ejerskab ikke længere er offentligt tilgængelige for at sikre en tilstrækkelig beskyttelse af personoplysninger og ret til respekt for privatliv. Det foreslås, at loven træder i kraft ved bekendtgørelse, når ændringen af Erhvervsstyrelsens it-løsning er klar.Med lovforslaget foreslås det, at adgangen til registeret over reelle ejere begrænses, så der fremover alene er adgang for kompetente myndigheder, forpligtede enheder og personer med en legitim interesse. Erhvervsstyrelsen bemyndiges i den forbindelse til at fastsætte nærmere regler om, hvem der vil være omfattet af de tre kategorier. Hensigten er, at reglerne fastsættes i overensstemmelse med de kategorier, der er nævnt i 6. hvidvaskdirektiv.Det foreslås, at der indføres bestemmelser om, at de reelle ejere, efter anmodning til Erhvervsstyrelsen, kan få en fortegnelse over personer med legitim interesse, der har adgang til oplysningerne. I forlængelse heraf bemyndiges Erhvervsstyrelsen til at fastsætte nærmere regler om, hvilke oplysninger der skal indgå i fortegnelsen.Det foreslås desuden, at der indføres bestemmelser om registreringskontrol i forbindelse med anmodning om adgang til oplysninger om reelle ejere samt efterfølgende risikobaseret kontrol, der skal sikre, at betingelserne for adgang til oplysninger om reelt ejerskab kontinuerligt er opfyldt. Det foreslås, at der indføres hjemmel til, at Erhvervsstyrelsen kan indhente den nødvendige dokumentation for at kunne udføre kontrollen.Det foreslås endvidere, at en anmodning om adgang kan afslås eller senere tilbagekaldes, hvis betingelserne for få adgang ikke er opfyldt. Erhvervsstyrelsen bemyndiges til at fastsætte nærmere regler om forhold, der kan begrunde afslag eller tilbagekaldelse. Hensigten er, at reglerne fastsættes i overensstemmelse med de i direktivet nævnte grunde.Med lovforslaget foreslås det desuden, at den der forsætligt eller ved grov uagtsomhed videregiver oplysninger om reelle ejere til andre, som ikke er kompetente myndigheder, forpligtede enheder eller personer med legitim interesse, eller offentliggør oplysningerne, straffes med bøde.Vi imødeser eventuelle bemærkninger til lovforslagetsenest d. 20. februar 2025 kl. 12.Bemærkninger til lovforslaget og eventuelle spørgsmål bedes rettet til:Fuldmægtig Camilla Christensen: camchr@erst.dk, tlf. 3529 1748.Chefkonsulent Anja Lamp Vrang: anjlam@erst.dk, tlf. 3529 1354.HøringstypeLovforslagMyndighedErhvervsstyrelsenOmrådeErhvervHøringsfrist20-02-2025Arkiveringsdato20-04-2025BemærkningerIkrafttrædelse ved bekendtgørelse.Høringsår2024/2025KontaktpersonCamilla ChristensenKontaktperson e-mailcamchr@erst.dkPubliceringsdato23-01-2025DokumenterDownload alle filer som zipTitelFilstørrelseHøringsdokumentForslag til lov om ændring af adgangen til oplysninger om reelle ejere som følge af 6. hvidvaskdirektiv1,217 MBHøringsbrev197,863 kBHøringsliste203,754 kBHøringsnotatHøringsnotat540,424 kBHøringssvarHøringssvar5,205 MBTilbage til oversigt Høring over forslag til lov om ændring af lov om Det Centrale Virksomhedsregister, selskabsloven og forskellige andre love (Ændring af adgangen til oplysninger om reelle ejere som følge af 6. hvidvaskdirektiv)","{""viewport"": ""1024"", ""og:title"": ""H\u00f8ring over forslag til lov om \u00e6ndring af lov om Det Centrale Virksomhedsregister, selskabsloven og forskellige andre love (\u00c6ndring af adgangen til oplysninger om reelle ejere som f\u00f8lge af 6. hvidvaskdirektiv) "", ""og:site_name"": ""H\u00f8ringsportalen"", ""og:url"": ""https://hoeringsportalen.dk/Hearing/Details/69602"", ""og:image"": ""https://hoeringsportalen.dk/Content/images/header.logo.png"", ""og:description"": ""<div><font face=\""Arial, Verdana\"">Hermed sendes udkast til lovforslag om \u00e6ndring af lov om Det Centrale Virksomhedsregister, selskabsloven og forskellige andre love (\u00c6ndring af adgangen til oplysninger om reelle ejere som f\u00f8lge af 6. hvidvaskdirektiv) i h\u00f8ring.&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Lovforslaget forventes fremsat APR I 2025.&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Lovforslaget gennemf\u00f8rer dele af Europa-Parlamentets og R\u00e5dets direktiv (EU) 2024/1640 af 31. maj 2024 om de mekanismer, som medlemsstaterne skal indf\u00f8re for at forebygge anvendelse af det finansielle system til hvidvask af penge eller finansiering af terrorisme, om \u00e6ndring af direktiv (EU) 2019/1937 og om \u00e6ndring og oph\u00e6velse af direktiv (EU) 2015/849 (6. hvidvaskdirektiv). 6. hvidvaskdirektiv har bl.a. til form\u00e5l at sikre efterlevelse af EU-dommen af 22. november 2022 i de forenede sager C-37/20 og C-601/20, hvorefter adgangen til oplysninger om reelle ejere for den brede offentlighed blev kendt ugyldig. 6. hvidvaskdirektivs bestemmelser, der sikrer efterlevelse af dommen, skal implementeres senest den 10. juli 2025.&nbsp; Herudover fasts\u00e6tter direktivet bestemmelser om, hvem der kan f\u00e5 adgang til reelejer oplysningerne og kontrollen hermed, som skal implementeres den 10. juli 2026.</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Lovforslaget er udformet med henblik p\u00e5 at sikre, at oplysninger om reelt ejerskab ikke l\u00e6ngere er offentligt tilg\u00e6ngelige for at sikre en tilstr\u00e6kkelig beskyttelse af personoplysninger og ret til respekt for privatliv. Det foresl\u00e5s, at loven tr\u00e6der i kraft ved bekendtg\u00f8relse, n\u00e5r \u00e6ndringen af Erhvervsstyrelsens it-l\u00f8sning er klar.&nbsp;&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Med lovforslaget foresl\u00e5s det, at adgangen til registeret over reelle ejere begr\u00e6nses, s\u00e5 der fremover alene er adgang for kompetente myndigheder, forpligtede enheder og personer med en legitim interesse. Erhvervsstyrelsen bemyndiges i den forbindelse til at fasts\u00e6tte n\u00e6rmere regler om, hvem der vil v\u00e6re omfattet af de tre kategorier. Hensigten er, at reglerne fasts\u00e6ttes i overensstemmelse med de kategorier, der er n\u00e6vnt i 6. hvidvaskdirektiv.&nbsp;&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Det foresl\u00e5s, at der indf\u00f8res bestemmelser om, at de reelle ejere, efter anmodning til Erhvervsstyrelsen, kan f\u00e5 en fortegnelse over personer med legitim interesse, der har adgang til oplysningerne. I forl\u00e6ngelse heraf bemyndiges Erhvervsstyrelsen til at fasts\u00e6tte n\u00e6rmere regler om, hvilke oplysninger der skal indg\u00e5 i fortegnelsen.&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Det foresl\u00e5s desuden, at der indf\u00f8res bestemmelser om registreringskontrol i forbindelse med anmodning om adgang til oplysninger om reelle ejere samt efterf\u00f8lgende risikobaseret kontrol, der skal sikre, at betingelserne for adgang til oplysninger om reelt ejerskab kontinuerligt er opfyldt. Det foresl\u00e5s, at der indf\u00f8res hjemmel til, at Erhvervsstyrelsen kan indhente den n\u00f8dvendige dokumentation for at kunne udf\u00f8re kontrollen.&nbsp;&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Det foresl\u00e5s endvidere, at en anmodning om adgang kan afsl\u00e5s eller senere tilbagekaldes, hvis betingelserne for f\u00e5 adgang ikke er opfyldt. Erhvervsstyrelsen bemyndiges til at fasts\u00e6tte n\u00e6rmere regler om forhold, der kan begrunde afslag eller tilbagekaldelse. Hensigten er, at reglerne fasts\u00e6ttes i overensstemmelse med de i direktivet n\u00e6vnte grunde.&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Med lovforslaget foresl\u00e5s det desuden, at den der fors\u00e6tligt eller ved grov uagtsomhed videregiver oplysninger om reelle ejere til andre, som ikke er kompetente myndigheder, forpligtede enheder eller personer med legitim interesse, eller offentligg\u00f8r oplysningerne, straffes med b\u00f8de.&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"" style=\""font-weight: normal;\"">Vi im\u00f8deser eventuelle bem\u00e6rkninger til lovforslaget\u202f</font>senest d. 20. februar 2025 kl. 12.&nbsp;</div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Bem\u00e6rkninger til lovforslaget og eventuelle sp\u00f8rgsm\u00e5l bedes rettet til:&nbsp;</font></div><div><font face=\""Arial, Verdana\""><br></font></div><div><font face=\""Arial, Verdana\"">Fuldm\u00e6gtig Camilla Christensen: camchr@erst.dk, tlf. 3529 1748.</font></div><div><font face=\""Arial, Verdana\"">Chefkonsulent Anja Lamp Vrang: anjlam@erst.dk, tlf. 3529 1354.&nbsp;</font></div><div><br></div>""}",,,,
https://ubm.se/publikationer/publikationer/2025-03-13-kunskapsrapport---avancerade-angrepp-mot-valfardssystemen,Kunskaps­rapport – Avancerade angrepp mot välfärds­systemen - Utbetalningsmyndigheten,"Kunskaps­rapport – Avancerade angrepp mot välfärds­systemenUtbetalnings­myndigheten presenterar en lägesbild som visar att avancerade angrepp mot välfärds­systemen framför allt sker genom oseriösa företag, identitets­missbruk och manipulation av folkbokföring och intyg.Relaterade filer:Kunskapsrapport – Lägesbild med fokus på avancerade angrepp mot välfärdssystemen.pdfPdf, 339.2 kB, öppnas i nytt fönster.339.2 kB | 2025-03-17 12.53 Kunskaps­rapport – Avancerade angrepp mot välfärds­systemen Utbetalnings­myndigheten presenterar en lägesbild som visar att avancerade angrepp mot välfärds­systemen framför allt sker genom oseriösa företag, identitets­missbruk och manipulation av folkbokföring och intyg.","{""og:title"": ""Kunskaps\u00adrapport \u2013 Avancerade angrepp mot v\u00e4lf\u00e4rds\u00adsystemen"", ""og:description"": ""Utbetalnings\u00admyndigheten presenterar en l\u00e4gesbild som visar att avancerade angrepp mot v\u00e4lf\u00e4rds\u00adsystemen framf\u00f6r allt sker genom oseri\u00f6sa f\u00f6retag, identitets\u00admissbruk och manipulation av folkbokf\u00f6ring och intyg."", ""og:fallbackimage"": ""https://ubm.se/images/18.2f5c778518c8ae5b49514574/1704192729063/1200x628_banner.png"", ""have-i-been-pwned-verification"": ""dweb_o6kiw3g8c095x2u0tcxeod3q"", ""viewport"": ""width=device-width, initial-scale=1, minimum-scale=1, shrink-to-fit=no"", ""dcterms.identifier"": ""https://ubm.se"", ""dcterms.language"": ""sv"", ""dcterms.format"": ""text/html"", ""dcterms.type"": ""text"", ""og:image"": ""https://ubm.se/images/18.2f5c778518c8ae5b49514574/1704192729063/1200x628_banner.png"", ""og:image:width"": ""1200"", ""og:image:height"": ""628"", ""twitter:card"": ""summary"", ""og:url"": ""https://ubm.se/publikationer/publikationer/2025-03-13-kunskapsrapport---avancerade-angrepp-mot-valfardssystemen""}",,,,
https://graphaware.com/resources/streamlining-criminal-assets-confiscation/,Streamlining Criminal Assets Confiscation | GraphAware,"Connected data analytics platform. Explore how state-of-the-art graph technology can redefine intelligence analysis. Transitioning to connected data analytics is a rewarding journey.We’re here to help. Leverage intelligence-led policing with mission-critical graph analytics capabilities. Gain capabilities to act quickly, stop fraud and protect your clients and your business. Enable automation, learn about bad actors and their networks, and leverage predictive strategies. New use cases, features, and live demos designed to make analysts’ lives easier. Our research, philosophy and case studies, all wrapped up in books and papers. Discover GraphAware Hume’s features, demos, and graph technology insights. Review our in-depth user guides and technical documentation to ensure flawless operations. A globally-recognised graph technology company. Want to work at GraphAware?Check our open positions. Get in touch with us.Drop us a line. Join our mission to help everyone to find the truth in data. Meet us all around the world. Streamlining Criminal Assets Confiscation BACKGROUNDThe Agency is a member of the financial crime investigation taskforce which investigates criminal wealth by targeting the proceeds and instruments of crime in both Australia and overseas. BEFOREData siloed in disparate systems | Manual, time consuming investigation | 4 weeks of work by a skilled team AFTERSingle view of ownership structures across many data sets | Easily explore multi-hop connections and patterns in relationships | ± 1 hour of work by a skilled analyst Our client is a law enforcement agency, with operational priorities including investigating complex crime, and criminal assets confiscation, while exploiting advanced technology to support Australia’s national interests. Targeting the criminal economy and confiscating criminal assets is crucial to disrupting and deterring organised criminal activity and delivering maximum impact. Criminal Assets Hidden Behind Complex Legal Company Structures In order to confiscate assets effectively, the taskforce must first identify assets that can be seized and then conduct a legal process for the confiscation. Increasingly, organised crime organisations are utilising legal company structures to mask the ownership of their assets. These company structures can also include complex beneficial ownership structures to further mask ownership of assets. In addition to this, there are dozens of data sources that contain both the beneficial ownership structures and the various asset types including real estate data, shareholdings, motor vehicles and much more. The combination of the utilisation of complex legal company structures as well as the number of asset data sets required means that identifying assets that can be seized is a manual, time consuming task. The identification of assets for one case alone was in some cases taking a skilled team over a month to complete. This elapsed time hampered taskforce’s ability to quickly and effectively complete their mission of seizing assets. Unified View of Company Structures and Asset Data GraphAware HumewithNeo4jis perfectly suited to storing and analysing complex company ownership chains. Rather than analysing company ownerships manually, graphs are able to represent the network of company ownerships almost instantaneously. In addition, Hume is perfectly suited to creating a single view of intelligence across many data sets. The combination of these two technologies means that Agency analysts can instantly uncover complex company structures, and the assets that are attached to them in one single tool. The Agency team utilised GraphAware Hume platform to load the required company structure data and asset data sets to the graph. Then, using Hume actions, the team developed queries that would allow analysts to select an entity of interest and query the database for the company structures they were associated with. Finally, with the company structures returned to the canvas, the team developed Hume actions that presented assets that were attached to the companies on the canvas. Identifying Confiscatable Assets in 1 Hour Instead of 4 Weeks Utilising the GraphAware Hume platform, the Agency team were able to build a cutting edge solution for the financial crime investigation taskforce. Analysts are now able to instantly identify company ownerships and the assets attached to them. One of the core functions of the Agency, the identification of potential assets was now a process that took 1 hour, instead of up to 4 weeks. This vast improvement in the speed to identify and analyse assets meant that financial crime investigation taskforce were able to identify significantly more assets, and have a better understanding of the complex company structures that are being utilised by organised criminals. Graphs have been a game changer for our agency and its mission. — Coordinator Data Analytics The Power of Connected Data Analytics A Global Advisor in Intelligence Technology Through advanced intelligence analysis, the Law enforcement agency has enhanced crime prevention and become an important advisor in the global law enforcement community, sharing expertise on effective intelligence technology use. Streamlined Investigations: From Weeks to Hours Tasks that once took a skilled team four weeks can now be completed by a single analyst in just one hour, speeding up investigations and optimising resources, which enhances their ability to combat crime. Unlocking Complex Investigations Connected data analytics has unlocked previously challenging investigative use cases, including digital forensics, offender monitoring, and digital communication analysis, greatly enhancing the Agency’s ability to solve complex cases faster. Download the full case study Fill out the form to download the full case study, and see how GraphAware Hume enhanced the efficiency of criminal asset confiscation. Connected data analytics platform. Explore how state-of-the-art graph technology can redefine intelligence analysis. Transitioning to connected data analytics is a rewarding journey.We’re here to help. Leverage intelligence-led policing with mission-critical graph analytics capabilities. Gain capabilities to act quickly, stop fraud and protect your clients and your business. Enable automation, learn about bad actors and their networks, and leverage predictive strategies. New use cases, features, and live demos designed to make analysts’ lives easier. Our research, philosophy and case studies, all wrapped up in books and papers. Discover GraphAware Hume’s features, demos, and graph technology insights. Review our in-depth user guides and technical documentation to ensure flawless operations. A globally-recognised graph technology company. Want to work at GraphAware?Check our open positions. Get in touch with us.Drop us a line. Join our mission to help everyone to find the truth in data. Meet us all around the world.","{""viewport"": ""width=device-width, initial-scale=1"", ""description"": ""Graph technology streamlines the criminal assets confiscation, which is crucial for disrupting and deterring organized crime, ..."", ""robots"": ""follow, index, max-snippet:-1, max-video-preview:-1, max-image-preview:large"", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""Streamlining Criminal Assets Confiscation | GraphAware"", ""og:description"": ""Graph technology streamlines the criminal assets confiscation, which is crucial for disrupting and deterring organized crime, ..."", ""og:url"": ""https://graphaware.com/resources/streamlining-criminal-assets-confiscation/"", ""og:site_name"": ""graphaware.com"", ""og:updated_time"": ""2025-04-15T11:45:32+00:00"", ""og:image"": ""https://graphaware.com/wp-content/uploads/2025/02/nikldn-t-6GW8T6Jsc-unsplash-scaled-e1742299764509.jpg"", ""og:image:secure_url"": ""https://graphaware.com/wp-content/uploads/2025/02/nikldn-t-6GW8T6Jsc-unsplash-scaled-e1742299764509.jpg"", ""og:image:width"": ""200"", ""og:image:height"": ""250"", ""og:image:alt"": ""Criminal asset confiscation case study"", ""og:image:type"": ""image/jpeg"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""Streamlining Criminal Assets Confiscation | GraphAware"", ""twitter:description"": ""Graph technology streamlines the criminal assets confiscation, which is crucial for disrupting and deterring organized crime, ..."", ""twitter:site"": ""@graph_aware"", ""twitter:creator"": ""@graph_aware"", ""twitter:image"": ""https://graphaware.com/wp-content/uploads/2025/02/nikldn-t-6GW8T6Jsc-unsplash-scaled-e1742299764509.jpg"", ""msapplication-TileImage"": ""https://graphaware.com/wp-content/uploads/2025/02/cropped-logo-socials-1-2-270x270.png""}",,,,
https://graphaware.com/law-enforcement/,Connected Data for Criminal Intelligence Analysis,"Connected data analytics platform. Explore how state-of-the-art graph technology can redefine intelligence analysis. Transitioning to connected data analytics is a rewarding journey.We’re here to help. Leverage intelligence-led policing with mission-critical graph analytics capabilities. Gain capabilities to act quickly, stop fraud and protect your clients and your business. Enable automation, learn about bad actors and their networks, and leverage predictive strategies. New use cases, features, and live demos designed to make analysts’ lives easier. Our research, philosophy and case studies, all wrapped up in books and papers. Discover GraphAware Hume’s features, demos, and graph technology insights. Review our in-depth user guides and technical documentation to ensure flawless operations. A globally-recognised graph technology company. Want to work at GraphAware?Check our open positions. Get in touch with us.Drop us a line. Join our mission to help everyone to find the truth in data. Meet us all around the world. AcceleratedCriminalIntelligence Accelerated criminal Intelligence analysis — Law Enforcement Agency, Data Science Lead — Western Australia Police Force, Senior Tactical Intelligence Analyst Connected Data Analytics Platform Connect data from siloed sources into a single view of truth, structured exactly as your organisation understands it. Geospatial and Temporal Analysis Investigate data visualised in relevant locations, and see how data changes over time. Continuously monitor patterns of interest, and alert colleagues so that your team never misses anything. Key Features for Law Enforcement THE GRAPHAWARE HUME ADVANTAGE Protect communities with the power of connected data. Unify and enrich datasets from siloed sources, enabling analysts to act faster against criminals and their networks. A Single Tool For All Analysis Everything an analyst requires in just one tool — from data ingestion to comprehensive report generation. Investigate Immediately All your data points are pre-linked and resolved, automatically connected into a knowledge graph for immediate exploration. Add New Data During Investigations Ingest data on demand, perform additional enrichment, query external systems, and much more — supporting analysts’ creativity with near unlimited flexibility. Uncover Unknown Unknowns Discover patterns and relationships with multi-hop connection analysis, and query them geo-temporally. Simple & Visual Query Creation Use visual query-building with no coding expertise required. Expand your link diagram and get to actionable intelligence faster. Share Intelligence Easily Set up workflows to distribute insights to various stakeholders seamlessly using snapshots and annotations. Enable co-offending network analysis and link prediction using context-rich network data, powered by graph data science and AI. Powering the criminal intelligence analysis of law enforcement agencies. Three Steps to Intelligence-Led Policing The knowledge graph approach to intelligence-led policing bridges data silos, providing a comprehensive structure to data and a single view of intelligence. Graph adoption Support Adopting graph technology doesn’t need to be complicated. With our proven process and expertise, we will support you throughout the whole journey. Seeing is believing.Schedule a live walkthrough withone of our specialists. Connected data analytics platform. Explore how state-of-the-art graph technology can redefine intelligence analysis. Transitioning to connected data analytics is a rewarding journey.We’re here to help. Leverage intelligence-led policing with mission-critical graph analytics capabilities. Gain capabilities to act quickly, stop fraud and protect your clients and your business. Enable automation, learn about bad actors and their networks, and leverage predictive strategies. New use cases, features, and live demos designed to make analysts’ lives easier. Our research, philosophy and case studies, all wrapped up in books and papers. Discover GraphAware Hume’s features, demos, and graph technology insights. Review our in-depth user guides and technical documentation to ensure flawless operations. A globally-recognised graph technology company. Want to work at GraphAware?Check our open positions. Get in touch with us.Drop us a line. Join our mission to help everyone to find the truth in data. Meet us all around the world.","{""viewport"": ""width=device-width, initial-scale=1"", ""description"": ""Empower law enforcement and defense agencies with Hume's advanced criminal intelligence analysis software."", ""robots"": ""follow, index, max-snippet:-1, max-video-preview:-1, max-image-preview:large"", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""Connected Data for Criminal Intelligence Analysis"", ""og:description"": ""Empower law enforcement and defense agencies with Hume's advanced criminal intelligence analysis software."", ""og:url"": ""https://graphaware.com/law-enforcement/"", ""og:site_name"": ""graphaware.com"", ""og:updated_time"": ""2025-05-21T06:39:47+00:00"", ""og:image"": ""https://graphaware.com/wp-content/uploads/2024/09/Screenshot-2024-09-10-at-9.32.56-1.png"", ""og:image:secure_url"": ""https://graphaware.com/wp-content/uploads/2024/09/Screenshot-2024-09-10-at-9.32.56-1.png"", ""og:image:width"": ""1916"", ""og:image:height"": ""1010"", ""og:image:alt"": ""law enforcement knowledge graph"", ""og:image:type"": ""image/png"", ""article:published_time"": ""2024-08-27T14:51:47+00:00"", ""article:modified_time"": ""2025-05-21T06:39:47+00:00"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""Connected Data for Criminal Intelligence Analysis"", ""twitter:description"": ""Empower law enforcement and defense agencies with Hume's advanced criminal intelligence analysis software."", ""twitter:site"": ""@graph_aware"", ""twitter:creator"": ""@graph_aware"", ""twitter:image"": ""https://graphaware.com/wp-content/uploads/2024/09/Screenshot-2024-09-10-at-9.32.56-1.png"", ""msapplication-TileImage"": ""https://graphaware.com/wp-content/uploads/2025/02/cropped-logo-socials-1-2-270x270.png""}",,,,
https://graphaware.com/blog/aml-investigations-detecting-risk-transactions/,AML Investigations: Detecting High-Risk Transactions with Network Analytics,"Connected data analytics platform. Explore how state-of-the-art graph technology can redefine intelligence analysis. Transitioning to connected data analytics is a rewarding journey.We’re here to help. Leverage intelligence-led policing with mission-critical graph analytics capabilities. Gain capabilities to act quickly, stop fraud and protect your clients and your business. Enable automation, learn about bad actors and their networks, and leverage predictive strategies. New use cases, features, and live demos designed to make analysts’ lives easier. Our research, philosophy and case studies, all wrapped up in books and papers. Discover GraphAware Hume’s features, demos, and graph technology insights. Review our in-depth user guides and technical documentation to ensure flawless operations. A globally-recognised graph technology company. Want to work at GraphAware?Check our open positions. Get in touch with us.Drop us a line. Join our mission to help everyone to find the truth in data. Meet us all around the world. AML Investigations: Detecting High-Risk Transactions with Network Analytics October 4, 2024 · 6 min read In the ever-evolving landscape of financial crime, Anti-Money Laundering (AML) and Know Your Customer (KYC) procedures are critical tools for detecting suspicious activity. As criminals become more sophisticated, so too must the methods used to AML investigations and uncover illicit financial networks. One high-profile case that illustrates the complexity of modern financial crime is theAzerbaijani Laundromat, a large-scale money-laundering operation that funnelled billions of dollars through a network of shell companies. In the a recently published webinar, our experts demonstrate howconnected data analysis tools, can transform the fight against financial crime, enabling institutions to shift from reactive AML investigations to proactive monitoring and real-time risk detection. This article delves into key takeaways from that session, showcasing how connected data analysis and integration techniques can make AML and KYC processes more efficient. The Power of Data Integration in AML Investigations One of the most powerful aspects of the innovative approach to data analysis using graph technology is its ability to pull data from multiple sourcesand resolve entities across different datasets. In this case, different disconnected data from the OCCRP, Companies House, and open sanctions lists were combined using GraphAware Hume to provide a fuller picture of LCML Alliance’s activities. For example, the same company appeared in both the OCCRP dataset and the UK Companies House records, but with different pieces of information attached. Graph technology excels at linking these disparate data points, creating a unified view of the company’s ownership structure, officers, and transactions. The result was a much clearer understanding of how a company operates within the broader network of financial crime. This ability to integrate data from multiple sources is crucial in modern AML investigations, where criminals often use a combination of fake companies, shell corporations, and cross-border transactions to obscure their activities.By combining data sources and resolving entities, analysts can identify real-world connections that are deliberately obfuscated by proxy or non-existent shareholders and would otherwise go unnoticed. Visualising Financial Networks One of the key challenges in financial crime and AML investigations is understanding the intricate web of transactions, entities, and individuals involved. Traditional approaches often focus on transaction monitoring alone, but this can miss the bigger picture. Connected data analytics platforms like GraphAware Hume, however, offer a powerful alternative by visualising financial networks in a natural way, as a human brain would understand it. In the Azerbaijani Laundromat case, the Hume platform mapped relationships between bank accounts, organisations, and individuals. The data included information from the Organized Crime and Corruption Reporting Project (OCCRP), detailing transactions between entities such as LCML Alliance LLP and numerous others. By placing this data into a graph format, investigators could easily visualise clusters identifying the most influential companies in the network that funnelled money through the same accounts or shared other suspicious connections. The graph representation highlighted how certain entities were intertwined in a broader financial network, revealing links that would have been hard to detect through spreadsheets or isolated transactional reports. Identifying Red Flags Through Data Analysis Connected data analysis not only improves visualisation but also simplifies the identification of red flags—warning signs that a transaction or entity might be involved in illicit activities. In the webinar, four significant red flags were identified during the Azerbaijani Laundromat investigations: The company LCML Alliance, registered in the UK, lacked any indication of who its ultimate beneficial owner was. There were only companies registered in Seychelles. This absence of transparency is a key indicator of potential fraud. 2.Mailbox Office Addresses: The AML investigations revealed that the company’s registered address was nothing more than a mailbox, raising further suspicions. This tactic is often used to create the illusion of a legitimate operation while masking the true activities of the business. 3.Suspicious Officers: The individuals listed as officers of the company were linked to offshore jurisdictions with a history of enabling financial secrecy. This added another layer of suspicion. 4.Politically Exposed Persons (PEPs): The analysis also identified that some of the transactions eventually funnelled money into the hands of politically exposed persons, further suggesting that the network was being used to launder money. By integrating data from public sources such as Companies House and open sanctions databases, the GraphAware Hume platform was able to enrich the analysis, connecting LCML Alliance to suspicious individuals and transactions. Advanced Queries for Analysts One of the major advantages of using a connected data analysis tool like GraphAware Hume is its ability to make complex queries accessible to non-technical users. Investigators don’t need to be experts in data science to uncover hidden relationships; they can use pre-configured business logic and right-click menus to explore connections within the data. In the Azerbaijani Laundromat case, analysts were able to trace transactions from LCML Alliance to individual bank accounts with a few clicks. Instead of manually sifting through hundreds of transactions, the tool allowed them to focus on the most relevant relationships quickly and efficiently. The advanced querying feature also allowed analysts to expand their AML investigations beyond the immediate network, tracing connections to other datasets, such as sanctions lists or politically exposed persons databases. This capability significantly reduces the time required to uncover critical information. Time-Scale Visualization and SAR Filing Traversing transactional with geo and time data also opens new opportunities for more efficient risk detection/red flags spotting. GraphAware Hume platform is its time-scale visualisation tool, which allows investigators to track how a network of transactions grows and evolves over time and space. This is particularly useful when monitoring high-risk entities, as it enables investigators to see patterns of activity that might otherwise go undetected. For example, if an organisation like LCML Alliance has been flagged as suspicious, investigators can use the time-scale tool to track its transaction history. Over time, they can see the scale and speed of how the company’s network expands, providing further evidence that it might be involved in money laundering. Such a tool is invaluable when deciding whether to file a Suspicious Activity Report (SAR). If a company shows multiple red flags—such as lack of ownership data, mailbox addresses, and connections to PEPs—analysts can file a SAR and flag the entity as high risk. This proactive approach helps prevent the further movement of illicit funds through the financial system. According to UN statistics, approximately 2-5% of global GDP is laundered money. The Azerbaijani Laundromat case is older, and just the tip of the iceberg – underscoring the importance of advanced tools in seriously combating financial crime. Traditional transaction monitoring methods, while still valuable, are no longer sufficient to uncover the complex, multi-layered networks that criminals use to launder money. Connected data analysis platforms like GraphAware Hume offer a new way forward, providing investigators with the ability to integrate data from multiple sources, visualise financial networks, identify red flags, and set alerts on suspicious patterns. By leveraging these tools, financial institutions can strengthen their AML and KYC processes, shifting from reactive AML investigations to proactive monitoring and detection of risk transactions. In a world where financial crime is constantly evolving, staying ahead requires not just vigilance, but also the right technology. Connected Money: Detecting High-Risk Transactions with Network Analytics Join our webinar with Senzing and OpenSanctions to discover how combining entity resolution with connected data analytics can tackle the challenges of disparate data sources in tracing financial transactions. Connected data analytics platform. Explore how state-of-the-art graph technology can redefine intelligence analysis. Transitioning to connected data analytics is a rewarding journey.We’re here to help. Leverage intelligence-led policing with mission-critical graph analytics capabilities. Gain capabilities to act quickly, stop fraud and protect your clients and your business. Enable automa","{""viewport"": ""width=device-width, initial-scale=1"", ""description"": ""See how connected data analysis tools, can transform the fight against financial crime, enabling institutions to shift from reactive AML investigations ..."", ""robots"": ""follow, index, max-snippet:-1, max-video-preview:-1, max-image-preview:large"", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""AML Investigations: Detecting High-Risk Transactions with Network Analytics"", ""og:description"": ""See how connected data analysis tools, can transform the fight against financial crime, enabling institutions to shift from reactive AML investigations ..."", ""og:url"": ""https://graphaware.com/blog/aml-investigations-detecting-risk-transactions/"", ""og:site_name"": ""graphaware.com"", ""article:tag"": ""Ultimate Beneficial Ownership Investigation"", ""article:section"": ""GraphAware"", ""og:updated_time"": ""2024-11-21T15:07:56+00:00"", ""og:image"": ""https://graphaware.com/wp-content/uploads/2024/10/Financial-crime-money-1024x768.jpg"", ""og:image:secure_url"": ""https://graphaware.com/wp-content/uploads/2024/10/Financial-crime-money-1024x768.jpg"", ""og:image:width"": ""1024"", ""og:image:height"": ""768"", ""og:image:alt"": ""AML investigations"", ""og:image:type"": ""image/jpeg"", ""article:published_time"": ""2024-10-04T11:58:13+00:00"", ""article:modified_time"": ""2024-11-21T15:07:56+00:00"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""AML Investigations: Detecting High-Risk Transactions with Network Analytics"", ""twitter:description"": ""See how connected data analysis tools, can transform the fight against financial crime, enabling institutions to shift from reactive AML investigations ..."", ""twitter:site"": ""@graph_aware"", ""twitter:creator"": ""@graph_aware"", ""twitter:image"": ""https://graphaware.com/wp-content/uploads/2024/10/Financial-crime-money-1024x768.jpg"", ""msapplication-TileImage"": ""https://graphaware.com/wp-content/uploads/2025/02/cropped-logo-socials-1-2-270x270.png""}",,,,
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5120765,The Legitimation of Shareholder Primacy by Ann Lipton :: SSRN,"Download This PaperOpen PDF in BrowserAdd Paper to My LibraryShare:PermalinkUsing these links will ensure access to this page indefinitelyCopy URLCopy DOIThe Legitimation of Shareholder PrimacyJournal of Corporation Law (forthcoming)European Corporate Governance Institute - Law Working No. 826/2025Tulane Public Law Research Paper No. 25-144 PagesPosted: 3 Feb 2025Last revised: 19 Feb 2025See all articles by Ann LiptonAnn LiptonTulane University - Law School; Tulane University - The Murphy Institute; European Corporate Governance Institute (ECGI)Date Written: February 01, 2025AbstractWe are living in a particularly polarized era, and corporate governance is no exception. With controversies raging over ""environmental, social, governance"" (ESG) investing, diversity, equity, and inclusion initiatives, climate change as an investment concern, and even Elon Musk's pay package at Tesla, it seems as though corporate governance has never been so starkly divided along partisan lines.The divisions have threatened to spill over to Delaware, the preferred jurisdiction for incorporation in the United States. Several high profile cases-including those involving Elon Musk-have called Delaware's neutrality into question. Commenters have argued that Delaware's newly-politicized approach threatens to splinter the corporate governance universe, driving corporations to other states that are more reliable (or that follow different corporations' preferred politics).This Article argues that, in some ways, the critics are correct: Delaware law is on a path toward politicization. But it is not because of any particular bias of its judges or its law; to the contrary, the pressures toward politicization are inherent in any system that purports to guide how vast aggregations of capital will be deployed. What is unique about the current moment is that the trends toward politicization result from tensions inherent in shareholder primacy. Shareholder primacy was conceived, in large part, as a compromise to keep politics out of business management; what the modern controversies reveal is the futility of that effort.Suggested Citation:Suggested CitationLipton, Ann, The Legitimation of Shareholder Primacy (February 01, 2025). Journal of Corporation Law (forthcoming), European Corporate Governance Institute - Law Working No. 826/2025, Tulane Public Law Research Paper No. 25-1, Available at SSRN:https://ssrn.com/abstract=5120765orhttp://dx.doi.org/10.2139/ssrn.5120765Ann Lipton (Contact Author)Tulane University - Law School (email)6329 Freret StreetNew Orleans, LA 70118United StatesTulane University - The Murphy Institute (email)6823 St Charles AveNew Orleans, LA 70118United StatesEuropean Corporate Governance Institute (ECGI) (email)c/o the Royal Academies of BelgiumRue Ducale 1 Hertogsstraat1000 BrusselsBelgiumDownload This PaperOpen PDF in BrowserDo you have a job opening that you would like to promote on SSRN?Place Job OpeningPaper statisticsDownloads1,159Abstract Views6,050Rank40,706150ReferencesPlumX MetricsRelated eJournalsTulane University School of Law Public Law & Legal Theory Research Paper SeriesFollowTulane University School of Law Public Law & Legal Theory Research Paper SeriesSubscribe to this free journal for more curated articles on this topicFOLLOWERS4,825PAPERS308This Journal is curated by:James E. Dugganat Tulane University - Law SchoolCorporate Governance Law eJournalFollowCorporate Governance Law eJournalSubscribe to this fee journal for more curated articles on this topicFOLLOWERS1,511PAPERS9,634This Journal is curated by:Bernard S. Blackat Northwestern University - Pritzker School of LawCorporate & Takeover Law eJournalFollowCorporate & Takeover Law eJournalSubscribe to this fee journal for more curated articles on this topicFOLLOWERS1,195PAPERS7,695This Journal is curated by:Bernard S. Blackat Northwestern University - Pritzker School of LawEuropean Corporate Governance Institute (ECGI) - Law Working Paper SeriesFollowEuropean Corporate Governance Institute (ECGI) - Law Working Paper SeriesSubscribe to this free journal for more curated articles on this topicFOLLOWERS1,181PAPERS836This Journal is curated by:Guido Ferrariniat University of Genoa - Law Department and Centre for Law and FinanceCorporate Governance & Law eJournalFollowCorporate Governance & Law eJournalSubscribe to this fee journal for more curated articles on this topicFOLLOWERS1,071PAPERS11,623This Journal is curated by:Lucian A. Bebchukat Harvard Law SchoolCorporate Governance: Internal Governance, Organization & Processes eJournalFollowCorporate Governance: Internal Governance, Organization & Processes eJournalSubscribe to this fee journal for more curated articles on this topicFOLLOWERS850PAPERS2,416This Journal is curated by:Lucian A. Bebchukat Harvard Law SchoolCorporate Governance: Economic Consequences, History, Development & Methodology eJournalFollowCorporate Governance: Economic Consequences, History, Development & Methodology eJournalSubscribe to this fee journal for more curated articles on this topicFOLLOWERS809PAPERS3,643This Journal is curated by:Lucian A. Bebchukat Harvard Law SchoolCorporate Governance: Actors & Players eJournalFollowCorporate Governance: Actors & Players eJournalSubscribe to this fee journal for more curated articles on this topicFOLLOWERS706PAPERS7,192This Journal is curated by:Lucian A. Bebchukat Harvard Law SchoolCorporate Governance: Arrangements & Laws eJournalFollowCorporate Governance: Arrangements & Laws eJournalSubscribe to this fee journal for more curated articles on this topicFOLLOWERS679PAPERS6,238This Journal is curated by:Lucian A. Bebchukat Harvard Law SchoolLaw & Economics eJournalFollowLaw & Economics eJournalSubscribe to this fee journal for more curated articles on this topicFOLLOWERS489PAPERS15,588This Journal is curated by:Ronald J. Gilsonat Stanford Law School,A. Mitchell Polinskyat Stanford Law SchoolEnvironmental, Social & Governance (ESG) Research Hub eJournalFollowEnvironmental, Social & Governance (ESG) Research Hub eJournalSubscribe to this free journal for more curated articles on this topicFOLLOWERS386PAPERS4,431FeedbackFeedback to SSRNFeedback(required)Email(required)Submit The Legitimation of Shareholder Primacy Journal of Corporation Law (forthcoming) European Corporate Governance Institute - Law Working No. 826/2025 Tulane Public Law Research Paper No. 25-1 44 PagesPosted: 3 Feb 2025Last revised: 19 Feb 2025 Tulane University - Law School; Tulane University - The Murphy Institute; European Corporate Governance Institute (ECGI) Date Written: February 01, 2025 We are living in a particularly polarized era, and corporate governance is no exception. With controversies raging over ""environmental, social, governance"" (ESG) investing, diversity, equity, and inclusion initiatives, climate change as an investment concern, and even Elon Musk's pay package at Tesla, it seems as though corporate governance has never been so starkly divided along partisan lines.The divisions have threatened to spill over to Delaware, the preferred jurisdiction for incorporation in the United States. Several high profile cases-including those involving Elon Musk-have called Delaware's neutrality into question. Commenters have argued that Delaware's newly-politicized approach threatens to splinter the corporate governance universe, driving corporations to other states that are more reliable (or that follow different corporations' preferred politics).This Article argues that, in some ways, the critics are correct: Delaware law is on a path toward politicization. But it is not because of any particular bias of its judges or its law; to the contrary, the pressures toward politicization are inherent in any system that purports to guide how vast aggregations of capital will be deployed. What is unique about the current moment is that the trends toward politicization result from tensions inherent in shareholder primacy. Shareholder primacy was conceived, in large part, as a compromise to keep politics out of business management; what the modern controversies reveal is the futility of that effort. Suggested Citation:Suggested Citation Ann Lipton (Contact Author) Tulane University - Law School (email) 6329 Freret StreetNew Orleans, LA 70118United States Tulane University - The Murphy Institute (email) 6823 St Charles AveNew Orleans, LA 70118United States European Corporate Governance Institute (ECGI) (email) c/o the Royal Academies of BelgiumRue Ducale 1 Hertogsstraat1000 BrusselsBelgium Do you have a job opening that you would like to promote on SSRN? Tulane University School of Law Public Law & Legal Theory Research Paper Series Tulane University School of Law Public Law & Legal Theory Research Paper Series Subscribe to this free journal for more curated articles on this topic Corporate Governance Law eJournal Corporate Governance Law eJournal Subscribe to this fee journal for more curated articles on this topic Corporate & Takeover Law eJournal Corporate & Takeover Law eJournal Subscribe to this fee journal for more curated articles on this topic European Corporate Governance Institute (ECGI) - Law Working Paper Series European Corporate Governance Institute (ECGI) - Law Working Paper Series Subscribe to this free journal for more curated articles on this topic Corporate Governance & Law eJournal Corporate Governance & Law eJournal Subscribe to this fee journal for more curated articles on this topic Corporate Governance: Internal Governance, Organization & Processes eJournal Corporate Governance: Internal Governance, Organization & Processes eJournal Subscribe to this fee journal for more curated articles on this topic Corporate Governance: Economic Consequences, History, Development & Methodology eJournal Corporate Governance: Economic Consequences, History, Development & Methodology eJournal Subscribe to this fee journal for more curated articles on this topic Corporate Governance: Actors & Players eJournal Corporate Gov","{""description"": ""We are living in a particularly polarized era, and corporate governance is no exception. With controversies raging over \""environmental, social, governance&"", ""keywords"": "" SSRN, The Legitimation of Shareholder Primacy, Ann Lipton"", ""citation_author"": ""Lipton, Ann"", ""citation_title"": ""The Legitimation of Shareholder Primacy"", ""citation_online_date"": ""2025/02/03"", ""citation_publication_date"": ""2025/02/01"", ""citation_doi"": ""10.2139/ssrn.5120765"", ""citation_abstract_html_url"": ""https://papers.ssrn.com/abstract=5120765"", ""citation_pdf_url"": ""https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=5120765"", ""viewport"": ""width=device-width, initial-scale=1"", ""format-detection"": ""telephone=no"", ""og:image"": ""https://cdn.ssrn.com/ssrn-global-header/11589acb53bc518aa22929bf19add113.svg"", ""og:image:width"": ""1200"", ""og:image:height"": ""630"", ""og:title"": ""The Legitimation of Shareholder Primacy"", ""free_download_available"": ""true"", ""part_id"": ""1"", ""www_server"": ""www.ssrn.com"", ""static_server"": ""https://cdn.ssrn.com"", ""hq_server"": ""hq.ssrn.com"", ""papers_server"": ""papers.ssrn.com"", ""user_name"": ""Public User"", ""is_custom"": ""false"", ""own_design"": ""false"", ""on_behalf"": ""false"", ""tdm-reservation"": ""1"", ""tdm-policy"": ""https://www.elsevier.com/tdm/tdmrep-policy.json""}",,,,
https://www.powermag.com/software-hardware-innovation-all-needed-to-upgrade-the-power-grid/,"Software, Hardware, Innovation All Needed to Upgrade the Power Grid","Feb 10, 2025by Darrell ProctorAlso In This IssueFebruary 10, 2025T&D|Feb 10, 2025A New Paradigm for Power Grid OperationbyAaron LarsonInterview|Feb 10, 2025The POWER Interview: Using Data, Device Models, and More to Support the GridbyDarrell ProctorData Centers|Feb 10, 2025Energy Transfer Will Provide Natural Gas to Texas Data Center ProjectbyDarrell ProctorSolar|Feb 10, 2025Microsoft Buying Power from Three EDP Renewables’ Solar ProjectsbyDarrell ProctorInterview|Feb 10, 2025The POWER Interview: Enhancing Reliability of the U.S. Power SystembyDarrell ProctorTrends|Feb 10, 2025The Evolving State of Power Plant O&MbySonal PatelInterview|Feb 10, 2025The POWER Interview: Emerson Exec Discusses Grid EnhancementsbyDarrell ProctorO&M|Feb 10, 2025Turbine MRO Best Practices: Expert Guide to Maintenance, Repair, and OverhaulbyAaron LarsonTrends|Feb 10, 2025O&M Innovation in the Power Sector: The Latest Tools Redefining Asset OptimizationbySonal PatelO&M|Feb 10, 2025Cut Downtime and Costs with Predictive Maintenance (PdM): Here's HowbyAaron LarsonFollow UsFacebookTwitterLinkedInPOWERis at the forefront of the global power market, providing in-depth news and insight on the end-to-end electricity system and the ongoing energy transition. We strive to be the “go-to” resource for power professionals, offering a wealth of information on innovative business practices, sound safety measures, useful productivity enhancements, and much more.Start your subscriptionEnhancing the transmission and distribution of electricity is a priority to ensure a reliable and resilient power supply, as demand increases and grid challenges mount.Providing more electricity to meet growing global demand for power has put a spotlight not only on adding more generation to the grid, primarily through construction of new power plants, but on improvements to the grid itself. Enhancements to support power grid reliability include investments for a variety of technologies, such as battery energy storage systems (BESS), advanced transmission lines, smart grid infrastructure, and distributed generation. Upgrades also focus on improved grid monitoring and control systems that allow for better and faster response to fluctuations in demand and disruptions caused by weather, equipment, or other issues.“Needed enhancements span across condition monitoring, advanced data analytics, fire mitigation, and improved system control mechanisms,” said John Russell, senior director, Solution Consulting atAspenTech, a provider of software and services for the process industries. “Reliability in these systems is crucial not only for preventing downtime but also for ensuring that power is consistently delivered to consumers with minimal disruptions. Specifically, key areas for enhancement include the implementation of condition-based maintenance, improved data collection with smart meters, AI [artificial intelligence]-powered asset management, and advanced control technologies for both transmission and generation systems. By integrating modern technologies, these systems can proactively address failures, optimize performance, and respond to real-time conditions.”“Reliability is central to the modern power grid, especially as we integrate more renewables and electrify transportation and heating. Much work has been done in generation and distribution, driven by smarter hardware, predictive software, and data analytics,” said Brandon Young, CEO atPayless Power, a Texas-based electricity group. “On the generation side, predictive maintenance technologies become game-changers. IoT [Internet of Things] sensors and AI are monitoring equipment like turbines and transformers in real time to pinpoint potential failures before they occur. That way, downtime is kept to a minimum, and power generation stays efficient.”Utilities and grid operators are studying a variety of ways to improve the reliability of power generation and delivery, with data at the heart of much of the research.Want to learn more about innovation that supports reliability and resiliency of the power grid?Read this POWER Interview with professionals from Engineering Design & Testing Corp., a forensic engineering group that works with a range of clients in the power industry. The company offers technical expertise to solve technical and often complex problems associated with power generation and delivery.“Reliability enhancements should be approached as a comprehensive, multi-pronged strategy that addresses design concerns and utilizes new and emerging technologies for improved data analytics,” said Michael Bennett, chief transformation officer at Powin, a battery energy storage company. “Up front, suppliers need to design and engineer components with reliability as a core principle. This includes using advanced materials, robust designs, and high-quality manufacturing processes.”Bennett added, “Ensuring transmission, distribution, and generation assets are equipped with IoT sensors for real-time data collection, monitoring, and reporting capabilities has become a core focus over the past few years as well. These sensors provide operators with actionable insights into system performance and potential issues, allowing them to leverage both cloud and on-premise data to uncover complex insights, correlations, and predictions.”Thomas L. Keefe, vice chair and U.S. Power, Utilities & Renewables Sector leader forDeloitte, said, “Increasing visibility and control through advanced grid technologies” is a major part of increasing grid reliability. “Sensors embedded throughout the network, including smart meters, automated control systems, and advanced monitoring tools, can provide real-time data on energy flow, equipment health, and grid stability,” said Keefe. “Analyzing sensor data can allow operators to anticipate equipment failures before they happen, preventing outages, enhancing the utilization of existing resources, and ultimately increasing grid reliability.”Efficiency a Key Part of UpgradesUpgrades to transmission infrastructure (Figure 1) are just part of the work being done to improve power grids. The need for maintenance, particularly during a period of transition to digitization of energy systems, is evolving as well.1. Power grids across the U.S. and throughout the world are in need of upgrades to handle increased loads. Those enhancements also are needed to help integrate more renewable energy resources into electricity transmission and distribution systems. Courtesy: Salvatore Ventura / StockSnap“There are several proactive maintenance solutions to improve grid reliability, such as implementing distributed intelligence [DI] systems for real-time monitoring and diagnostics,” said Matt Smith, who leads the global business and product strategy for the grid management business atItron, a global group helping utilities develop innovative solutions for their operations. “Additionally, predictive analytics and edge intelligence can identify trouble spots below the substation, enabling utilities to automate fault isolation and repair processes, reducing the need for manual intervention, which leads to faster recovery times and improved grid stability. This integrated approach allows for a more efficient, resilient power grid, especially during times of increased demand or extreme weather events.”Actalent is a global company specializing in engineering and sciences services, along with talent solutions. Amanda Neuenfeldt, an energy management systems modeling lead engineer with the group, providedPOWERwith insight into emerging technologies that support the power grid.Learn more in thisPOWERInterview.Smith listed what he called “key enhancements” to improve the overall reliability of electricity transmission and distribution, including decentralizing grids.“Traditional centralized grids are vulnerable to cascading failures during extreme weather events, like major hurricanes and heatwaves, which are becoming more prevalent. Switching to a decentralized model, which includes incorporating distributed generation resources [such as renewables] closer to demand points, improves resilience,” said Smith. The Itron executive also noted the importance of leveraging intelligent grid edge solutions. “Integrating distributed intelligence into utility systems enables grid sectionalization, allowing power to be rerouted automatically. This reduces outages by leveraging real-time data to detect anomalies more efficiently than manual inspections.”The use of distributed generation is helping provide additional power apart from centralized power plants. Advanced metering infrastructure is helping monitor power usage in real-time, and supporting demand response programs. And then there are efforts to combat the problems associated with keeping the lights out during extreme weather events.“At the top of the list for transmission and distribution is grid hardening and modernization,” said Young. “Utilities are replacing aging infrastructure with weather-resilient materials, and deploying smart grid technologies such as automated reclosers, which isolate faults and reroute power almost instantly, reducing outages. The growth in smaller energy sources, such as rooftop solar and batteries, has been supported by distributed energy resource management systems [DERMS] that aggregate them to provide stability to the grid in times of peaks or emergencies. Future technologies, like grid-forming inverters, will stabilize grids with high renewable penetration, controlling voltage and frequency independently and acting as virtual power plants.”Itron’s Smith said, “EV [electric vehicle] charging stations are an increasingly valuable resource that can be quickly repurposed before and during grid failures to provide grid services and backup power, respectively. Additionally, EV batteries within vehicles, specifically within larger vehicles like buses, offer a robust source of energy storage. These batteries can be tapped during outages to enhance grid re","{""viewport"": ""width=device-width, initial-scale=1"", ""robots"": ""index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"", ""description"": ""Enhancing the transmission and distribution of electricity is a priority to ensure a reliable and resilient power supply, as demand increases and grid challenges mount. Providing more electricity to meet"", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""Software, Hardware, Innovation All Needed to Upgrade the Power Grid"", ""og:description"": ""Enhancing the transmission and distribution of electricity is a priority to ensure a reliable and resilient power supply, as demand increases and grid challenges mount. Providing more electricity to meet"", ""og:url"": ""https://live-powermag.pantheonsite.io/software-hardware-innovation-all-needed-to-upgrade-the-power-grid/"", ""og:site_name"": ""POWER Magazine"", ""article:publisher"": ""https://www.facebook.com/POWERmagazine/?eid=ARCX-gcC19LD579joiuiyNgkMBBj7kFB4ULWl5E82dprwFaEPjW4gngACBc7s40NDsdYvmBn2_R35_59"", ""article:published_time"": ""2025-02-10T14:16:00+00:00"", ""article:modified_time"": ""2025-04-04T15:23:57+00:00"", ""og:image"": ""https://live-powermag.pantheonsite.io/wp-content/uploads/2025/02/fig5.jpg"", ""og:image:width"": ""650"", ""og:image:height"": ""433"", ""og:image:type"": ""image/jpeg"", ""author"": ""Darrell Proctor"", ""twitter:card"": ""summary_large_image"", ""twitter:creator"": ""@POWERmagazine"", ""twitter:site"": ""@POWERmagazine"", ""twitter:label1"": ""Written by"", ""twitter:data1"": ""Darrell Proctor"", ""twitter:label2"": ""Est. reading time"", ""twitter:data2"": ""25 minutes"", ""addsearch-custom-field"": ""content_type=Post"", ""tec-api-version"": ""v1"", ""tec-api-origin"": ""https://www.powermag.com"", ""olyticsTarget"": ""met_68"", ""msapplication-TileImage"": ""https://www.powermag.com/wp-content/uploads/2020/11/cropped-p-power-270x270.jpg"", ""google-site-verification"": ""GT36o_ywMbkd3K_ZYOv1ibiLPt0UrK1JxoZZD6utf-4""}",,,,
https://wattclarity.com.au/articles/2025/02/nemde-nightmares-parallel-pathways-and-clashing-constraints/,NEMDE nightmares - parallel pathways and clashing constraints - WattClarity,"Posted byAllan O'NeilWednesday 19thFebruary 2025 4:15 PMTopic:2025-02-11,How dispatch works,Market Operations,PEC (Project Energy Connect),Review of price outcomesI was recently involved in a training session for users of Global-Roam’sez2viewsoftware where an attendee asked an innocent question about an odd-looking recent price outcome in South Australia. Finding the answer involved descending a fairly deep rabbit hole, but since it’s a good illustration of:some of the more complex aspects of theNEM’s dispatch and pricing process, andissues arising from the recent energisation ofProject EnergyConnect Stage 1(PEC-1) which has featured in a couple of recentWattClarity postswe thought it would be worth writing up for those interested.If you’re not sure what “NEMDE” is, and haven’t grappled in some way withNEM constraints, this probably isn’t the post for you. Otherwise buckle in.Down the rabbit holeThis was the situation for the19:05 dispatch interval (DI), NEM time, onTuesday 11th Feb 2025as shown in part of ez2view’s NEM Map widget.The innocent question:where did the $4,950/MWh price in South Australia (thatPaul recorded here earlier) come from?A quick scan of bids by our questioner hadn’t identified anyone offering megawatts at that price in South Australia, andAren’t prices setby the most expensive bid dispatched to meet demand?What are interconnector limits again?A closer look at the two interconnectors between South Australia and Victoria also raises questions:where’s PEC-1?On the two links shown, why are the limits on transfers so out of whack?To explain what this second question’s even about, here’s a blow-up of the interconnector information shown above:“V-S-MNSP1” is theMurraylink DC cablerunning from north-west Victoria to mid-north South Australia. “V-SA” is – or looks like – the well-knownHeywood interconnectorin the far south-west / south-east of the two states.The large numbers show thetarget transfer– energy flow in megawatts – across each interconnector, with the icon shape indicating flow direction. The two pairs of smaller numbers with directional arrowheads are (supposedly) the limits on flows when exporting from Victoria to South Australia (on the left) and when importing from South Australia into Victoria (on the right).Most newcomers to the NEM start with the very reasonable assumption that these flow limits will be something to do with how bigthe transmission lines and cables between regionsare, so shouldn’t differ too much if at all from the inherent physical capacity of these links. Unfortunately that’s often not the case.So what does set them?In practice, the limits arevery oftennothing to do with physical capacity. They are generally set by considerations ofsystem security, or what levels of transfer are possible while keeping all aspects of power system operation robust against disturbances that can inevitably buffet the grid – generators or transmission lines tripping, lightning strikes etc. These limits are dynamically calculated based on the actual state of the power system at any time and can move around a lot.In this case, these limits are saying that Murraylink can’timportmore than the 99 MW it’s carrying into Victoria (this limit is indicated at the bottom right of the icon by the right-facing arrowhead and ‘99’) – sounds reasonable. But at bottom left the Murraylink icon shows that its maximumexportto South Australia is -548 MW. That’snegative(indicated by another right-facing arrowhead) 548 MW into South Australia, meaning Murraylink should be flowingat least548 MWeastwards. This isn’t remotely physically possible, and anyway it completely conflicts with the 99 MW ‘maximum import’ limit.Things are not much better for V-SA, which has a target flow of 277 MW west from Victoria into South Australia, exceeding an export limit of 259 MW. The graphic also shows an import limit implying that V-SA shouldn’t carry more than-353 MWinto Victoria, ie that it should be flowingat least 353 MW westward. Again, in total conflict with the nominal export limit.After all that time explaining what the limit question is about, I’m not going to answer it here except to say it indicates that the dispatch process was facing great difficulties coming up with a pattern of generation dispatch and inter-regional flows that satisfied all the requirements being placed on it. We’ll see further down what those difficulties were.Where’s PEC?Back to the simpler question – where is PEC-1? An actualnetwork maphelps here:The ‘V-SA’ interconnector used in the market dispatch process now comprisestwo physical AC linksin parallel, the familiar Heywood 500kV/275kV link running through the southwest of Victoria / southeast South Australia, and the new PEC-1 330kV/220kV connection between Bundey in mid-north South Australia and Buronga in NSW which then connects into northwest Victoria via Red Cliffs. Flows across these paths can’t be independently controlled – they follow the simple physics of AC networks. Market dispatch treats the two as a single interconnection whose flow is the sum of physical flows on the two links.For anyone wondering how two parallel links can be controlled in combination, when neither of them can be individually – good question.They can’t. All the dispatch process can do for AC-connected regions is set targets for controllable generators and loads on either side of their boundary (as well as for controllable DC links like Murraylink). By choosing suitable targets for these controllable elements relative to demand in each region, the process can effectively determine anet AC transfer targetacross all the pathways linking the two regions. If generators, loads, and DC links all follow their targets exactly (almost never happens), and demand is exactly at the levels forecast (definitely never happens), then the overall AC transfer should be at exactly the planned level. In practice, net variations in supply and demand in adjoining regions play out as variations in the actual inter-regional flows.At the time of this price event, hot weather meant demand in South Australia was very high (over 2,900 MW) and the Heywood connection was transferring power into South Australia; at the same time high demand in northwest Victoria / southwest NSW, and the lack of solar farm output in these areas at this time of day (20:05 eastern daylight saving time) meant that PEC-1 was carrying power out of South Australia into Victoria. The net V-SA flow (306.6 MW at the start of the interval, available in an ez2view widget I haven’t shown here) was the sum of flow across the two links, with flows out of Victoria to SA positive by convention and flows out of South Australia negative. Market data doesn’t routinely show the split between the two physical links, only the net total. Based on some back-calculations, I’ve estimated that the physical flows at interval start were something like 163 MWeastwardson PEC-1 and 470 MWwestwardson Heywood.Don’t forget system securityUnlike market dispatch, network security limitations – managed through constraints on the dispatch process – needs to respond to and deal with not only combined transfers between regions, but also flow levels on individual physical links. In this interval, one network constraint labelledI_6F_SN_150was seeking to limit eastward flows on PEC-1 to under 150 MW by interval end. At the same time, other constraints – related to a scheduled outage of one of the two Heywood interconnector circuits due to start at 19:30 – were seeking to reduce the overall AC transfer from Victoria to South Australia (ie the V-SA combined flow across Heywood and PEC-1) to 277 MW or less westwards, again at interval end. At the start of the interval both quantities were outside these secure levels.To reduce eastward flows on PEC-1, the dispatch process could seek to increase overall westward transfers from Victoria into South Australia, byincreasingthe dispatch target for V-SA; alternatively or in addition, it might seek toreduceoutput targets for South Australian generators (and/or increase charge targets for batteries) relatively close electrically to the PEC-1 connection point, because some of their output naturally tends to flow eastwards across PEC-1. These options are reflected in the target variables and constraint factors (coefficients) present on the left-hand side (LHS) of the I_6F_SN_150 constraint (the screenshot mashup below is from ez2view’sConstraint Equation Dashboard widget):Help, I’m cornered!The problem with trying to reduce PEC-1 eastward flows byincreasingthe target for V-SA flows from its start of interval level (307 MW) is that this would violate one or more of the outage-related constraints limiting its transfers into SA at the end of the interval to 277 MW. So in trying to satisfy the I_6F_SN_150 constraint, the dispatch algorithm (NEMDE) would have to reduce generation in South Australia. In the screenshot above we can see that the LHS targets for several generators and batteries (targets are the bold values in the ‘Target / Available’ column) have indeed been set to levels below their offered availability, shown at the right of the same column.Target flow on the Murraylink interconnector (which can be independently dispatched by NEMDE because it’s a DC link) have been set to -99 MW, meaning imports into Victoria, because moving power eastward on this link tends to reduce eastward flows on nearby PEC.But doing too much of all this runs into yet another constraint – supply (including net transfers) and demand still have to balance in South Australia. With net V-SA exports from Victoria to South Australia limited to 277 MW, 99 MW flowing out of the region on Murraylink, and high South Australian demand, it turned out that there was simply not enough available generation in South Australia to both:reduce output targetsfor generators affecting the I_6F_SN_150 constraint by enough to satisfy the constraint (ie bring PEC eastward flows down below 150 MW), and st","{""viewport"": ""width=device-width, initial-scale=1.0"", ""robots"": ""index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"", ""description"": ""Guest author Allan O'Neil drills into a recent hard-to-explain spot price outcome, exposing several of the NEM's underlying complexities."", ""og:locale"": ""en_US"", ""og:type"": ""article"", ""og:title"": ""NEMDE nightmares - parallel pathways and clashing constraints"", ""og:description"": ""Guest author Allan O'Neil drills into a recent hard-to-explain spot price outcome, exposing several of the NEM's underlying complexities."", ""og:url"": ""https://wattclarity.com.au/articles/2025/02/nemde-nightmares-parallel-pathways-and-clashing-constraints/"", ""og:site_name"": ""WattClarity"", ""article:published_time"": ""2025-02-19T06:15:56+00:00"", ""article:modified_time"": ""2025-04-26T05:37:07+00:00"", ""og:image"": ""https://wattclarity.com.au/wp-content/uploads/2025/02/01-sthnem.jpg"", ""og:image:width"": ""1260"", ""og:image:height"": ""670"", ""og:image:type"": ""image/jpeg"", ""author"": ""Allan O'Neil"", ""twitter:card"": ""summary_large_image"", ""twitter:label1"": ""Written by"", ""twitter:data1"": ""Allan O'Neil"", ""twitter:label2"": ""Est. reading time"", ""twitter:data2"": ""15 minutes"", ""generator"": ""Site Kit by Google 1.152.1"", ""msapplication-TileImage"": ""https://wattclarity.com.au/wp-content/uploads/2018/09/cropped-icon2-270x270.png""}",,,,
https://github.com/kyribaker/7bus_LMPs,GitHub - kyribaker/7bus_LMPs: An illustration of how congestion causes high locational marginal prices in a 7-bus power grid.,kyribaker/7bus_LMPsPublicNotificationsYou must be signed in to change notification settingsFork2Star13An illustration of how congestion causes high locational marginal prices in a 7-bus power grid.13stars2forksBranchesTagsActivityStarNotificationsYou must be signed in to change notification settingskyribaker/7bus_LMPsmainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commitHistory4 Commits7bus_congestion_LMPs.ipynb7bus_congestion_LMPs.ipynbREADME.mdREADME.mdimage.pngimage.pngView all filesRepository files navigationA jupyter notebook illustrating the following example of a DC optimal power flow (OPF) problem solved on a simple 7-bus system. Two congested lines create a locational marginal price (LMP) that exceeds ($90/MWh) the cost of the highest priced generator in the grid ($45/MWh).AboutAn illustration of how congestion causes high locational marginal prices in a 7-bus power grid.ResourcesReadmeUh oh!There was an error while loading.Please reload this page.ActivityStars13starsWatchers1watchingForks2forksReport repositoryReleasesNo releases publishedPackages0No packages publishedUh oh!There was an error while loading.Please reload this page.LanguagesJupyter Notebook100.0% An illustration of how congestion causes high locational marginal prices in a 7-bus power grid. Repository files navigation A jupyter notebook illustrating the following example of a DC optimal power flow (OPF) problem solved on a simple 7-bus system. Two congested lines create a locational marginal price (LMP) that exceeds ($90/MWh) the cost of the highest priced generator in the grid ($45/MWh). A jupyter notebook illustrating the following example of a DC optimal power flow (OPF) problem solved on a simple 7-bus system. Two congested lines create a locational marginal price (LMP) that exceeds ($90/MWh) the cost of the highest priced generator in the grid ($45/MWh). An illustration of how congestion causes high locational marginal prices in a 7-bus power grid. There was an error while loading.Please reload this page. There was an error while loading.Please reload this page. There was an error while loading.Please reload this page. There was an error while loading.Please reload this page.,"{""route-pattern"": ""/:user_id/:repository"", ""route-controller"": ""files"", ""route-action"": ""disambiguate"", ""fetch-nonce"": ""v2:32029874-a45c-bc70-b058-f387e8f82b87"", ""current-catalog-service-hash"": ""f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb"", ""request-id"": ""80D6:3EEB38:AEBB82:F6B231:6839E2D1"", ""html-safe-nonce"": ""00f8d75d9dd1b70a9586e0323edde0bac8f7605f08dae4593970c617b8203537"", ""visitor-payload"": ""eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4MEQ2OjNFRUIzODpBRUJCODI6RjZCMjMxOjY4MzlFMkQxIiwidmlzaXRvcl9pZCI6IjMwOTUwMzc0OTIwNTExNzQwOTciLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ=="", ""visitor-hmac"": ""eebae8844aabe1e9c4021aa09868b2128016c4b35a60d4f85b28d4c95763b4fc"", ""hovercard-subject-tag"": ""repository:939744333"", ""github-keyboard-shortcuts"": ""repository,copilot"", ""google-site-verification"": ""Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I"", ""octolytics-url"": ""https://collector.github.com/github/collect"", ""analytics-location"": ""/<user-name>/<repo-name>"", ""viewport"": ""width=device-width"", ""description"": ""An illustration of how congestion causes high locational marginal prices in a 7-bus power grid. - kyribaker/7bus_LMPs"", ""fb:app_id"": ""1401488693436528"", ""apple-itunes-app"": ""app-id=1477376905, app-argument=https://github.com/kyribaker/7bus_LMPs"", ""twitter:image"": ""https://opengraph.githubassets.com/9460a1282180b88d1a05b1e0c1c1d4ac280f8b6e453414d3127ffbd8f918efde/kyribaker/7bus_LMPs"", ""twitter:site"": ""@github"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""GitHub - kyribaker/7bus_LMPs: An illustration of how congestion causes high locational marginal prices in a 7-bus power grid."", ""twitter:description"": ""An illustration of how congestion causes high locational marginal prices in a 7-bus power grid. - kyribaker/7bus_LMPs"", ""og:image"": ""https://opengraph.githubassets.com/9460a1282180b88d1a05b1e0c1c1d4ac280f8b6e453414d3127ffbd8f918efde/kyribaker/7bus_LMPs"", ""og:image:alt"": ""An illustration of how congestion causes high locational marginal prices in a 7-bus power grid. - kyribaker/7bus_LMPs"", ""og:image:width"": ""1200"", ""og:image:height"": ""600"", ""og:site_name"": ""GitHub"", ""og:type"": ""object"", ""og:title"": ""GitHub - kyribaker/7bus_LMPs: An illustration of how congestion causes high locational marginal prices in a 7-bus power grid."", ""og:url"": ""https://github.com/kyribaker/7bus_LMPs"", ""og:description"": ""An illustration of how congestion causes high locational marginal prices in a 7-bus power grid. - kyribaker/7bus_LMPs"", ""hostname"": ""github.com"", ""expected-hostname"": ""github.com"", ""turbo-cache-control"": ""no-preview"", ""go-import"": ""github.com/kyribaker/7bus_LMPs git https://github.com/kyribaker/7bus_LMPs.git"", ""octolytics-dimension-user_id"": ""43766081"", ""octolytics-dimension-user_login"": ""kyribaker"", ""octolytics-dimension-repository_id"": ""939744333"", ""octolytics-dimension-repository_nwo"": ""kyribaker/7bus_LMPs"", ""octolytics-dimension-repository_public"": ""true"", ""octolytics-dimension-repository_is_fork"": ""false"", ""octolytics-dimension-repository_network_root_id"": ""939744333"", ""octolytics-dimension-repository_network_root_nwo"": ""kyribaker/7bus_LMPs"", ""turbo-body-classes"": ""logged-out env-production page-responsive"", ""browser-stats-url"": ""https://api.github.com/_private/browser/stats"", ""browser-errors-url"": ""https://api.github.com/_private/browser/errors"", ""release"": ""994628876282f66f40ba0bae7848f6c92a1e1688"", ""theme-color"": ""#1e2327"", ""color-scheme"": ""light dark""}",,,,
https://www.abc.net.au/news/2024-10-13/australian-coal-plant-in-extraordinary-survival-experiment/104461504,"Australian coal plant in 'extraordinary' survival experiment as solar, funding woes stalk industry - ABC News","Australian coal plant in 'extraordinary' survival experiment as solar, funding woes stalk industryBy energy reporterDaniel MercerTopic:CoalSat 12 OctSaturday 12 OctoberSat 12 Oct 2024 at 7:07pmCoal plants like Bayswater have been the pillars of Australia's power supply. But that's changing.(Reuters: Loren Elliott)abc.net.au/news/australian-coal-plant-in-extraordinary-survival-experiment/104461504Link copiedShareSharearticleAfter years of setbacks, bad news and mounting obstacles, Australia's coal-fired generators must have felt they had something to celebrate.AGL, the giant energy company backed by tech billionaire and climate evangelist Mike Cannon-Brookes, revealed it had pulled off a first.At its huge Bayswater power station in the Hunter Valley north of Sydney, AGL successfully switched off an entire unit before switching it back on again just five hours later – a feat until recently considered unthinkable.In a post on social media, Bayswater general manager Len McLachlan said this process of ""two-shifting"" was a harbinger of the future.Throughout its history, coal-fired power had been considered the quintessential provider of so-called base-load electricity.The term refers to generation sources that run round-the-clock, throughout the year and more or less at their full capacity.It was a function that coal plants had carried out for decades, and a business model on which the industry was built.The rise and rise of rooftop solar in Australia has been breathtaking.(ABC News: Glyn Jones)But, more and more, base-load coal plants have been squeezed out of the market as ever more renewable energy – particularly solar power – flooded the system.In doing so, renewable energy was forcing wholesale prices ever lower – so low that they were entering negative territory where generators had to pay to keep producing.And while coal plants – despite the orthodox thinking – could in fact reduce their output to minimise their exposure to those low or negative prices, they were only able to lower production so much.Beyond that, the industry had claimed, it was technically unsafe and economically unsound to operate coal plants designed to run full steam.That was, until now.Times, and coal, are a-changin'Two-shifting, Mr McLachlan said, was a way for coal plants to capitalise on high prices in the evening peak while avoiding bearish prices in the middle of the day when solar power was most abundant.It was a way to give flexibility to a type of generation that was not designed to be flexible.Mike Cannon-Brookes.(AAP: Dan Himbrechts)""Bayswater power station achieved a major milestone recently with the successful completion of our first two-shift trial,"" Mr McLachlan wrote.""Our team desynchronised 20 seconds ahead of the 10am target and re-synchronised within 50 seconds of the 3pm target.""This level of precision on our first attempt is extraordinary and sets a new benchmark for our operations.""David Leitch, an energy industry analyst, said it was a significant achievement by AGL.""The general presumption has been that coal-fired generation units, which are very large units … have a minimum operating rate below which they can't run,"" Mr Leitch said.""The presumption was that when you turned them off you then had to let them cool down and start them up fairly gradually.""You couldn't stop and start them in the same way that you could with a gas generator, for instance, let alone a battery that can change direction in milliseconds.""But the exciting news out of Bayswater is that it can now be turned off and on within a 24-hour cycle on a continuous basis without damaging anything very much.""It's a very positive result all around.""Mr Leitch said that on top of the financial savings for their owners, switching off coal plants in the middle of the day would also cut emissions and make more room for renewable energy.The floor below which coal output could not drop is seen by industry players as an impediment to Australia's energy transition – a cause to waste huge amounts of cheap wind and solar output at certain times.These times are most obvious in the middle of the day when solar output is highest, particularly in autumn and spring, when relatively mild weather means demand for power can be subdued.""It's only still only experiments at this stage,"" he said.""Assuming they do get confidence … the minimum generation level of coal could theoretically fall all the way to zero.""Now comes the bad newsBut mere days after AGL's announcement of the good news, another Australian coal-fired generator painted a bleaker, arguably truer, picture for the industry.Delta, the Czech firm that owns the aging Vales Point coal plant near Lake Macquarie, reported that it had been unable to get the financial backing of any major bank in Australia.And Delta, like any other generator in the national electricity market covering Australia's eastern seaboard, needs financial backing from the banks.Vales Point Power Station(ABC News: Ben Millington)Each day, the generators are producing and selling vast quantities of electricity, trading with customers more or less continuously.To cover periods where a company like Delta might sell power at a loss and incur any debts, the Australian Energy Market Operator requires generators to provide credit support in the form of a bank guarantee.But Delta, in a letter written to the body that makes the rules in the market, said none of the 15 banks it had met had been willing to provide it the necessary coverage because of environmental concerns.As a result, the company was in a quandary.When the support from its current bank expired later this year, Delta said it would be unable to meet the funding requirements from AEMO even though, it insisted, it had the money.""A significant number of financial institutions, that would be acceptable to AEMO, are no longer providing financing facilities to fossil fuel generators,"" the company wrote in its letter.""While the energy transition is progressing, there will be an ongoing reliance on fossil fuel generators, at least in the immediate future.""It has been identified during the refinancing process that 13 of the 15 lenders declined due to (environmental, social and governance) constraints, which included the Big-4 Australian banks.""There exists a real potential that a market participant, while being a profitable and solvent business, may be unable to meet prudential requirements with AEMO from the end of 2024.""Macquarie is reported to be Delta's current lender, but that support will dry up at year's end.(Reuters: David Gray)The company wants the rules urgently changed so AEMO can accept cash payments instead of a bank guarantee.Failure to do so, Delta warned, could lead to inefficient outcomes – or worse.""Without the option of providing cash as credit support, (it) is likely to result in severe reliability and security issues,"" it wrote.""At worst … critical generation assets are forced to withdraw from the market or are removed from participating in the market by AEMO because of an inability to meet prudential requirements through a bank guarantee.""Czech group Sev.en reportedly spent more than $200 million on Vales Point in 2022 when they bought it off businessmen Trevor St Baker and Brian Flannery, who famously paid just $1 million for the asset in 2015.Under Sev.ev's plans, it extended the life of Vales Point from 2029, when it had been due to shut, to 2033.Coal's future 'nailed shut'Energy analyst Mr Leitch, who owns consultancy ITK Services, said Delta's problems were, to a large extent, of its own making.Mr Leitch, a former investment banker, said the company was seemingly indifferent to the push to decarbonise, or lay out a credible play to do so.He said this flew in the face of the demands on banks, which were under growing pressure to stop lending to fossil fuel projects or firms without decarbonisation plans.""It's exacerbated in Delta's case because they are very unashamedly totally pro-coal,"" Mr Leitch said.""They've got no plans to decarbonise or do anything.""So it makes it very hard for anyone who is under pressure themselves about climate change goals – which the banks all are – to continue supporting a business that refuses to even acknowledge the reality of it.""Wind power is being wasted because rooftop solar is uncontrolled and coal can only go so low.(ABC News: Daniel Mercer)In the short term, Mr Leitch said Delta was likely to win a reprieve and be given the rule change it was after.He said the business ""actually has cash and can provide those guarantees – they don't actually need the banks, it's just been a legal or AEMO requirement"".""For me, the broader issue is that the pressure from the banks, and I think it will come from the insurance companies as well, is increasing all the time.""By and large, most of the finance industry, particularly people investing in the future and the longer term, take climate change in general very seriously and feel like they have to get on with the task of doing something about it.""And, so, they exert pressure.""Longer term, Mr Leitch said the plight of AGL and Delta, while different in many ways, shared common ground in one, crucial way.He said the financial screws were getting tighter on the coal-fired power industry, and this was unlikely to change.According to Mr Leitch, measures like two-shifting at Bayswater may help extend the life of some coal plants, at least for a time.And he said it even opened up the possibility of coal plants being left on care-and-maintenance after they retired from full-time service – of using them as back-up generators when the system needed the help.But, ultimately, he said the writing was on the wall for coal power as we know it.""The coal-fired generation is going to go out of business in Australia over the next 10 years,"" he said.""Nearly everyone accepts that.""It's absolutely locked in that the coal generation in Australia is going away and it's only the same as is happening all over the world.""AGL's Bays","{""title"": ""Australian coal plant in 'extraordinary' survival experiment as solar, funding woes stalk industry - ABC News"", ""description"": ""A remarkable first for coal power in Australia gave the beleaguered industry hope recently. But news this week might have snuffed it out again."", ""keywords"": ""coal, bayswater, power station, agl"", ""viewport"": ""width=device-width, initial-scale=1.0, maximum-scale=2.0"", ""ABC.ContentType"": ""Article"", ""ABC.ContentSource"": ""coremedia"", ""generator"": ""PL NEWS WEB"", ""ABC.Generator"": ""PL NEWS WEB"", ""ContentId"": ""104461504"", ""ABC.ContentId"": ""104461504"", ""ABC.VersionNumber"": ""24"", ""article:author"": ""https://www.abc.net.au/news/daniel-mercer/11547686"", ""article:tag"": ""agl"", ""article:published_time"": ""2024-10-12T19:07:31+00:00"", ""article:modified_time"": ""2024-10-12T19:07:54+00:00"", ""og:url"": ""https://www.abc.net.au/news/2024-10-13/australian-coal-plant-in-extraordinary-survival-experiment/104461504"", ""og:description"": ""A remarkable first for coal power in Australia gave the beleaguered industry hope recently. But news this week might have snuffed it out again."", ""og:title"": ""Can coal survive the solar spread? Major Australian power plant notches 'extraordinary' first"", ""og:type"": ""article"", ""twitter:card"": ""summary_large_image"", ""twitter:site"": ""@abcnews"", ""twitter:image"": ""https://live-production.wcms.abc-cdn.net.au/4fe87c4d57115b8593132d8bb75dcb45?impolicy=wcms_watermark_news&cropH=1687&cropW=3000&xPos=0&yPos=152&width=862&height=485&imformat=generic"", ""twitter:image:alt"": ""Shot zoomed in on the top of the Bayswater coal-fired power plant, with its smoke stacks and high voltage power lines"", ""og:image"": ""https://live-production.wcms.abc-cdn.net.au/4fe87c4d57115b8593132d8bb75dcb45?impolicy=wcms_watermark_news&cropH=1687&cropW=3000&xPos=0&yPos=152&width=862&height=485&imformat=generic"", ""og:updated_time"": ""2024-10-12T19:07:54+00:00"", ""next-head-count"": ""46""}",,,,
https://blog.gridstatus.io/curtailment/,Curtailment: When We Throw Away Clean Energy,"As renewable energy from solar and wind expands across the country, surpluses in generation will become increasingly common and consequently lead to curtailment, which is the deliberate reduction of output below what could be produced.As a concept and in practice, curtailment is interwoven into conversations, questions, and decisions about the modern grid. On its face, curtailment is a waste of “free” electricity from clean sources, but why does it occur? Is the answer as simple as building more transmission, as often presented? Electricity markets are a construct of human administrative engineering, so recognizing their limitations and how those constraints can lead to unintuitive outcomes is important to understanding curtailment.In this post, we analyze the dynamics behind renewable curtailment under three different (albeit interrelated) market circumstances in the areas that have the highest penetrations of renewables in the United States: California Independent System Operator (CAISO), Electric Reliability Council of Texas (ERCOT), and Southwest Power Pool (SPP).Table of ContentsA primer on curtailmentLow demand for excess California SolarTransmission Congestion in TexasDispatchable yet inflexible generation in Southwest Power PoolWhen less is more: a deeper look into congestionConclusionA primer on curtailmentIn nodal electricity markets, curtailment refers to the intentional reduction in the production of electricity by certain generation resources. When used in conversation today, it almost always refers to zero cost renewable resources, namely wind and solar.While curtailment is often seen as undesirable, especially from the perspective of renewable energy producers, is an essential mechanism for market operators to maintain a reliable and stable electricity grid.⚡Why is electricity not like other commodities?A key difference between electricity as a commodity and others such as metals or produce is that the grid has to maintain a balance between supply and demand at all times. For example, while there are natural limits to the storage of potatoes, there is some flexibility in the timing of potato harvest, storage, and sale. Conversely, electricity is expected instantaneously whenever demand may occur. Fortunately, in aggregate we can make informed enough estimates to build a system with some tolerance, but that band remains fairly slim, albeit growing with the penetration of battery systems.Curtailment and LMPsCurtailment typically results from a negative price signal to generators via theLocational Marginal Pricing, or LMP. The LMP reflects the value of electricity at a specific location, taking into account the costs of generation, transmission constraints, and transmission losses. When the LMP is sufficiently negative, it becomes uneconomical for a unit to generate its full output, leading to curtailment. The LMP can be viewed as a representation of the administrative engineering needed for the operation of wholesale electricity markets.In the following sections, we examine different circumstances that all lead to the same outcome - a strongly negative congestion component of the LMP. Curtailment may also occur via specific, targeted, operator actions (such as theSeptember 6th event in ERCOT), but here we will largely focus on market fundamentals that influence LMP formation.The fact that disparate circumstances can lead to curtailment through price signals alone is both the beauty of a market system and a factor that muddles understanding of correlation and causation.Low demand for excess California SolarLet's start by exploring a fundamental driver of curtailment – a lack of demand for the renewable capacity that has been built.California has seen explosive growth in solar generation, with solar resources built to serve the summer peak leading to excess capacity during periods of low demand. The scatter plot below lays bare the existence of a relationship between curtailment and low load.In a way, this graph shows a properly functioning market, as higher prices tend to be correlated with lower levels of curtailment, while very low prices are properly signaling the existence of excess generation exacerbating congestion.The solar buildout is so large that CAISO is often exporting during peak sunny hours, evenwhile running gas plants internally. But, what happens when the regional grid can't use all of California's solar?While it still relies on interchange with neighbors, the timing and depth of the relationship has shifted due to renewable generation as we can see belowCAISO has undergone quite a transformation over the past decade.In the above figure, the second chart shows a deepening of CAISO exports that even surpasses the solar and wind generation of the first chart.While it appears the solar generation suddenly spikes over the summer in 2023, it was actually being substantially reduced by the greater rate of spring curtailment than previous years.A driver of this outcome not in the chart is the rapid penetration of behind-the-meter solar, which is roughly half of all installed solar in the CAISO’s footprint. This generation doesn’t show up in the typical fuel mix chart, but does have an impact on load balancing requirements by freeing up additional utility-scale generation for regional exports.As solar has expanded its role in daily CAISO generation, exports have become more common, but when regional demand is satiated, curtailment becomes the only option. With economic incentives to deliver as much renewable energy as possible, conditions can occur in which a given area has energy production above its load.Here, we see the relationship betweeninterchange,solar generation, andcurtailmentin CAISO. A few things stick outThe area near zero on the interchange axis implies low demand for CAISO solar generation, either internally or throughout the region.The higher periods of curtailment are clustered in the middle of the figure because curtailment is correlated with lower demand, either in CAISO or regionally.The bottom right quadrant has relatively little curtailment, despite very high solar generation, because there is a strong enough regional demand for generationConversely, we see slightly more curtailment (in terms of %) in the upper left, despite lower solar. This is likely related to individually odd hours or congested conditions where the high level of imports creates a more difficult-to-manage topology.When generation exceeds demand, instability may occur. In such cases, curtailment of renewables is often required to balance out the system and may even be preferred in a policy environment that prefers a highly renewable resource mix.It is tempting to conclude that any additional load while there is curtailment would have zero marginal emissions because it would not actually require more fossil fuel generation. However, in the next two sections, we will explain how not all curtailment is caused by insufficient load.Transmission Congestion in TexasUtility-scale renewables often depend on transmission lines to allow electricity to flow from where it is generated to where it is needed. When transmission bottlenecks arise, the system operator may have to curtail generation from certain sources to ensure grid stability.No place is a better example of this dynamic than Texas, where disparities between the geographic locations of renewables and load can cause ERCOT to experience particularly expensive curtailment due to transmission constraints. Transmission bottlenecks can take a few different forms, but the two most common are thermal constraints, where the line will quite literally melt past certain limits, and voltage constraints related to electrical balancing.The map below shows the location of solar and wind units in ERCOT as they are curtailed throughout a day in April of this year. The circles and squares are proportionally sized by facility nameplate capacity, while the color shows an approximation of total facility curtailment.ERCOT curtailed generation over a shoulder season day, with 345kV lines and major metropolitan areasThe curtailment data from ERCOT is not perfectly clean (you may notice some solar blips overnight) as ERCOT does not report curtailment directly. Instead, it can be calculated via the60-day SCED datausing the difference of basepoint and high sustained limit (HSL), which may be subject to occasional operator errors in submission.A subset of 345kV transmission lines and major metropolitan areas are also overlaid to give a sense of scale and location - most of the curtailed generation isn’t particularly close to the Austin-Dallas-Houston triangle and therein lies much of the operational issue in ERCOT today. To put it in perspective, some of those curtailed western resources are closer (as the crow flies) to all of Albuquerque, Phoenix, and Oklahoma City, but cannot flow towards those load centers due to ERCOT’s isolationist tendencies.When transmission constraints cause generator output to be “bottled up” in a given area, power prices in that area fall due to the congestion component of the LMP. Prices fall because that constrained generation is less valuable to the system.Today,solar and wind generators have the capabilityto modulate their output, but market-based curtailment events still rely on the actual bids of generators. Due to the unique economics of wind and solar plants (e.g., not having neither minimum generating levels nor heat rate variations over their output curve) they often have fewer points in their bid curves compared to traditional dispatchable generation, which can result in curtailment approaching complete facility capacity more often than may be needed.In a sense, the system-wide grid balancing of the CAISO example becomes localized in ERCOT due to local pockets of imbalance supply and demand, which are exacerbated by resistance against interconnection with neighboring regions.The Market Mechanisms of Curtailment in ERCOTInternal congestion ","{""HandheldFriendly"": ""True"", ""viewport"": ""width=device-width, initial-scale=1.0"", ""description"": ""As we approach the end of another shoulder season \u2014 a period of lower demand and higher transmission outages \u2014 it's a good time to explain curtailment, a crucial yet often controversial aspect of today's grid operations."", ""referrer"": ""no-referrer-when-downgrade"", ""og:site_name"": ""Grid Status Exports"", ""og:type"": ""article"", ""og:title"": ""Curtailment: When We Throw Away Clean Energy"", ""og:description"": ""As we approach the end of another shoulder season \u2014 a period of lower demand and higher transmission outages \u2014 it's a good time to explain curtailment, a crucial yet often controversial aspect of today's grid operations."", ""og:url"": ""https://blog.gridstatus.io/curtailment/"", ""og:image"": ""https://blog.gridstatus.io/content/images/size/w1200/2023/11/Untitled-design--35-.png"", ""article:published_time"": ""2023-11-07T15:45:15.000Z"", ""article:modified_time"": ""2023-11-29T16:02:17.000Z"", ""article:tag"": ""renewables"", ""article:publisher"": ""https://www.facebook.com/ghost"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""Curtailment: When We Throw Away Clean Energy"", ""twitter:description"": ""As we approach the end of another shoulder season \u2014 a period of lower demand and higher transmission outages \u2014 it's a good time to explain curtailment, a crucial yet often controversial aspect of today's grid operations."", ""twitter:url"": ""https://blog.gridstatus.io/curtailment/"", ""twitter:image"": ""https://blog.gridstatus.io/content/images/size/w1200/2023/11/Untitled-design--35-.png"", ""twitter:label1"": ""Written by"", ""twitter:data1"": ""Grid Status"", ""twitter:label2"": ""Filed under"", ""twitter:data2"": ""Curtailment, Wind, Solar, ERCOT, SPP, CAISO, renewables"", ""twitter:site"": ""@ghost"", ""og:image:width"": ""1200"", ""og:image:height"": ""675"", ""generator"": ""Ghost 5.120""}",,,,
https://blog.gridstatus.io/spp-expansion-west/,SPP Expansion Provides a Blueprint for the Future of the Grid,"SPP, the organized electricity market dominating the Great Plains,announced a substantial expansionof their footprint to the West earlier this month. When it goes into effect in early 2026, it will be the largest RTO/ISO expansion since MISO South in 2013.What made this announcement particularly notable is that the joining entities mostly operate in the Western Interconnection. This expansion makes SPP the first RTO in the US to bridge that gap.Given the importance of this change we wanted to explore the interchange, fuel mix, and emissions data for relevant Balancing Authorities (BAs) using the newEIA Data Browseron Grid Status. As we will show, greater connectivity and unified planning over the patchwork of the West can help to facilitate a reduction in both power prices as well as total emissions.Grids in TransitionTwo new Balancing Authorities are joining SPP,WACMandWAUW.WACM is managed by the Rocky Mountain region of the Western Area Power Administration (WAPA) while WAUW is under the control of the Upper Great Plains region of WAPA. WAPA itself was originally created to market and transmit electricity from federal hydropower facilities, but by developing into BAs these regions became more entangled in the wider resource mix of the west.Fuel mix is available for every BA in theEIA-930 data, whether interesting or not. In the case of WAUW it’s only interesting in a historic context - it looks like an isolated grid from the 1900s,totalling under 100 MW of pure hydropower- directly in line with the original WAPA mission.WACM vs SPP Fuel MixWACM, however, is more interesting, managing a larger area with the resources of multiple entities, and is a great representative example for the continued evolution of the grid.Interactively explore the datahereIf you squint a bit, the contribution of different resources to WACM does not look altogether dissimilar to where SPP itself was only 12 years ago (albeit with a greater amount of hydropower in place of natural gas). Just over the last year you can see the natural gas generation begin to grow and coal begins to drop off somewhat. Hydropower helps in displacing some coal - the West had an excellent winter from a water-recharge perspective - but you still see natural gas running more frequently as demand has also picked up.For comparison, here’s SPP’s fuel mix over the same time frame and also from the EIA data (which does have some inconsistencies with the ISO-reported values). SPP has a lot more wind, but also far more natural gas.Interactively explore the datahereSPP represents something like what we may see WACM transition towards - an increase in wind and solar, along with some natural gas, accompanied by a reduction in coal’s share of generation.Entry into a coordinated transmission process at the RTO level could accelerate the retirement of coal resources and incentivize more rapid development in relatively wind, solar, and geothermal rich areas of the BA’s footprint.WACM vs SPP EmissionsThe preponderance of coal in WACM is also borne out by the BA’s CO2 emissions factor from the EIA.In comparison to SPP, generation in WACM’s footprint not only emits substantially more CO2 per MWh of production, but is in a smaller range due to the relatively low penetration of variable renewables such as wind and solar.WACM vs SPP PricingAdditionally, there is increased potential for trading between the markets, both via the limited interconnection capacity of today as well the transmission lines of tomorrow. You can already look at real time prices today in both BAs to see the impact wind-heavy western SPP could have on coal-heavy WACM. Indeed, this process is already ongoing - in 2022, 400 MW of coal in WACM retired.SCSE’s mean daily price is often lower than the WACM node, particularly during the time of year in which hydropower resources are in the part of their annual cycle waiting for “recharge” from snowpack and the “missing” hydropower generation is replaced by technologies that have fuel costs. This bodes well for the transition of WACM, and in these graphs you can see a blueprint for the transition of coal heavy regions.With any increase in regional connectivity SPP’s extant wind resource can help to drive down both prices and emissions during the annual “off peak” for hydropower, which lines up well with the seasonal pattern of stronger wind.Bridging the GapWhen this change goes into effect, SPP will be the first RTO to breach a historic barrier in the US: coordinated operation across two grids.It may surprise some readers to discover that the US consists of not one, but three “grids”. Other than Eastern and Western Interconnections, the third isERCOT’s, which encompasses most, but not all, of Texas. There are historic and political reasons for the three grids, which we won’t dive into here (although check out thisfun Planet Money episodefor a taste of the ERCOT grid).PerNREL’s Seams study, there is only ~1,300 MW of direct connection between the eastern and western grids. To describe the technical obstacle very simply, while the two grids operate at the same 60Hz frequency (unlikeJapan), their actual AC currents are not in rhythm, so these HVDC connections are the only major pathways.Some of this interchange is facilitated through lines withendpoints in SPP’s footprint, and with the addition ofEIA-930 data to Grid Status, you can explore the fuel mix, emissions, load, and interchange between SPP and the two joining BA’s, WAUW and WACM.Interchange TrendsBringing balancing authorities together creates the potential for further coordination. At the simplest level, a single operational entity could help to optimize extant flows between the three BAs. With that in mind, let's look at the interchange between these regions for a sense of how it may evolve over the coming years.Southwest Power Pool (SPP)Let’s take a look at trends over the last several months, starting with SPP’s interchange with the joining entities that are in the Western Interconnection.Interactively explore the datahereOf the two BAs, WACM has substantially greater daily interchange. During the period in the graph, WACM imported a total of 245 GWh from SPP, while WAUW imported only 23 GWh. WACM also has the largest one-hour peak transfer, with 486 MWh being imported from SPP. This is much larger than the peak 144 MWh being exported from WAUW to SPP.Once these 2 BAs join they will become the interface between SPP and the rest of the west, substantially expanding the operational surface area between western and eastern markets, if not the physical capability. So, let’s look at the interchange from the perspective of these two BAs.Western Area Power Administration - Upper Great Plains West (WAUW)Interactively explore the dataherePerhaps to be expected from the smaller SPP flows, WAUW has a fairly straightforward set of interchange partners and generally a low volume of total interchange. Geographically this makes sense, as WAUW is the more isolated BA in the northerly reaches of the mountain west.WAUW does show an interesting pattern: interchanges through the region between SPP and NWMT are near mirror reflections of each other. When SPP is importing from WAUW, NWMT is exporting into WAUW. This could reflectwheeled poweror other obligations and speaks to the complexity of these systems and difficulty in assigning providence to any set of electrons on “the grid”.Is SPP importing from WAUW or NWMT? Of course, neither is exactly true, as the entire interconnected machine must be kept in near perfect sync with the whims of demand at all times.Western Area Power Administration - Rocky Mountain Region (WACM BA)Interactively explore the datahereBy contrast, WACM has substantially more interchange with a larger set of partners, fitting for its central location in the West, covering a more integrated and populous region than WAUW. Here we see very steady exports to WALC, which makes sense, as it is the Desert Southwest region of WAPA. PacifiCorp East (PACE) is also a major importer, although less steadily. The Public Service Company of Colorado (PSCO) is the largest exporter into WACM, which partially surrounds PSCO geographically. Additionally, PSCO is owned by Xcel, which has a much larger footprint than just Colorado.Through the prism of interchange, WACM seems to be a bit of a switching yard through which substantial amounts of power in the mountain west flow.Operational Consolidation In a Fractious RegionWhile the eastern grid is dominated by wholesale markets, most of the west has, to date, resisted consolidation. However, electric grid unification in the Western United States stands to benefit participants financially. In 2020,Brattle estimated $49Min annual savings under a potential SPP RTO West.💡What is an RTO, and how does it differ from constructs already in place?A Regional Transmission Organization (RTO) or Independent System Operator (ISO, you’ll see the terms used interchangeably) is a non-profit entity set up to run and manage the grid in “deregulated” and competitive market regions. Instead of a single utility owning all the power lines and power plants, deciding what facilities to turn up, down, or off, in an RTO the system is managed through price signals in various markets with different entities owning generation and transmission. “Open access” to the transmission system was a key regulatory change several decades ago which made this construct possible.The most basic market in an RTO/ISO is Locational Marginal Prices (LMP), which is the cost of the next MWh to serve the grid. With proper oversight mechanisms this leads to generators bidding in their marginal costs, creating an orderly and efficient supply stack - the “merit order”. This is one piece of the topline dollar benefits, another is the economies of scale derived from centrally managing a larger and more diverse pool of resources.A larger coordinating entity can also take advantage of inherent regional efficiencies: the great plains","{""HandheldFriendly"": ""True"", ""viewport"": ""width=device-width, initial-scale=1.0"", ""description"": ""The U.S. power grid is so complex that trivial changes are hard to comprehend and harder to implement. Yet, a recent announcement by the Southwest Power Pool (SPP) is closer to historic than trivial, making it a good case study for a more integrated and efficient grid."", ""referrer"": ""no-referrer-when-downgrade"", ""og:site_name"": ""Grid Status Exports"", ""og:type"": ""article"", ""og:title"": ""SPP Expansion Provides a Blueprint for the Future of the Grid"", ""og:description"": ""The U.S. power grid is so complex that trivial changes are hard to comprehend and harder to implement. Yet, a recent announcement by the Southwest Power Pool (SPP) is closer to historic than trivial, making it a good case study for a more integrated and efficient grid."", ""og:url"": ""https://blog.gridstatus.io/spp-expansion-west/"", ""og:image"": ""https://blog.gridstatus.io/content/images/size/w1200/2023/09/SPP-Westerward-Exapnsion-min.jpg"", ""article:published_time"": ""2023-09-26T14:06:18.000Z"", ""article:modified_time"": ""2025-02-06T15:57:00.000Z"", ""article:tag"": ""Emissions"", ""article:publisher"": ""https://www.facebook.com/ghost"", ""twitter:card"": ""summary_large_image"", ""twitter:title"": ""SPP Expansion Provides a Blueprint for the Future of the Grid"", ""twitter:description"": ""The U.S. power grid is so complex that trivial changes are hard to comprehend and harder to implement. Yet, a recent announcement by the Southwest Power Pool (SPP) is closer to historic than trivial, making it a good case study for a more integrated and efficient grid."", ""twitter:url"": ""https://blog.gridstatus.io/spp-expansion-west/"", ""twitter:image"": ""https://blog.gridstatus.io/content/images/size/w1200/2023/09/SPP-Westerward-Exapnsion-min.jpg"", ""twitter:label1"": ""Written by"", ""twitter:data1"": ""Grid Status"", ""twitter:label2"": ""Filed under"", ""twitter:data2"": ""SPP, CAISO, WECC, Interchange, Emissions"", ""twitter:site"": ""@ghost"", ""og:image:width"": ""1200"", ""og:image:height"": ""675"", ""generator"": ""Ghost 5.120""}",,,,
https://www.eia.gov/outlooks/steo/,Short-Term Energy Outlook - U.S. Energy Information Administration (EIA),"‹ Analysis & ProjectionsShort-Term Energy OutlookRelease Date:May 6, 2025 |Forecast Completed:May 1, 2025 |Next Release Date:June 10, 2025|Full Report|Text Only|All Tables|All FiguresGlossary ›FAQS ›ForecastsOverviewGlobal oil marketsPetroleum productsNatural gasElectricity, coal, and renewablesEconomy, weather, and CO2DataFiguresTablesSTEO Data browserReal Prices ViewerData series changesSupplementsForecast overviewTrade policy assumptions.The U.S. macroeconomic outlook we use in theShort-Term Energy Outlook(STEO) is based on S&P Global’s macroeconomic model. S&P Global’s most recent model reflects the tariffs announced on April 2, but the model was finalized prior to the90-day temporary suspension of tariffsgranted to certain countries. As a result, our macroeconomic forecast assumes significantly lower tariffs on China’s products than are currently in place and significantly higher tariffs on countries subject to the 90-day temporary suspension. These differences in tariff rates likely have offsetting effects on the macroeconomic forecast.Macroeconomics.Our U.S. GDP forecast has been revised downwards from our April STEO. We now assume real GDP will grow by 1.5% in 2025, a 0.5 percentage point reduction from the April STEO, and 1.6% in 2026, a 0.4 percentage point reduction from last month.Global oil prices.We expect crude oil prices to fall over much of the forecast period. The Brent crude oil spot price averaged $68 per barrel (b) in April. In our forecast, increasing oil production outpaces annual oil demand growth, which rises by around 1.0 million barrels per day (b/d) in both 2025 and 2026, leading to the accumulation of oil inventories globally. We expect the rising inventories will result in the Brent price averaging $62/b in the second half of this year and falling to $59/b next year.Global oil production.We forecast global liquid fuels production will increase by between 1.3 b/d and 1.4 million b/d in both 2025 and 2026 led by production growth in countries outside of OPEC+. We completed modeling and analysis for this forecast beforeOPEC+ announced on May 3that it would raise production in June. Although we expect OPEC+ to increase production somewhat in the coming months, we expect OPEC+ production to remain below the current target path.U.S. ethane markets.In late April, China waived a retaliatory 125% tariff on imports of U.S. ethane that had been levied earlier in the month. With that tariff no longer in place, we continue to expect strong growth in U.S. ethane production and exports in our forecast. We forecast the United States will produce 2.9 million b/d of ethane this year and 3.1 million b/d next year, up from 2.8 million b/d in 2024. Most of this growth in ethane production will be exported to supply growing international demand.Natural gas prices.The Henry Hub spot price fell to $3.44 per million British thermal units (MMBtu) in April, down 68 cents/MMBtu from the March average. The price decrease was primarily driven by relatively warm weather in March and early April, which led to higher-than-expected levels of natural gas injections into storage. We expect natural gas prices will rise in the coming months as the United States exports more LNG and demand for natural gas from the electric power sector increases seasonally. We forecast the Henry Hub spot price will average nearly $4.20/MMBtu in the third quarter of 2025 (3Q25). Despite rising seasonal demand for natural gas heading into summer, our forecast for the 3Q25 Henry Hub price is almost double the price from a year earlier and is contributing to our expectation of less natural gas use in the electric power sector on average this year compared with last year.Electricity generation.Although we expect the U.S. power sector will generate 2% more electricity this year than it did in 2024, we forecast generation from U.S. natural gas-fired power plants will decline by 3% in 2025, partially driven by rising natural gas prices. Less generation from natural gas contributes to a 6% increase in generation from coal. U.S. solar generation continues to provide the largest increases in electricity generation in our forecast, increasing by 34% in 2025 and 18% in 2026.Coal markets.With U.S. coal-fired power plants generating more electricity this year, we now expect coal production will decline by less than we previously expected. We forecast U.S. coal production will total 506 million short tons in 2025, nearly the same amount of coal that was produced last year. Last month, we expected U.S. coal production to fall by 4% this year compared with last year.Summer fuels.This month we published ourGasoline Summer Outlooktableand ourElectricity Summer Outlooktable. We expect gasoline prices across the United States will average $3.14 per gallon over 2Q25 and 3Q25, down 9% from the same period last year. Lower gasoline prices this summer mostly reflect lower crude oil prices. For electricity, we expect the average U.S. electricity bill will be about 4% more this summer (June, July, and August) compared with last summer. The increase is the result of electricity prices that we expect will be 4% higher this summer, largely reflecting an increase in natural gas prices.Notable Forecast Changes20252026Note: Values in this table are rounded and may not match values in other tables in this report. Percentages are calculated from unrounded values.The current STEO forecast was released May 6.The previous STEO forecast was released April 10.Global oil inventory change(million barrels per day)0.40.8Previous forecast0.50.7Change-0.10.1U.S. secondary coal inventories(million short tons)121116Previous forecast108100Percentage change11.6%16.5%U.S coal production(million short tons)506475Previous forecast489466Percentage change3.5%1.9%World GDP(percentage change)2.82.8Previous forecast3.13.2Percentage point change-0.3-0.4U.S. GDP(percentage change)1.51.6Previous forecast2.02.0Percentage point change-0.5-0.4You can find more information in thedetailed table of forecast changes.Overview202320242025projected2026projectedNote: Values in this table are rounded and may not match values in other tables in this report.Brent crude oil(dollars per barrel)82816659Gasoline retail price(dollars per gallon)3.503.303.103.10U.S. crude oil production(million barrels per day)12.913.213.413.5Natural gas spot price(dollars per million BTU)2.502.204.104.80U.S. LNG exports(billion cubic feet per day)12121516Shares of U.S. electricity generation(percentage)Natural gas42424040Coal17161615Renewables22232527Nuclear19191919U.S. GDP(percentage change)2.92.81.51.6U.S. CO2 emissions(million metric tons)4,7904,7804,8304,740Interactive Data ViewersProvides custom data views of historical and forecast dataSTEO Data browser ›Real Prices Viewer ›About theShort-Term Energy OutlookSTEO Release ScheduleContact STEO ExpertsModel DocumentationSign up for email updatesPrevious STEO Forecasts:Changes in Forecast from Last MonthSTEO ArchivesApril 2025March 2025February 2025January 2025December 2024prior issuesOther EIA Forecasts:Annual Energy OutlookInternational Energy Outlook Short-Term Energy Outlook Release Date:May 6, 2025 |Forecast Completed:May 1, 2025 |Next Release Date:June 10, 2025|Full Report|Text Only|All Tables|All Figures Note: Values in this table are rounded and may not match values in other tables in this report. Percentages are calculated from unrounded values.The current STEO forecast was released May 6.The previous STEO forecast was released April 10. You can find more information in thedetailed table of forecast changes. Interactive Data Viewers Provides custom data views of historical and forecast dataSTEO Data browser ›Real Prices Viewer › About theShort-Term Energy Outlook Previous STEO Forecasts:","{""robots"": ""all"", ""agency"": ""EIA - Energy Information Administration"", ""subject"": ""official energy statistics, data, analysis and forecasting"", ""Description"": ""Energy Information Administration - EIA - Official Energy Statistics from the U.S. Government""}",,,,
